{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d136b7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d20903b5",
   "metadata": {},
   "source": [
    "### Directory Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "18cc2714",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'data\\\\Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 0}, page_content='Darshan Hiremath \\n8904691801 | darshanah2002@gmail.com \\n \\nProfile \\nAI & Machine Learning enthusiast with hands-on experience in Statistical Models, Transformer \\nModels, and Large Language Models (LLMs). Passionate about model explainability, fine-tuning \\ntechniques, and AI-powered applications. Skilled in integrating LIME, SHAP, and LLMs (GPT-\\n4, Gemini AI) to enhance interpretability. Experienced in efficient fine-tuning (LoRA, PEFT) and \\noptimizing large models for real-world use. \\n \\nTechnical Skills \\nProgramming: Python \\n‚Ä¢ \\nExplainable AI: SHAP, LIME, Grad-CAM, Integrated Gradients \\n‚Ä¢ \\nLLM : Llama 3.1  \\n‚Ä¢ \\nDeep Learning: CNNs, Transformers, LLMs   \\n‚Ä¢ \\nNLP Models: GPT-2, DistilBERT   \\n‚Ä¢ \\nLLM Fine-Tuning: LoRA, PEFT, Quantization (4-bit, 8-bit)   \\n‚Ä¢ \\nFrameworks: PyTorch, TensorFlow , Hugging Face   \\n‚Ä¢ \\nTools: Gemini AI, GPT-4   \\n‚Ä¢ \\nDomains: XAI, NLP, Deep Learning , Model Interpretability \\n \\nWork Experience \\nAI & Machine Learning Engineer   \\nL&T Technology Services | July 2024 ‚Äì Present   \\n \\nExplainable AI ‚Äì Statistical Models (Honda Use Case) \\n\\uf0b7 \\nApplied LIME and SHAP to explain predictions of a statistical sensor-based quality \\nmodel (Gx, Gy, Gz). \\n\\uf0b7 \\nDelivered instance-level and global feature attributions for ‚ÄúGood / No-Good‚Äù \\nclassifications. \\n\\uf0b7 \\nIntegrated GPT-4 and Gemini AI to automatically convert XAI outputs into \\nbusiness-friendly explanations for non-technical stakeholders. \\n\\uf0b7 \\nPresented explainability results through visual reports and demo videos to cross-\\nfunctional teams. \\n \\nExplainability in Transformer Models \\n\\uf0b7 Investigated feasibility of applying SHAP to transformer architectures. \\n\\uf0b7 Fine-tuned GPT-2 and DistilBERT on Amazon Reviews for sentiment \\nclassification. \\n\\uf0b7 Identified and resolved incorrect attribution issues by improving fine-tuning strategy. \\n\\uf0b7 Successfully generated token-level and feature-level explanations for transformer \\npredictions. \\n \\nExploration of LLMs & Efficient Fine-Tuning \\n\\uf0b7 Explored explainability extensions for Large Language Models (LLMs). \\n\\uf0b7 Experimented with 4-bit and 8-bit quantized model loading for memory-efficient \\ninference. \\n\\uf0b7 Implemented PEFT techniques, including LoRA, to fine-tune LLMs with reduced \\ncompute cost. \\n\\uf0b7 Evaluated trade-offs between performance, memory usage, and interpretability.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'data\\\\Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 1}, page_content='Hackathon  \\n\\uf0b7 \\nParticipated in L&T internal hackathon focused on applied AI solutions. \\n\\uf0b7 \\nImplemented Grad-CAM on ResNet for eye disease classification, highlighting \\nclass-discriminative regions. \\n\\uf0b7 \\nDemonstrated how CNN models learn visual patterns and validated predictions using \\nsaliency maps. \\nEDUCATION \\nBapuji Institute Of Engineering And Technology                                                    2020 ‚Äì 2024 \\nComputer Science & Engineering                                                                              \\n7.8/10 CGPA  \\nVishwaachetana Vidyaniketana Pu College                                                              2018 - 2020 \\n 73 percent  \\nOM National PU College                                                                                          2018 \\n71 percent'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'data\\\\Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 2}, page_content=''), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 0}, page_content='Speech and Language Processing.\\nDaniel Jurafsky & James H. Martin.\\nCopyright ¬© 2025.\\nAll\\nrights reserved.\\nDraft of August 24, 2025.\\nCHAPTER\\n5\\nEmbeddings\\nËçÉËÄÖÊâÄ‰ª•Âú®È±ºÔºåÂæóÈ±ºËÄåÂøòËçÉNets are for Ô¨Åsh;\\nOnce you get the Ô¨Åsh, you can forget the net.\\nË®ÄËÄÖÊâÄ‰ª•Âú®ÊÑèÔºåÂæóÊÑèËÄåÂøòË®ÄWords are for meaning;\\nOnce you get the meaning, you can forget the words\\nÂ∫ÑÂ≠ê(Zhuangzi), Chapter 26\\nThe asphalt that Los Angeles is famous for occurs mainly on its freeways. But\\nin the middle of the city is another patch of asphalt, the La Brea tar pits, and this\\nasphalt preserves millions of fossil bones from the last of the Ice Ages of the Pleis-\\ntocene Epoch. One of these fossils is the Smilodon, or saber-toothed tiger, instantly\\nrecognizable by its long canines. Five million years ago or so, a completely different\\nsaber-tooth tiger called Thylacosmilus lived\\nin Argentina and other parts of South Amer-\\nica. Thylacosmilus was a marsupial whereas\\nSmilodon was a placental mammal, but Thy-\\nlacosmilus had the same long upper canines\\nand, like Smilodon, had a protective bone\\nÔ¨Çange on the lower jaw.\\nThe similarity of\\nthese two mammals is one of many examples\\nof parallel or convergent evolution, in which particular contexts or environments\\nlead to the evolution of very similar structures in different species (Gould, 1980).\\nThe role of context is also important in the similarity of a less biological kind\\nof organism: the word. Words that occur in similar contexts tend to have similar\\nmeanings. This link between similarity in how words are distributed and similarity\\nin what they mean is called the distributional hypothesis. The hypothesis was\\ndistributional\\nhypothesis\\nÔ¨Årst formulated in the 1950s by linguists like Joos (1950), Harris (1954), and Firth\\n(1957), who noticed that words which are synonyms (like oculist and eye-doctor)\\ntended to occur in the same environment (e.g., near words like eye or examined)\\nwith the amount of meaning difference between two words ‚Äúcorresponding roughly\\nto the amount of difference in their environments‚Äù (Harris, 1954, p. 157).\\nIn this chapter we introduce embeddings, vector representations of the meaning\\nembeddings\\nof words that are learned directly from word distributions in texts. Embeddings lie\\nat the heart of large language models and other modern applications. The static em-\\nbeddings we introduce here underlie the more powerful dynamic or contextualized\\nembeddings like BERT that we will see in Chapter 10 and Chapter 8.\\nThe linguistic Ô¨Åeld that studies embeddings and their meanings is called vector\\nsemantics. Embeddings are also the Ô¨Årst example in this book of representation\\nvector\\nsemantics\\nlearning, automatically learning useful representations of the input text. Finding\\nrepresentation\\nlearning\\nsuch self-supervised ways to learn representations of language, instead of creat-\\ning representations by hand via feature engineering, is an important principle of\\nmodern NLP (Bengio et al., 2013).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 1}, page_content='2\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n5.1\\nLexical Semantics\\nLet‚Äôs begin by introducing some basic principles of word meaning. How should\\nwe represent the meaning of a word? In the n-gram models of Chapter 3, and in\\nclassical NLP applications, our only representation of a word is as a string of letters,\\nor an index in a vocabulary list. This representation is not that different from a\\ntradition in philosophy, perhaps you‚Äôve seen it in introductory logic classes, in which\\nthe meaning of words is represented by just spelling the word with small capital\\nletters; representing the meaning of ‚Äúdog‚Äù as DOG, and ‚Äúcat‚Äù as CAT, or by using an\\napostrophe (DOG‚Äô).\\nRepresenting the meaning of a word by capitalizing it is a pretty unsatisfactory\\nmodel. You might have seen a version of a joke due originally to semanticist Barbara\\nPartee (Carlson, 1977):\\nQ: What‚Äôs the meaning of life?\\nA: LIFE‚Äô\\nSurely we can do better than this! After all, we‚Äôll want a model of word meaning\\nto do all sorts of things for us. It should tell us that some words have similar mean-\\nings (cat is similar to dog), others are antonyms (cold is the opposite of hot), some\\nhave positive connotations (happy) while others have negative connotations (sad). It\\nshould represent the fact that the meanings of buy, sell, and pay offer differing per-\\nspectives on the same underlying purchasing event. (If I buy something from you,\\nyou‚Äôve probably sold it to me, and I likely paid you.) More generally, a model of\\nword meaning should allow us to draw inferences to address meaning-related tasks\\nlike question-answering or dialogue.\\nIn this section we summarize some of these desiderata, drawing on results in the\\nlinguistic study of word meaning, which is called lexical semantics; we‚Äôll return to\\nlexical\\nsemantics\\nand expand on this list in Appendix G and Chapter 21.\\nLemmas and Senses\\nLet‚Äôs start by looking at how one word (we‚Äôll choose mouse)\\nmight be deÔ¨Åned in a dictionary (simpliÔ¨Åed from the online dictionary WordNet):\\nmouse (N)\\n1.\\nany of numerous small rodents...\\n2.\\na hand-operated device that controls a cursor...\\nHere the form mouse is the lemma, also called the citation form. The form\\nlemma\\ncitation form\\nmouse would also be the lemma for the word mice; dictionaries don‚Äôt have separate\\ndeÔ¨Ånitions for inÔ¨Çected forms like mice. Similarly sing is the lemma for sing, sang,\\nsung. In many languages the inÔ¨Ånitive form is used as the lemma for the verb, so\\nSpanish dormir ‚Äúto sleep‚Äù is the lemma for duermes ‚Äúyou sleep‚Äù. The speciÔ¨Åc forms\\nsung or carpets or sing or duermes are called wordforms.\\nwordform\\nAs the example above shows, each lemma can have multiple meanings; the\\nlemma mouse can refer to the rodent or the cursor control device. We call each\\nof these aspects of the meaning of mouse a word sense. The fact that lemmas can\\nbe polysemous (have multiple senses) can make interpretation difÔ¨Åcult (is some-\\none who searches for ‚Äúmouse info‚Äù looking for a pet or a widget?). Chapter 10\\nand Appendix G will discuss the problem of polysemy, and introduce word sense\\ndisambiguation, the task of determining which sense of a word is being used in a\\nparticular context.\\nSynonymy\\nOne important component of word meaning is the relationship be-\\ntween word senses. For example when one word has a sense whose meaning is'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 2}, page_content='5.1\\n‚Ä¢\\nLEXICAL SEMANTICS\\n3\\nidentical to a sense of another word, or nearly identical, we say the two senses of\\nthose two words are synonyms. Synonyms include such pairs as\\nsynonym\\ncouch/sofa vomit/throw up Ô¨Ålbert/hazelnut car/automobile\\nA more formal deÔ¨Ånition of synonymy (between words rather than senses) is that\\ntwo words are synonymous if they are substitutable for one another in any sentence\\nwithout changing the truth conditions of the sentence, the situations in which the\\nsentence would be true.\\nWhile substitutions between some pairs of words like car / automobile or wa-\\nter / H2O are truth preserving, the words are still not identical in meaning. Indeed,\\nprobably no two words are absolutely identical in meaning. One of the fundamental\\ntenets of semantics, called the principle of contrast (Girard 1718, Br¬¥eal 1897, Clark\\nprinciple of\\ncontrast\\n1987), states that a difference in linguistic form is always associated with some dif-\\nference in meaning. For example, the word H2O is used in scientiÔ¨Åc contexts and\\nwould be inappropriate in a hiking guide‚Äîwater would be more appropriate‚Äî and\\nthis genre difference is part of the meaning of the word. In practice, the word syn-\\nonym is therefore used to describe a relationship of approximate or rough synonymy.\\nWord Similarity\\nWhile words don‚Äôt have many synonyms, most words do have\\nlots of similar words. Cat is not a synonym of dog, but cats and dogs are certainly\\nsimilar words. In moving from synonymy to similarity, it will be useful to shift from\\ntalking about relations between word senses (like synonymy) to relations between\\nwords (like similarity). Dealing with words avoids having to commit to a particular\\nrepresentation of word senses, which will turn out to simplify our task.\\nThe notion of word similarity is very useful in larger semantic tasks. Knowing\\nsimilarity\\nhow similar two words are can help in computing how similar the meaning of two\\nphrases or sentences are, a very important component of tasks like question answer-\\ning, paraphrasing, and summarization. One way of getting values for word similarity\\nis to ask humans to judge how similar one word is to another. A number of datasets\\nhave resulted from such experiments. For example the SimLex-999 dataset (Hill\\net al., 2015) gives values on a scale from 0 to 10, like the examples below, which\\nrange from near-synonyms (vanish, disappear) to pairs that scarcely seem to have\\nanything in common (hole, agreement):\\nvanish\\ndisappear\\n9.8\\nbelief\\nimpression 5.95\\nmuscle bone\\n3.65\\nmodest Ô¨Çexible\\n0.98\\nhole\\nagreement\\n0.3\\nWord Relatedness\\nThe meaning of two words can be related in ways other than\\nsimilarity. One such class of connections is called word relatedness (Budanitsky\\nrelatedness\\nand Hirst, 2006), also traditionally called word association in psychology.\\nassociation\\nConsider the meanings of the words coffee and cup. Coffee is not similar to cup;\\nthey share practically no features (coffee is a plant or a beverage, while a cup is a\\nmanufactured object with a particular shape). But coffee and cup are clearly related;\\nthey are associated by co-participating in an everyday event (the event of drinking\\ncoffee out of a cup). Similarly scalpel and surgeon are not similar but are related\\neventively (a surgeon tends to make use of a scalpel).\\nOne common kind of relatedness between words is if they belong to the same\\nsemantic Ô¨Åeld. A semantic Ô¨Åeld is a set of words which cover a particular semantic\\nsemantic Ô¨Åeld\\ndomain and bear structured relations with each other. For example, words might be'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 3}, page_content='4\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nrelated by being in the semantic Ô¨Åeld of hospitals (surgeon, scalpel, nurse, anes-\\nthetic, hospital), restaurants (waiter, menu, plate, food, chef), or houses (door, roof,\\nkitchen, family, bed). Semantic Ô¨Åelds are also related to topic models, like Latent\\ntopic models\\nDirichlet Allocation, LDA, which apply unsupervised learning on large sets of texts\\nto induce sets of associated words from text. Semantic Ô¨Åelds and topic models are\\nvery useful tools for discovering topical structure in documents.\\nIn Appendix G we‚Äôll introduce more relations between senses like hypernymy\\nor IS-A, antonymy (opposites) and meronymy (part-whole relations).\\nConnotation\\nFinally, words have affective meanings or connotations. The word\\nconnotations\\nconnotation has different meanings in different Ô¨Åelds, but here we use it to mean the\\naspects of a word‚Äôs meaning that are related to a writer or reader‚Äôs emotions, senti-\\nment, opinions, or evaluations. For example some words have positive connotations\\n(wonderful) while others have negative connotations (dreary). Even words whose\\nmeanings are similar in other ways can vary in connotation; consider the difference\\nin connotations between fake, knockoff, forgery, on the one hand, and copy, replica,\\nreproduction on the other, or innocent (positive connotation) and naive (negative\\nconnotation). Some words describe positive evaluation (great, love) and others neg-\\native evaluation (terrible, hate). Positive or negative evaluation language is called\\nsentiment, as we saw in Appendix K, and word sentiment plays a role in impor-\\nsentiment\\ntant tasks like sentiment analysis, stance detection, and applications of NLP to the\\nlanguage of politics and consumer reviews.\\nEarly work on affective meaning (Osgood et al., 1957) found that words varied\\nalong three important dimensions of affective meaning:\\nvalence: the pleasantness of the stimulus\\narousal: the intensity of emotion provoked by the stimulus\\ndominance: the degree of control exerted by the stimulus\\nThus words like happy or satisÔ¨Åed are high on valence, while unhappy or an-\\nnoyed are low on valence. Excited is high on arousal, while calm is low on arousal.\\nControlling is high on dominance, while awed or inÔ¨Çuenced are low on dominance.\\nEach word is thus represented by three numbers, corresponding to its value on each\\nof the three dimensions:\\nValence Arousal Dominance\\ncourageous 8.0\\n5.5\\n7.4\\nmusic\\n7.7\\n5.6\\n6.5\\nheartbreak\\n2.5\\n5.7\\n3.6\\ncub\\n6.7\\n4.0\\n4.2\\nOsgood et al. (1957) noticed that in using these 3 numbers to represent the\\nmeaning of a word, the model was representing each word as a point in a three-\\ndimensional space, a vector whose three dimensions corresponded to the word‚Äôs\\nrating on the three scales. This revolutionary idea that word meaning could be rep-\\nresented as a point in space (e.g., that part of the meaning of heartbreak can be\\nrepresented as the point [2.5,5.7,3.6]) was the Ô¨Årst expression of the vector seman-\\ntics models that we introduce next.\\n5.2\\nVector Semantics: The Intuition\\nVector semantics is the standard way to represent word meaning in NLP, helping\\nvector\\nsemantics'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 4}, page_content='5.2\\n‚Ä¢\\nVECTOR SEMANTICS: THE INTUITION\\n5\\nus model many of the aspects of word meaning we saw in the previous section. The\\nroots of the model lie in the 1950s when two big ideas converged: Osgood‚Äôs 1957\\nidea mentioned above to use a point in three-dimensional space to represent the\\nconnotation of a word, and the proposal by linguists like Joos (1950), Harris (1954),\\nand Firth (1957) to deÔ¨Åne the meaning of a word by its distribution in language\\nuse, meaning its neighboring words or grammatical environments. Their idea was\\nthat two words that occur in very similar distributions (whose neighboring words are\\nsimilar) have similar meanings.\\nFor example, suppose you didn‚Äôt know the meaning of the word ongchoi (a re-\\ncent borrowing from Cantonese) but you see it in the following contexts:\\n(5.1) Ongchoi is delicious sauteed with garlic.\\n(5.2) Ongchoi is superb over rice.\\n(5.3) ...ongchoi leaves with salty sauces...\\nAnd suppose that you had seen many of these context words in other contexts:\\n(5.4) ...spinach sauteed with garlic over rice...\\n(5.5) ...chard stems and leaves are delicious...\\n(5.6) ...collard greens and other salty leafy greens\\nThe fact that ongchoi occurs with words like rice and garlic and delicious and\\nsalty, as do words like spinach, chard, and collard greens might suggest that ongchoi\\nis a leafy green similar to these other leafy greens.1 We can implement the same\\nintuition computationally by just counting words in the context of ongchoi.\\nFigure 5.1\\nA two-dimensional (t-SNE) visualization of 200-dimensional word2vec em-\\nbeddings for some words close to the word sweet, showing that words with similar mean-\\nings are nearby in space. Visualization created using the TensorBoard Embedding Projector\\nhttps://projector.tensorflow.org/.\\nThe idea of vector semantics is to represent a word as a point in a multidimen-\\nsional semantic space that is derived (in different ways we‚Äôll see) from the distri-\\nbutions of word neighbors. Vectors for representing words are called embeddings.\\nembeddings\\nThe word ‚Äúembedding‚Äù derives historically from its mathematical sense as a map-\\nping from one space or structure to another, although the meaning has shifted; see\\nthe end of the chapter.\\nFig. 5.1 shows a visualization of embeddings learned by the word2vec algorithm,\\nshowing the location of selected words (neighbors of ‚Äúsweet‚Äù) projected down from\\n1\\nIt‚Äôs in fact Ipomoea aquatica, a relative of morning glory sometimes called water spinach in English.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 5}, page_content='6\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n200-dimensional space into a 2-dimensional space. Note that the nearest neighbors\\nof sweet are semantically related words like honey, candy, juice, chocolate. This idea\\nthat similar words are near each other in high-dimensional space is an important\\nthat offers enormous power to language models and other NLP applications. For\\nexample the sentiment classiÔ¨Åers of Chapter 4 depend on the same words appearing\\nin the training and test sets. But by representing words as embeddings, a classiÔ¨Åer\\ncan assign sentiment as long as it sees some words with similar meanings. And as\\nwe‚Äôll see, vector semantic models like the ones showed in Fig. 5.1 can be learned\\nautomatically from text without supervision.\\nIn this chapter we‚Äôll begin with a simple pedagogical model of embeddings in\\nwhich the meaning of a word is deÔ¨Åned by a vector with the counts of nearby words.\\nWe introduce this model as a helpful way to understand the concept of vectors and\\nwhat it means for a vector to be a representation of word meaning, but more sophis-\\nticated variants like the tf-idf model we will introduce in Chapter 11 are important\\nmethods you should understand. We will see that this method results in very long\\nvectors that are sparse, i.e. mostly zeros (since most words simply never occur in the\\ncontext of others). We‚Äôll then introduce the word2vec model family for constructing\\nshort, dense vectors that have even more useful semantic properties.\\nWe‚Äôll also introduce the cosine, the standard way to use embeddings to com-\\npute semantic similarity, between two words, two sentences, or two documents, an\\nimportant tool in practical applications.\\n5.3\\nSimple count-based embeddings\\n‚ÄúThe most important attributes of a vector in 3-space are {Location, Location, Location}‚Äù\\nRandall Munroe, the hover from https://xkcd.com/2358/\\nLet‚Äôs now introduce the Ô¨Årst way to compute word vector embeddings. This sim-\\nplest vector model of meaning is based on the co-occurrence matrix, a way of rep-\\nresenting how often words co-occur. We‚Äôll deÔ¨Åne a particular kind of co-occurrence\\nmatrix, the word-context matrix, in which each row in the matrix represents a word\\nword-context\\nmatrix\\nin the vocabulary and each column represents how often each other word in the vo-\\ncabulary appears nearby. This matrix is thus of dimensionality |V| √ó |V| and each\\ncell records the number of times the row (target) word and the column (context)\\nword co-occur nearby in some training corpus.\\nWhat do we mean by ‚Äònearby‚Äô? We could implement various methods, but let‚Äôs\\nstart with a very simple one: a context window around the word, let‚Äôs say of 4 words\\nto the left and 4 words to the right. If we do that, each cell will represents the\\nnumber of times (in some training corpus) the column word occurs in such a ¬±4\\nword window around the row word.\\nLet‚Äôs see how this works for 4 words: cherry, strawberry, digital, and informa-\\ntion. For each word we took a single instance from a corpus, and we show the ¬±4\\nword window from that instance:\\nis traditionally followed by cherry\\npie, a traditional dessert\\noften mixed, such as strawberry\\nrhubarb pie. Apple pie\\ncomputer peripherals and personal digital\\nassistants. These devices usually\\na computer. This includes information available on the internet\\nIf we then take every occurrence of each word in a large corpus and count the\\ncontext words around it, we get a word-context co-occurrence matrix. The full word-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 6}, page_content='5.3\\n‚Ä¢\\nSIMPLE COUNT-BASED EMBEDDINGS\\n7\\ncontext co-occurrence matrix is very large, because for each word in the vocabulary\\n(since |V|) we have to count how often it occurs with every other word in the vo-\\ncabulary, hence dimensionality |V|√ó|V|. Let‚Äôs therefore instead sketch the process\\non a smaller scale. Imagine that we are going to look at only the 4 words, and only\\nconsider the following 3 context words: a, computer, and pie. Furthermore let‚Äôs\\nassume we only count occurrences in the mini-corpus above.\\nSo before looking at Fig. 5.2, compute by hand the counts for these 3 context\\nwords for the four words cherry, strawberry, digital, and information.\\na\\ncomputer\\npie\\ncherry\\n1\\n0\\n1\\nstrawberry\\n0\\n0\\n2\\ndigital\\n0\\n1\\n0\\ninformation\\n1\\n1\\n0\\nFigure 5.2\\nCo-occurrence vectors for four words with counts from the 4 windows above,\\nshowing just 3 of the potential context word dimensions. The vector for cherry is outlined in\\nred. Note that a real vector would have vastly more dimensions and thus be even sparser.\\nHopefully your count matches what is shown in Fig. 5.2, so that each cell repre-\\nsents the number of times a particular word (deÔ¨Åned by the row) occurs in a partic-\\nular context (deÔ¨Åned by the word column).\\nEach row, then, is a vector representing a word. To review some basic linear\\nalgebra, a vector is, at heart, just a list or array of numbers. So cherry is represented\\nvector\\nas the list [1,0,1] (the Ô¨Årst row vector in Fig. 5.2) and information is represented as\\nthe list [1,1,0] (the fourth row vector).\\nA vector space is a collection of vectors, and is characterized by its dimension.\\nvector space\\ndimension\\nVectors in a 3-dimensional vector space have an element for each dimension of the\\nspace. We will loosely refer to a vector in a 3-dimensional space as a 3-dimensional\\nvector, with one element along each dimension. In the example in Fig. 5.2, we‚Äôve\\nchosen to make the document vectors of dimension 3, just so they Ô¨Åt on the page; in\\nreal term-document matrices, the document vectors would have dimensionality |V|,\\nthe vocabulary size.\\nThe ordering of the numbers in a vector space indicates the different dimensions\\non which documents vary. The third dimension for all these vectors corresponds\\nto the number of times pie occurs in the context. The second dimension for all of\\nthem corresponds to the number of times the word computer occurs. Notice that\\nthe vectors for information and digital have the same value (1) for this ‚Äúcomputer‚Äù\\ndimension.\\nIn reality, we don‚Äôt compute word vectors on a single context window. Instead,\\nwe compute them over an entire corpus. Let‚Äôs see what some real counts look like.\\nLet‚Äôs look at some vectors computed in this way. Fig. 5.3 shows a subset of the\\nword-word co-occurrence matrix for these four words, where, again because it‚Äôs\\nimpossible to visualize all |V| possible context words on the page of this textbook,\\nwe show a subset of 6 of the dimensions, with counts computed from the Wikipedia\\ncorpus (Davies, 2015).\\nNote in Fig. 5.3 that the two words cherry and strawberry are more similar to\\neach other (both pie and sugar tend to occur in their window) than they are to other\\nwords like digital; conversely, digital and information are more similar to each other\\nthan, say, to strawberry.\\nWe can think of the vector for a document as a point in |V|-dimensional space;\\nthus the documents in Fig. 5.3 are points in 3-dimensional space. Fig. 5.4 shows a\\nspatial visualization.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 7}, page_content='8\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\naardvark\\n...\\ncomputer\\ndata\\nresult\\npie\\nsugar\\n...\\ncherry\\n0\\n...\\n2\\n8\\n9\\n442\\n25\\n...\\nstrawberry\\n0\\n...\\n0\\n0\\n1\\n60\\n19\\n...\\ndigital\\n0\\n...\\n1670\\n1683\\n85\\n5\\n4\\n...\\ninformation\\n0\\n...\\n3325\\n3982\\n378\\n5\\n13\\n...\\nFigure 5.3\\nCo-occurrence vectors for four words in the Wikipedia corpus, showing six of\\nthe dimensions (hand-picked for pedagogical purposes). The vector for digital is outlined in\\nred. Note that a real vector would have vastly more dimensions and thus be much sparser, i.e.\\nwould have zero values in most dimensions.\\n1000 2000 3000 4000\\n1000\\n2000\\ndigital\\n [1683,1670]\\ncomputer\\n data\\ninformation\\n [3982,3325] \\n3000\\n4000\\nFigure 5.4\\nA spatial visualization of word vectors for digital and information, showing just\\ntwo of the dimensions, corresponding to the words data and computer.\\nNote that |V|, the dimensionality of the vector, is generally the size of the vo-\\ncabulary, often between 10,000 and 50,000 words (using the most frequent words\\nin the training corpus; keeping words after about the most frequent 50,000 or so is\\ngenerally not helpful). Since most of these numbers are zero these are sparse vector\\nrepresentations; there are efÔ¨Åcient algorithms for storing and computing with sparse\\nmatrices.\\nIt‚Äôs also possible to applying various kinds of weighting functions to the counts\\nin these cells. The most popular such weighting is tf-idf, which we‚Äôll introduce in\\nChapter 11, but there have historically been a wide variety of other weightings.\\nNow that we have some intuitions, let‚Äôs move on to examine the details of com-\\nputing word similarity.\\n5.4\\nCosine for measuring similarity\\nTo measure similarity between two target words v and w, we need a metric that\\ntakes two vectors (of the same dimensionality, either both with words as dimensions,\\nhence of length |V|, or both with documents as dimensions, of length |D|) and gives\\na measure of their similarity. By far the most common similarity metric is the cosine\\nof the angle between the vectors.\\nThe cosine‚Äîlike most measures for vector similarity used in NLP‚Äîis based on\\nthe dot product operator from linear algebra, also called the inner product:\\ndot product\\ninner product\\ndot product(v,w) = v ¬∑w =\\nN\\nX\\ni=1\\nviwi = v1w1 +v2w2 +...+vNwN\\n(5.7)\\nThe dot product acts as a similarity metric because it will tend to be high just when\\nthe two vectors have large values in the same dimensions. Alternatively, vectors that'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 8}, page_content='5.4\\n‚Ä¢\\nCOSINE FOR MEASURING SIMILARITY\\n9\\nhave zeros in different dimensions‚Äîorthogonal vectors‚Äîwill have a dot product of\\n0, representing their strong dissimilarity.\\nThis raw dot product, however, has a problem as a similarity metric: it favors\\nlong vectors. The vector length is deÔ¨Åned as\\nvector length\\n|v| =\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nv2\\ni\\n(5.8)\\nThe dot product is higher if a vector is longer, with higher values in each dimension.\\nMore frequent words have longer vectors, since they tend to co-occur with more\\nwords and have higher co-occurrence values with each of them. The raw dot product\\nthus will be higher for frequent words. But this is a problem; we‚Äôd like a similarity\\nmetric that tells us how similar two words are regardless of their frequency.\\nWe modify the dot product to normalize for the vector length by dividing the\\ndot product by the lengths of each of the two vectors. This normalized dot product\\nturns out to be the same as the cosine of the angle between the two vectors, following\\nfrom the deÔ¨Ånition of the dot product between two vectors a and b:\\na¬∑b = |a||b|cosŒ∏\\na¬∑b\\n|a||b| = cosŒ∏\\n(5.9)\\nThe cosine similarity metric between two vectors v and w thus can be computed as:\\ncosine\\ncosine(v,w) = v ¬∑w\\n|v||w| =\\nN\\nX\\ni=1\\nviwi\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nv2\\ni\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nw2\\ni\\n(5.10)\\nFor some applications we pre-normalize each vector, by dividing it by its length,\\ncreating a unit vector of length 1. Thus we could compute a unit vector from a by\\nunit vector\\ndividing it by |a|. For unit vectors, the dot product is the same as the cosine.\\nThe cosine value ranges from 1 for vectors pointing in the same direction, through\\n0 for orthogonal vectors, to -1 for vectors pointing in opposite directions. But since\\nraw frequency values are non-negative, the cosine for these vectors ranges from 0‚Äì1.\\nLet‚Äôs see how the cosine computes which of the words cherry or digital is closer\\nin meaning to information, just using raw counts from the following shortened table:\\npie\\ndata computer\\ncherry\\n442\\n8\\n2\\ndigital\\n5\\n1683\\n1670\\ninformation\\n5\\n3982\\n3325\\ncos(cherry,information) =\\n442‚àó5+8‚àó3982+2‚àó3325\\n‚àö\\n4422 +82 +22‚àö\\n52 +39822 +33252 = .018\\ncos(digital,information) =\\n5‚àó5+1683‚àó3982+1670‚àó3325\\n‚àö\\n52 +16832 +16702‚àö\\n52 +39822 +33252 = .996\\nThe model decides that information is way closer to digital than it is to cherry, a\\nresult that seems sensible. Fig. 5.5 shows a visualization.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 9}, page_content='10\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n500\\n1000\\n1500\\n2000\\n2500\\n3000\\n500\\ndigital\\ncherry\\ninformation\\nDimension 1: ‚Äòpie‚Äô\\nDimension 2: ‚Äòcomputer‚Äô\\nFigure 5.5\\nA (rough) graphical demonstration of cosine similarity, showing vectors for\\nthree words (cherry, digital, and information) in the two dimensional space deÔ¨Åned by counts\\nof the words computer and pie nearby. The Ô¨Ågure doesn‚Äôt show the cosine, but it highlights the\\nangles; note that the angle between digital and information is smaller than the angle between\\ncherry and information. When two vectors are more similar, the cosine is larger but the angle\\nis smaller; the cosine has its maximum (1) when the angle between two vectors is smallest\\n(0‚ó¶); the cosine of all other angles is less than 1.\\ncan be used to compute word similarity, for tasks like Ô¨Ånding word paraphrases,\\ntracking changes in word meaning, or automatically discovering meanings of words\\nin different corpora. For example, we can Ô¨Ånd the 10 most similar words to any\\ntarget word w by computing the cosines between w and each of the |V| ‚àí1 other\\nwords, sorting, and looking at the top 10.\\n5.5\\nWord2vec\\nIn the previous sections we saw how to represent a word as a sparse, long vector with\\ndimensions corresponding to words in the vocabulary. We now introduce a more\\npowerful word representation: embeddings, short dense vectors. Unlike the vectors\\nwe‚Äôve seen so far, embeddings are short, with number of dimensions d ranging from\\n50-1000, rather than the much larger vocabulary size |V|.These d dimensions don‚Äôt\\nhave a clear interpretation. And the vectors are dense: instead of vector entries\\nbeing sparse, mostly-zero counts or functions of counts, the values will be real-\\nvalued numbers that can be negative.\\nIt turns out that dense vectors work better in every NLP task than sparse vectors.\\nWhile we don‚Äôt completely understand all the reasons for this, we have some intu-\\nitions. Representing words as 300-dimensional dense vectors requires our classiÔ¨Åers\\nto learn far fewer weights than if we represented words as 50,000-dimensional vec-\\ntors, and the smaller parameter space possibly helps with generalization and avoid-\\ning overÔ¨Åtting. Dense vectors may also do a better job of capturing synonymy.\\nFor example, in a sparse vector representation, dimensions for synonyms like car\\nand automobile dimension are distinct and unrelated; sparse vectors may thus fail\\nto capture the similarity between a word with car as a neighbor and a word with\\nautomobile as a neighbor.\\nIn this section we introduce one method for computing embeddings: skip-gram\\nskip-gram\\nwith negative sampling, sometimes called SGNS. The skip-gram algorithm is one\\nSGNS\\nof two algorithms in a software package called word2vec, and so sometimes the\\nword2vec\\nalgorithm is loosely referred to as word2vec (Mikolov et al. 2013a, Mikolov et al.\\n2013b). The word2vec methods are fast, efÔ¨Åcient to train, and easily available on-\\nline with code and pretrained embeddings. Word2vec embeddings are static em-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 10}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n11\\nbeddings, meaning that the method learns one Ô¨Åxed embedding for each word in the\\nstatic\\nembeddings\\nvocabulary. In Chapter 10 we‚Äôll introduce methods for learning dynamic contextual\\nembeddings like the popular family of BERT representations, in which the vector\\nfor each word is different in different contexts.\\nThe intuition of word2vec is that instead of counting how often each word w oc-\\ncurs near, say, apricot, we‚Äôll instead train a classiÔ¨Åer on a binary prediction task: ‚ÄúIs\\nword w likely to show up near apricot?‚Äù We don‚Äôt actually care about this prediction\\ntask; instead we‚Äôll take the learned classiÔ¨Åer weights as the word embeddings.\\nThe revolutionary intuition here is that we can just use running text as implicitly\\nsupervised training data for such a classiÔ¨Åer; a word c that occurs near the target\\nword apricot acts as gold ‚Äòcorrect answer‚Äô to the question ‚ÄúIs word c likely to show\\nup near apricot?‚Äù This method, often called self-supervision, avoids the need for\\nself-supervision\\nany sort of hand-labeled supervision signal. This idea was Ô¨Årst proposed in the task\\nof neural language modeling, when Bengio et al. (2003) and Collobert et al. (2011)\\nshowed that a neural language model (a neural network that learned to predict the\\nnext word from prior words) could just use the next word in running text as its\\nsupervision signal, and could be used to learn an embedding representation for each\\nword as part of doing this prediction task.\\nWe‚Äôll see how to do neural networks in the next chapter, but word2vec is a\\nmuch simpler model than the neural network language model, in two ways. First,\\nword2vec simpliÔ¨Åes the task (making it binary classiÔ¨Åcation instead of word pre-\\ndiction). Second, word2vec simpliÔ¨Åes the architecture (training a logistic regression\\nclassiÔ¨Åer instead of a multi-layer neural network with hidden layers that demand\\nmore sophisticated training algorithms). The intuition of skip-gram is:\\n1. Treat the target word and a neighboring context word as positive examples.\\n2. Randomly sample other words in the lexicon to get negative samples.\\n3. Use logistic regression to train a classiÔ¨Åer to distinguish those two cases.\\n4. Use the learned weights as the embeddings.\\n5.5.1\\nThe classiÔ¨Åer\\nLet‚Äôs start by thinking about the classiÔ¨Åcation task, and then turn to how to train.\\nImagine a sentence like the following, with a target word apricot, and assume we‚Äôre\\nusing a window of ¬±2 context words:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nOur goal is to train a classiÔ¨Åer such that, given a tuple (w,c) of a target word\\nw paired with a candidate context word c (for example (apricot, jam), or perhaps\\n(apricot, aardvark)) it will return the probability that c is a real context word (true\\nfor jam, false for aardvark):\\nP(+|w,c)\\n(5.11)\\nThe probability that word c is not a real context word for w is just 1 minus\\nEq. 5.11:\\nP(‚àí|w,c) = 1‚àíP(+|w,c)\\n(5.12)\\nHow does the classiÔ¨Åer compute the probability P? The intuition of the skip-\\ngram model is to base this probability on embedding similarity: a word is likely to'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 11}, page_content='12\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\noccur near the target if its embedding vector is similar to the target embedding. To\\ncompute similarity between these dense embeddings, we rely on the intuition that\\ntwo vectors are similar if they have a high dot product (after all, cosine is just a\\nnormalized dot product). In other words:\\nSimilarity(w,c) ‚âàc¬∑w\\n(5.13)\\nThe dot product c ¬∑ w is not a probability, it‚Äôs just a number ranging from ‚àí‚àûto ‚àû\\n(since the elements in word2vec embeddings can be negative, the dot product can be\\nnegative). To turn the dot product into a probability, we‚Äôll use the logistic or sigmoid\\nfunction œÉ(x), the fundamental core of logistic regression:\\nœÉ(x) =\\n1\\n1+exp(‚àíx)\\n(5.14)\\nWe model the probability that word c is a real context word for target word w as:\\nP(+|w,c) = œÉ(c¬∑w) =\\n1\\n1+exp(‚àíc¬∑w)\\n(5.15)\\nThe sigmoid function returns a number between 0 and 1, but to make it a probability\\nwe‚Äôll also need the total probability of the two possible events (c is a context word,\\nand c isn‚Äôt a context word) to sum to 1. We thus estimate the probability that word c\\nis not a real context word for w as:\\nP(‚àí|w,c) = 1‚àíP(+|w,c)\\n= œÉ(‚àíc¬∑w) =\\n1\\n1+exp(c¬∑w)\\n(5.16)\\nEquation 5.15 gives us the probability for one word, but there are many context\\nwords in the window. Skip-gram makes the simplifying assumption that all context\\nwords are independent, allowing us to just multiply their probabilities:\\nP(+|w,c1:L) =\\nL\\nY\\ni=1\\nœÉ(ci ¬∑w)\\n(5.17)\\nlogP(+|w,c1:L) =\\nL\\nX\\ni=1\\nlogœÉ(ci ¬∑w)\\n(5.18)\\nIn summary, skip-gram trains a probabilistic classiÔ¨Åer that, given a test target word\\nw and its context window of L words c1:L, assigns a probability based on how similar\\nthis context window is to the target word. The probability is based on applying the\\nlogistic (sigmoid) function to the dot product of the embeddings of the target word\\nwith each context word. To compute this probability, we just need embeddings for\\neach target word and context word in the vocabulary.\\nFig. 5.6 shows the intuition of the parameters we‚Äôll need. Skip-gram actually\\nstores two embeddings for each word, one for the word as a target, and one for the\\nword considered as context. Thus the parameters we need to learn are two matrices\\nW and C, each containing an embedding for every one of the |V| words in the\\nvocabulary V.2 Let‚Äôs now turn to learning these embeddings (which is the real goal\\nof training this classiÔ¨Åer in the Ô¨Årst place).\\n2\\nIn principle the target matrix and the context matrix could use different vocabularies, but we‚Äôll simplify\\nby assuming one shared vocabulary V.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 12}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n13\\n1\\nW\\nC\\naardvark\\nzebra\\nzebra\\naardvark\\napricot\\napricot\\n|V|\\n|V|+1\\n2|V|\\nùúΩ =\\ntarget words\\ncontext & noise\\nwords\\n‚Ä¶\\n‚Ä¶\\n1..d\\n‚Ä¶\\n‚Ä¶\\nFigure 5.6\\nThe embeddings learned by the skipgram model. The algorithm stores two em-\\nbeddings for each word, the target embedding (sometimes called the input embedding) and\\nthe context embedding (sometimes called the output embedding). The parameter Œ∏ that the al-\\ngorithm learns is thus a matrix of 2|V| vectors, each of dimension d, formed by concatenating\\ntwo matrices, the target embeddings W and the context+noise embeddings C.\\n5.5.2\\nLearning skip-gram embeddings\\nThe learning algorithm for skip-gram embeddings takes as input a corpus of text,\\nand a chosen vocabulary size N. It begins by assigning a random embedding vector\\nfor each of the N vocabulary words, and then proceeds to iteratively shift the em-\\nbedding of each word w to be more like the embeddings of words that occur nearby\\nin texts, and less like the embeddings of words that don‚Äôt occur nearby. Let‚Äôs start\\nby considering a single piece of training data:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nThis example has a target word w (apricot), and 4 context words in the L = ¬±2\\nwindow, resulting in 4 positive training instances (on the left below):\\npositive examples +\\nw\\ncpos\\napricot tablespoon\\napricot of\\napricot jam\\napricot a\\nnegative examples -\\nw\\ncneg\\nw\\ncneg\\napricot aardvark apricot seven\\napricot my\\napricot forever\\napricot where\\napricot dear\\napricot coaxial\\napricot if\\nFor training a binary classiÔ¨Åer we also need negative examples. In fact skip-\\ngram with negative sampling (SGNS) uses more negative examples than positive\\nexamples (with the ratio between them set by a parameter k). So for each of these\\n(w,cpos) training instances we‚Äôll create k negative samples, each consisting of the\\ntarget w plus a ‚Äònoise word‚Äô cneg. A noise word is a random word from the lexicon,\\nconstrained not to be the target word w. The table right above shows the setting\\nwhere k = 2, so we‚Äôll have 2 negative examples in the negative training set ‚àífor\\neach positive example w,cpos.\\nThe noise words are chosen according to their weighted unigram probability\\npŒ±(w), where Œ± is a weight. If we were sampling according to unweighted proba-\\nbility P(w), it would mean that with unigram probability P(‚Äúthe‚Äù) we would choose\\nthe word the as a noise word, with unigram probability P(‚Äúaardvark‚Äù) we would\\nchoose aardvark, and so on. But in practice it is common to set Œ± = 0.75, i.e. use'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 13}, page_content='14\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nthe weighting P3\\n4 (w):\\nPŒ±(w) =\\ncount(w)Œ±\\nP\\nw‚Ä≤ count(w‚Ä≤)Œ±\\n(5.19)\\nSetting Œ± = .75 gives better performance because it gives rare noise words slightly\\nhigher probability: for rare words, PŒ±(w) > P(w). To illustrate this intuition, it\\nmight help to work out the probabilities for an example with Œ± = .75 and two events,\\nP(a) = 0.99 and P(b) = 0.01:\\nPŒ±(a) =\\n.99.75\\n.99.75 +.01.75 = 0.97\\nPŒ±(b) =\\n.01.75\\n.99.75 +.01.75 = 0.03\\n(5.20)\\nThus using Œ± = .75 increases the probability of the rare event b from 0.01 to 0.03.\\nGiven the set of positive and negative training instances, and an initial set of\\nembeddings, the goal of the learning algorithm is to adjust those embeddings to\\n‚Ä¢ Maximize the similarity of the target word, context word pairs (w,cpos) drawn\\nfrom the positive examples\\n‚Ä¢ Minimize the similarity of the (w,cneg) pairs from the negative examples.\\nIf we consider one word/context pair (w,cpos) with its k noise words cneg1...cnegk,\\nwe can express these two goals as the following loss function L to be minimized\\n(hence the ‚àí); here the Ô¨Årst term expresses that we want the classiÔ¨Åer to assign the\\nreal context word cpos a high probability of being a neighbor, and the second term\\nexpresses that we want to assign each of the noise words cnegi a high probability of\\nbeing a non-neighbor, all multiplied because we assume independence:\\nL = ‚àílog\\n\"\\nP(+|w,cpos)\\nkY\\ni=1\\nP(‚àí|w,cnegi)\\n#\\n= ‚àí\\n\"\\nlogP(+|w,cpos)+\\nk\\nX\\ni=1\\nlogP(‚àí|w,cnegi)\\n#\\n= ‚àí\\n\"\\nlogP(+|w,cpos)+\\nk\\nX\\ni=1\\nlog\\n\\x001‚àíP(+|w,cnegi)\\n\\x01\\n#\\n= ‚àí\\n\"\\nlogœÉ(cpos ¬∑w)+\\nk\\nX\\ni=1\\nlogœÉ(‚àícnegi ¬∑w)\\n#\\n(5.21)\\nThat is, we want to maximize the dot product of the word with the actual context\\nwords, and minimize the dot products of the word with the k negative sampled non-\\nneighbor words.\\nWe minimize this loss function using stochastic gradient descent. Fig. 5.7 shows\\nthe intuition of one step of learning.\\nTo get the gradient, we need to take the derivative of Eq. 5.21 with respect to\\nthe different embeddings. It turns out the derivatives are the following (we leave the'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 14}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n15\\nW\\nC\\nmove apricot and jam closer,\\nincreasing cpos z w\\naardvark\\nmove apricot and matrix apart\\ndecreasing cneg1 z w\\n‚Äú‚Ä¶apricot jam‚Ä¶‚Äù\\nw\\nzebra\\nzebra\\naardvark\\njam\\napricot\\ncpos\\nmatrix\\nTolstoy\\nmove apricot and Tolstoy apart\\ndecreasing cneg2 z w\\n!\\ncneg1\\ncneg2\\nk=2\\nFigure 5.7\\nIntuition of one step of gradient descent. The skip-gram model tries to shift em-\\nbeddings so the target embeddings (here for apricot) are closer to (have a higher dot product\\nwith) context embeddings for nearby words (here jam) and further from (lower dot product\\nwith) context embeddings for noise words that don‚Äôt occur nearby (here Tolstoy and matrix).\\nproof as an exercise at the end of the chapter):\\n‚àÇL\\n‚àÇcpos\\n= [œÉ(cpos ¬∑w)‚àí1]w\\n(5.22)\\n‚àÇL\\n‚àÇcneg\\n= [œÉ(cneg ¬∑w)]w\\n(5.23)\\n‚àÇL\\n‚àÇw = [œÉ(cpos ¬∑w)‚àí1]cpos +\\nk\\nX\\ni=1\\n[œÉ(cnegi ¬∑w)]cnegi\\n(5.24)\\nThe update equations going from time step t to t + 1 in stochastic gradient descent\\nare thus:\\nct+1\\npos\\n= ct\\npos ‚àíŒ∑[œÉ(ct\\npos ¬∑wt)‚àí1]wt\\n(5.25)\\nct+1\\nneg = ct\\nneg ‚àíŒ∑[œÉ(ct\\nneg ¬∑wt)]wt\\n(5.26)\\nwt+1 = wt ‚àíŒ∑\\n\"\\n[œÉ(ct\\npos ¬∑wt)‚àí1]ct\\npos +\\nk\\nX\\ni=1\\n[œÉ(ct\\nnegi ¬∑wt)]ct\\nnegi\\n#\\n(5.27)\\nJust as in logistic regression, then, the learning algorithm starts with randomly ini-\\ntialized W and C matrices, and then walks through the training corpus using gradient\\ndescent to move W and C so as to minimize the loss in Eq. 5.21 by making the up-\\ndates in (Eq. 5.25)-(Eq. 5.27).\\nRecall that the skip-gram model learns two separate embeddings for each word i:\\nthe target embedding wi and the context embedding ci, stored in two matrices, the\\ntarget\\nembedding\\ncontext\\nembedding\\ntarget matrix W and the context matrix C. It‚Äôs common to just add them together,\\nrepresenting word i with the vector wi +ci. Alternatively we can throw away the C\\nmatrix and just represent each word i by the vector wi.\\nAs with the simple count-based methods like tf-idf, the context window size L\\naffects the performance of skip-gram embeddings, and experiments often tune the\\nparameter L on a devset.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 15}, page_content='16\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n5.5.3\\nOther kinds of static embeddings\\nThere are many kinds of static embeddings. An extension of word2vec, fasttext\\nfasttext\\n(Bojanowski et al., 2017), addresses a problem with word2vec as we have presented\\nit so far: it has no good way to deal with unknown words‚Äîwords that appear in\\na test corpus but were unseen in the training corpus. A related problem is word\\nsparsity, such as in languages with rich morphology, where some of the many forms\\nfor each noun and verb may only occur rarely. Fasttext deals with these problems\\nby using subword models, representing each word as itself plus a bag of constituent\\nn-grams, with special boundary symbols < and > added to each word. For example,\\nwith n = 3 the word where would be represented by the sequence <where> plus the\\ncharacter n-grams:\\n<wh, whe, her, ere, re>\\nThen a skipgram embedding is learned for each constituent n-gram, and the word\\nwhere is represented by the sum of all of the embeddings of its constituent n-grams.\\nUnknown words can then be presented only by the sum of the constituent n-grams.\\nA fasttext open-source library, including pretrained embeddings for 157 languages,\\nis available at https://fasttext.cc.\\nAnother very widely used static embedding model is GloVe (Pennington et al.,\\n2014), short for Global Vectors, because the model is based on capturing global\\ncorpus statistics. GloVe is based on ratios of probabilities from the word-word co-\\noccurrence matrix.\\nIt turns out that dense embeddings like word2vec actually have an elegant math-\\nematical relationship with count-based embeddings, in which word2vec can be seen\\nas implicitly optimizing a function of a count matrix with a particular (PPMI) weight-\\ning (Levy and Goldberg, 2014c).\\n5.6\\nVisualizing Embeddings\\n‚ÄúI see well in many dimensions as long as the dimensions are around two.‚Äù\\nThe late economist Martin Shubik\\nVisualizing embeddings is an important goal in helping understand, apply, and\\nimprove these models of word meaning. But how can we visualize a (for example)\\n100-dimensional vector?\\nWRIST\\nANKLE\\nSHOULDER\\nARM\\nLEG\\nHAND\\nFOOT\\nHEAD\\nNOSE\\nFINGER\\nTOE\\nFACE\\nEAR\\nEYE\\nTOOTH\\nDOG\\nCAT\\nPUPPY\\nKITTEN\\nCOW\\nMOUSE\\nTURTLE\\nOYSTER\\nLION\\nBULL\\nCHICAGO\\nATLANTA\\nMONTREAL\\nNASHVILLE\\nTOKYO\\nCHINA\\nRUSSIA\\nAFRICA\\nASIA\\nEUROPE\\nAMERICA\\nBRAZIL\\nMOSCOW\\nFRANCE\\nHAWAII\\nThe simplest way to visualize the meaning of a word\\nw embedded in a space is to list the most similar words to\\nw by sorting the vectors for all words in the vocabulary by\\ntheir cosine with the vector for w. For example the 7 closest\\nwords to frog using a particular embeddings computed with\\nthe GloVe algorithm are: frogs, toad, litoria, leptodactyli-\\ndae, rana, lizard, and eleutherodactylus (Pennington et al.,\\n2014).\\nYet another visualization method is to use a clustering\\nalgorithm to show a hierarchical representation of which\\nwords are similar to others in the embedding space. The\\nuncaptioned Ô¨Ågure on the left uses hierarchical clustering\\nof some embedding vectors for nouns as a visualization\\nmethod (Rohde et al., 2006).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 16}, page_content='5.7\\n‚Ä¢\\nSEMANTIC PROPERTIES OF EMBEDDINGS\\n17\\nProbably the most common visualization method, how-\\never, is to project the 100 dimensions of a word down into 2\\ndimensions. Fig. 5.1 showed one such visualization, as does\\nFig. 5.9, using a projection method called t-SNE (van der\\nMaaten and Hinton, 2008).\\n5.7\\nSemantic properties of embeddings\\nIn this section we brieÔ¨Çy summarize some of the semantic properties of embeddings\\nthat have been studied.\\nDifferent types of similarity or association:\\nOne parameter of vector semantic\\nmodels that is relevant to both sparse PPMI vectors and dense word2vec vectors is\\nthe size of the context window used to collect counts. This is generally between 1\\nand 10 words on each side of the target word (for a total context of 2-20 words).\\nThe choice depends on the goals of the representation. Shorter context windows\\ntend to lead to representations that are a bit more syntactic, since the information is\\ncoming from immediately nearby words. When the vectors are computed from short\\ncontext windows, the most similar words to a target word w tend to be semantically\\nsimilar words with the same parts of speech. When vectors are computed from long\\ncontext windows, the highest cosine words to a target word w tend to be words that\\nare topically related but not similar.\\nFor example Levy and Goldberg (2014a) showed that using skip-gram with a\\nwindow of ¬±2, the most similar words to the word Hogwarts (from the Harry Potter\\nseries) were names of other Ô¨Åctional schools: Sunnydale (from Buffy the Vampire\\nSlayer) or Evernight (from a vampire series). With a window of ¬±5, the most similar\\nwords to Hogwarts were other words topically related to the Harry Potter series:\\nDumbledore, Malfoy, and half-blood.\\nIt‚Äôs also often useful to distinguish two kinds of similarity or association between\\nwords (Sch¬®utze and Pedersen, 1993). Two words have Ô¨Årst-order co-occurrence\\nÔ¨Årst-order\\nco-occurrence\\n(sometimes called syntagmatic association) if they are typically nearby each other.\\nThus wrote is a Ô¨Årst-order associate of book or poem. Two words have second-order\\nco-occurrence (sometimes called paradigmatic association) if they have similar\\nsecond-order\\nco-occurrence\\nneighbors. Thus wrote is a second-order associate of words like said or remarked.\\nAnalogy/Relational Similarity:\\nAnother semantic property of embeddings is their\\nability to capture relational meanings. In an important early vector space model of\\ncognition, Rumelhart and Abrahamson (1973) proposed the parallelogram model\\nparallelogram\\nmodel\\nfor solving simple analogy problems of the form a is to b as a* is to what?. In such\\nproblems, a system is given a problem like apple:tree::grape:?, i.e., apple is to tree\\nas grape is to\\n, and must Ô¨Åll in the word vine. In the parallelogram model, il-\\nlustrated in Fig. 5.8, the vector from the word apple to the word tree (= #   ¬ª\\ntree‚àí#       ¬ª\\napple)\\nis added to the vector for grape (#        ¬ª\\ngrape); the nearest word to that point is returned.\\nIn early work with sparse embeddings, scholars showed that sparse vector mod-\\nels of meaning could solve such analogy problems (Turney and Littman, 2005),\\nbut the parallelogram method received more modern attention because of its suc-\\ncess with word2vec or GloVe vectors (Mikolov et al. 2013c, Levy and Goldberg\\n2014b, Pennington et al. 2014). For example, the result of the expression #     ¬ª\\nking ‚àí\\n#     ¬ª\\nman + #            ¬ª\\nwoman is a vector close to #         ¬ª\\nqueen. Similarly, #      ¬ª\\nParis ‚àí#           ¬ª\\nFrance + #     ¬ª\\nItaly results\\nin a vector that is close to #         ¬ª\\nRome. The embedding model thus seems to be extract-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 17}, page_content='18\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\ntree\\napple\\ngrape\\nvine\\nFigure 5.8\\nThe parallelogram model for analogy problems (Rumelhart and Abrahamson,\\n1973): the location of #     ¬ª\\nvine can be found by subtracting #       ¬ª\\napple from #   ¬ª\\ntree and adding #       ¬ª\\ngrape.\\ning representations of relations like MALE-FEMALE, or CAPITAL-CITY-OF, or even\\nCOMPARATIVE/SUPERLATIVE, as shown in Fig. 5.9 from GloVe.\\n(a)\\n(b)\\nFigure 5.9\\nRelational properties of the GloVe vector space, shown by projecting vectors onto two dimensions.\\n(a) #     ¬ª\\nking‚àí#     ¬ª\\nman+ #            ¬ª\\nwoman is close to #        ¬ª\\nqueen. (b) offsets seem to capture comparative and superlative morphology\\n(Pennington et al., 2014).\\nFor a a : b :: a‚àó: b‚àóproblem, meaning the algorithm is given vectors a, b, and\\na‚àóand must Ô¨Ånd b‚àó, the parallelogram method is thus:\\nÀÜb‚àó= argmin\\nx\\ndistance(x,b‚àía+a‚àó)\\n(5.28)\\nwith some distance function, such as Euclidean distance.\\nThere are some caveats. For example, the closest value returned by the paral-\\nlelogram algorithm in word2vec or GloVe embedding spaces is usually not in fact\\nb* but one of the 3 input words or their morphological variants (i.e., cherry:red ::\\npotato:x returns potato or potatoes instead of brown), so these must be explicitly\\nexcluded. Furthermore while embedding spaces perform well if the task involves\\nfrequent words, small distances, and certain relations (like relating countries with\\ntheir capitals or verbs/nouns with their inÔ¨Çected forms), the parallelogram method\\nwith embeddings doesn‚Äôt work as well for other relations (Linzen 2016, Gladkova\\net al. 2016, Schluter 2018, Ethayarajh et al. 2019a), and indeed Peterson et al. (2020)\\nargue that the parallelogram method is in general too simple to model the human\\ncognitive process of forming analogies of this kind.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 18}, page_content='5.8\\n‚Ä¢\\nBIAS AND EMBEDDINGS\\n19\\n5.7.1\\nEmbeddings and Historical Semantics\\nEmbeddings can also be a useful tool for studying how meaning changes over time,\\nby computing multiple embedding spaces, each from texts written in a particular\\ntime period. For example Fig. 5.10 shows a visualization of changes in meaning in\\nEnglish words over the last two centuries, computed by building separate embedding\\nspaces for each decade from historical corpora like Google n-grams (Lin et al., 2012)\\nand the Corpus of Historical American English (Davies, 2012).\\nFigure 5.10\\nA t-SNE visualization of the semantic change of 3 words in English using\\nword2vec vectors. The modern sense of each word, and the grey context words, are com-\\nputed from the most recent (modern) time-point embedding space. Earlier points are com-\\nputed from earlier historical embedding spaces. The visualizations show the changes in the\\nword gay from meanings related to ‚Äúcheerful‚Äù or ‚Äúfrolicsome‚Äù to referring to homosexuality,\\nthe development of the modern ‚Äútransmission‚Äù sense of broadcast from its original sense of\\nsowing seeds, and the pejoration of the word awful as it shifted from meaning ‚Äúfull of awe‚Äù\\nto meaning ‚Äúterrible or appalling‚Äù (Hamilton et al., 2016).\\n5.8\\nBias and Embeddings\\nIn addition to their ability to learn word meaning from text, embeddings, alas,\\nalso reproduce the implicit biases and stereotypes that were latent in the text. As\\nthe prior section just showed, embeddings can roughly model relational similar-\\nity: ‚Äòqueen‚Äô as the closest word to ‚Äòking‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô implies the analogy\\nman:woman::king:queen. But these same embedding analogies also exhibit gender\\nstereotypes. For example Bolukbasi et al. (2016) Ô¨Ånd that the closest occupation\\nto ‚Äòcomputer programmer‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô in word2vec embeddings trained on\\nnews text is ‚Äòhomemaker‚Äô, and that the embeddings similarly suggest the analogy\\n‚Äòfather‚Äô is to ‚Äòdoctor‚Äô as ‚Äòmother‚Äô is to ‚Äònurse‚Äô. This could result in what Crawford\\n(2017) and Blodgett et al. (2020) call an allocational harm, when a system allo-\\nallocational\\nharm\\ncates resources (jobs or credit) unfairly to different groups. For example algorithms\\nthat use embeddings as part of a search for hiring potential programmers or doctors\\nmight thus incorrectly downweight documents with women‚Äôs names.\\nIt turns out that embeddings don‚Äôt just reÔ¨Çect the statistics of their input, but also\\namplify bias; gendered terms become more gendered in embedding space than they\\nbias\\nampliÔ¨Åcation\\nwere in the input text statistics (Zhao et al. 2017, Ethayarajh et al. 2019b, Jia et al.\\n2020), and biases are more exaggerated than in actual labor employment statistics\\n(Garg et al., 2018).\\nEmbeddings also encode the implicit associations that are a property of human\\nreasoning. The Implicit Association Test (Greenwald et al., 1998) measures peo-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 19}, page_content='20\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nple‚Äôs associations between concepts (like ‚ÄòÔ¨Çowers‚Äô or ‚Äòinsects‚Äô) and attributes (like\\n‚Äòpleasantness‚Äô and ‚Äòunpleasantness‚Äô) by measuring differences in the latency with\\nwhich they label words in the various categories.3 Using such methods, people\\nin the United States have been shown to associate African-American names with\\nunpleasant words (more than European-American names), male names more with\\nmathematics and female names with the arts, and old people‚Äôs names with unpleas-\\nant words (Greenwald et al. 1998, Nosek et al. 2002a, Nosek et al. 2002b). Caliskan\\net al. (2017) replicated all these Ô¨Åndings of implicit associations using GloVe vectors\\nand cosine similarity instead of human latencies. For example African-American\\nnames like ‚ÄòLeroy‚Äô and ‚ÄòShaniqua‚Äô had a higher GloVe cosine with unpleasant words\\nwhile European-American names (‚ÄòBrad‚Äô, ‚ÄòGreg‚Äô, ‚ÄòCourtney‚Äô) had a higher cosine\\nwith pleasant words. These problems with embeddings are an example of a repre-\\nsentational harm (Crawford 2017, Blodgett et al. 2020), which is a harm caused by\\nrepresentational\\nharm\\na system demeaning or even ignoring some social groups. Any embedding-aware al-\\ngorithm that made use of word sentiment could thus exacerbate bias against African\\nAmericans.\\nRecent research focuses on ways to try to remove these kinds of biases, for\\nexample by developing a transformation of the embedding space that removes gen-\\nder stereotypes but preserves deÔ¨Ånitional gender (Bolukbasi et al. 2016, Zhao et al.\\n2017) or changing the training procedure (Zhao et al., 2018). However, although\\nthese sorts of debiasing may reduce bias in embeddings, they do not eliminate it\\ndebiasing\\n(Gonen and Goldberg, 2019), and this remains an open problem.\\nHistorical embeddings are also being used to measure biases in the past. Garg\\net al. (2018) used embeddings from historical texts to measure the association be-\\ntween embeddings for occupations and embeddings for names of various ethnici-\\nties or genders (for example the relative cosine similarity of women‚Äôs names versus\\nmen‚Äôs to occupation words like ‚Äòlibrarian‚Äô or ‚Äòcarpenter‚Äô) across the 20th century.\\nThey found that the cosines correlate with the empirical historical percentages of\\nwomen or ethnic groups in those occupations. Historical embeddings also repli-\\ncated old surveys of ethnic stereotypes; the tendency of experimental participants in\\n1933 to associate adjectives like ‚Äòindustrious‚Äô or ‚Äòsuperstitious‚Äô with, e.g., Chinese\\nethnicity, correlates with the cosine between Chinese last names and those adjectives\\nusing embeddings trained on 1930s text. They also were able to document historical\\ngender biases, such as the fact that embeddings for adjectives related to competence\\n(‚Äòsmart‚Äô, ‚Äòwise‚Äô, ‚Äòthoughtful‚Äô, ‚Äòresourceful‚Äô) had a higher cosine with male than fe-\\nmale words, and showed that this bias has been slowly decreasing since 1960. We\\nreturn in later chapters to this question about the role of bias in natural language\\nprocessing.\\n5.9\\nEvaluating Vector Models\\nThe most important evaluation metric for vector models is extrinsic evaluation on\\ntasks, i.e., using vectors in an NLP task and seeing whether this improves perfor-\\nmance over some other model.\\n3\\nRoughly speaking, if humans associate ‚ÄòÔ¨Çowers‚Äô with ‚Äòpleasantness‚Äô and ‚Äòinsects‚Äô with ‚Äòunpleasant-\\nness‚Äô, when they are instructed to push a green button for ‚ÄòÔ¨Çowers‚Äô (daisy, iris, lilac) and ‚Äòpleasant words‚Äô\\n(love, laughter, pleasure) and a red button for ‚Äòinsects‚Äô (Ô¨Çea, spider, mosquito) and ‚Äòunpleasant words‚Äô\\n(abuse, hatred, ugly) they are faster than in an incongruous condition where they push a red button for\\n‚ÄòÔ¨Çowers‚Äô and ‚Äòunpleasant words‚Äô and a green button for ‚Äòinsects‚Äô and ‚Äòpleasant words‚Äô.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 20}, page_content='5.10\\n‚Ä¢\\nSUMMARY\\n21\\nNonetheless it is useful to have intrinsic evaluations. The most common metric\\nis to test their performance on similarity, computing the correlation between an\\nalgorithm‚Äôs word similarity scores and word similarity ratings assigned by humans.\\nWordSim-353 (Finkelstein et al., 2002) is a commonly used set of ratings from 0\\nto 10 for 353 noun pairs; for example (plane, car) had an average score of 5.77.\\nSimLex-999 (Hill et al., 2015) is a more complex dataset that quantiÔ¨Åes similarity\\n(cup, mug) rather than relatedness (cup, coffee), and includes concrete and abstract\\nadjective, noun and verb pairs. The TOEFL dataset is a set of 80 questions, each\\nconsisting of a target word with 4 additional word choices; the task is to choose\\nwhich is the correct synonym, as in the example: Levied is closest in meaning to:\\nimposed, believed, requested, correlated (Landauer and Dumais, 1997). All of these\\ndatasets present words without context.\\nSlightly more realistic are intrinsic similarity tasks that include context. The\\nStanford Contextual Word Similarity (SCWS) dataset (Huang et al., 2012) and the\\nWord-in-Context (WiC) dataset (Pilehvar and Camacho-Collados, 2019) offer richer\\nevaluation scenarios. SCWS gives human judgments on 2,003 pairs of words in\\ntheir sentential context, while WiC gives target words in two sentential contexts that\\nare either in the same or different senses; see Appendix G. The semantic textual\\nsimilarity task (Agirre et al. 2012, Agirre et al. 2015) evaluates the performance of\\nsentence-level similarity algorithms, consisting of a set of pairs of sentences, each\\npair with human-labeled similarity scores.\\nAnother task used for evaluation is the analogy task, discussed on page 17, where\\nthe system has to solve problems of the form a is to b as a* is to b*, given a, b, and a*\\nand having to Ô¨Ånd b* (Turney and Littman, 2005). A number of sets of tuples have\\nbeen created for this task (Mikolov et al. 2013a, Mikolov et al. 2013c, Gladkova\\net al. 2016), covering morphology (city:cities::child:children), lexicographic rela-\\ntions (leg:table::spout:teapot) and encyclopedia relations (Beijing:China::Dublin:Ireland),\\nsome drawing from the SemEval-2012 Task 2 dataset of 79 different relations (Jur-\\ngens et al., 2012).\\nAll embedding algorithms suffer from inherent variability. For example because\\nof randomness in the initialization and the random negative sampling, algorithms\\nlike word2vec may produce different results even from the same dataset, and in-\\ndividual documents in a collection may strongly impact the resulting embeddings\\n(Tian et al. 2016, Hellrich and Hahn 2016, Antoniak and Mimno 2018). When em-\\nbeddings are used to study word associations in particular corpora, therefore, it is\\nbest practice to train multiple embeddings with bootstrap sampling over documents\\nand average the results (Antoniak and Mimno, 2018).\\n5.10\\nSummary\\n‚Ä¢ In vector semantics, a word is modeled as a vector‚Äîa point in high-dimensional\\nspace, also called an embedding. In this chapter we focus on static embed-\\ndings, where each word is mapped to a Ô¨Åxed embedding.\\n‚Ä¢ Vector semantic models fall into two classes: sparse and dense. In sparse\\nmodels each dimension corresponds to a word in the vocabulary V and cells\\nare functions of co-occurrence counts. The word-context or term-term ma-\\ntrix has a row for each (target) word in the vocabulary and a column for each\\ncontext term in the vocabulary.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 21}, page_content='22\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n‚Ä¢ Dense vector models typically have dimensionality 50‚Äì1000. Word2vec al-\\ngorithms like skip-gram are a popular way to compute dense embeddings.\\nSkip-gram trains a logistic regression classiÔ¨Åer to compute the probability that\\ntwo words are ‚Äòlikely to occur nearby in text‚Äô. This probability is computed\\nfrom the dot product between the embeddings for the two words.\\n‚Ä¢ Skip-gram uses stochastic gradient descent to train the classiÔ¨Åer, by learning\\nembeddings that have a high dot product with embeddings of words that occur\\nnearby and a low dot product with noise words.\\n‚Ä¢ Other important embedding algorithms include GloVe, a method based on\\nratios of word co-occurrence probabilities.\\n‚Ä¢ Whether using sparse or dense vectors, word and document similarities are\\ncomputed by some function of the dot product between vectors. The cosine\\nof two vectors‚Äîa normalized dot product‚Äîis the most popular such metric.\\nHistorical Notes\\nThe idea of vector semantics arose out of research in the 1950s in three distinct\\nÔ¨Åelds: linguistics, psychology, and computer science, each of which contributed a\\nfundamental aspect of the model.\\nThe idea that meaning is related to the distribution of words in context was\\nwidespread in linguistic theory of the 1950s, among distributionalists like Zellig\\nHarris, Martin Joos, and J. R. Firth, and semioticians like Thomas Sebeok. As Joos\\n(1950) put it,\\nthe linguist‚Äôs ‚Äúmeaning‚Äù of a morpheme. . . is by deÔ¨Ånition the set of conditional\\nprobabilities of its occurrence in context with all other morphemes.\\nThe idea that the meaning of a word might be modeled as a point in a multi-\\ndimensional semantic space came from psychologists like Charles E. Osgood, who\\nhad been studying how people responded to the meaning of words by assigning val-\\nues along scales like happy/sad or hard/soft. Osgood et al. (1957) proposed that the\\nmeaning of a word in general could be modeled as a point in a multidimensional\\nEuclidean space, and that the similarity of meaning between two words could be\\nmodeled as the distance between these points in the space.\\nA Ô¨Ånal intellectual source in the 1950s and early 1960s was the Ô¨Åeld then called\\nmechanical indexing, now known as information retrieval. In what became known\\nmechanical\\nindexing\\nas the vector space model for information retrieval (Salton 1971, Sparck Jones\\n1986), researchers demonstrated new ways to deÔ¨Åne the meaning of words in terms\\nof vectors (Switzer, 1965), and reÔ¨Åned methods for word similarity based on mea-\\nsures of statistical association between words like mutual information (Giuliano,\\n1965) and idf (Sparck Jones, 1972), and showed that the meaning of documents\\ncould be represented in the same vector spaces used for words. Around the same\\ntime, (Cordier, 1965) showed that factor analysis of word association probabilities\\ncould be used to form dense vector representations of words.\\nSome of the philosophical underpinning of the distributional way of thinking\\ncame from the late writings of the philosopher Wittgenstein, who was skeptical of\\nthe possibility of building a completely formal theory of meaning deÔ¨Ånitions for\\neach word. Wittgenstein suggested instead that ‚Äúthe meaning of a word is its use in\\nthe language‚Äù (Wittgenstein, 1953, PI 43). That is, instead of using some logical lan-\\nguage to deÔ¨Åne each word, or drawing on denotations or truth values, Wittgenstein‚Äôs'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 22}, page_content='HISTORICAL NOTES\\n23\\nidea is that we should deÔ¨Åne a word by how it is used by people in speaking and un-\\nderstanding in their day-to-day interactions, thus preÔ¨Åguring the movement toward\\nembodied and experiential models in linguistics and NLP (Glenberg and Robertson\\n2000, Lake and Murphy 2021, Bisk et al. 2020, Bender and Koller 2020).\\nMore distantly related is the idea of deÔ¨Åning words by a vector of discrete fea-\\ntures, which has roots at least as far back as Descartes and Leibniz (Wierzbicka 1992,\\nWierzbicka 1996). By the middle of the 20th century, beginning with the work of\\nHjelmslev (Hjelmslev, 1969) (originally 1943) and Ô¨Çeshed out in early models of\\ngenerative grammar (Katz and Fodor, 1963), the idea arose of representing mean-\\ning with semantic features, symbols that represent some sort of primitive meaning.\\nsemantic\\nfeature\\nFor example words like hen, rooster, or chick, have something in common (they all\\ndescribe chickens) and something different (their age and sex), representable as:\\nhen\\n+female, +chicken, +adult\\nrooster -female, +chicken, +adult\\nchick\\n+chicken, -adult\\nThe dimensions used by vector models of meaning to deÔ¨Åne words, however, are\\nonly abstractly related to this idea of a small Ô¨Åxed number of hand-built dimensions.\\nNonetheless, there has been some attempt to show that certain dimensions of em-\\nbedding models do contribute some speciÔ¨Åc compositional aspect of meaning like\\nthese early semantic features.\\nThe use of dense vectors to model word meaning, and indeed the term embed-\\nding, grew out of the latent semantic indexing (LSI) model (Deerwester et al.,\\n1988) recast as LSA (latent semantic analysis) (Deerwester et al., 1990). In LSA\\nsingular value decomposition‚ÄîSVD‚Äî is applied to a term-document matrix (each\\nSVD\\ncell weighted by log frequency and normalized by entropy), and then the Ô¨Årst 300\\ndimensions are used as the LSA embedding. Singular Value Decomposition (SVD)\\nis a method for Ô¨Ånding the most important dimensions of a data set, those dimen-\\nsions along which the data varies the most. LSA was then quickly widely applied:\\nas a cognitive model (Landauer and Dumais, 1997), and for tasks like spell checking\\n(Jones and Martin, 1997), language modeling (Bellegarda 1997, Coccaro and Ju-\\nrafsky 1998, Bellegarda 2000), morphology induction (Schone and Jurafsky 2000,\\nSchone and Jurafsky 2001b), multiword expressions (MWEs) (Schone and Jurafsky,\\n2001a), and essay grading (Rehder et al., 1998). Related models were simultane-\\nously developed and applied to word sense disambiguation by Sch¬®utze (1992). LSA\\nalso led to the earliest use of embeddings to represent words in a probabilistic clas-\\nsiÔ¨Åer, in the logistic regression document router of Sch¬®utze et al. (1995). The idea of\\nSVD on the term-term matrix (rather than the term-document matrix) as a model of\\nmeaning for NLP was proposed soon after LSA by Sch¬®utze (1992). Sch¬®utze applied\\nthe low-rank (97-dimensional) embeddings produced by SVD to the task of word\\nsense disambiguation, analyzed the resulting semantic space, and also suggested\\npossible techniques like dropping high-order dimensions. See Sch¬®utze (1997).\\nA number of alternative matrix models followed on from the early SVD work,\\nincluding Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 1999), Latent\\nDirichlet Allocation (LDA) (Blei et al., 2003), and Non-negative Matrix Factoriza-\\ntion (NMF) (Lee and Seung, 1999).\\nThe LSA community seems to have Ô¨Årst used the word ‚Äúembedding‚Äù in Landauer\\net al. (1997), in a variant of its mathematical meaning as a mapping from one space\\nor mathematical structure to another. In LSA, the word embedding seems to have\\ndescribed the mapping from the space of sparse count vectors to the latent space of\\nSVD dense vectors. Although the word thus originally meant the mapping from one'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 23}, page_content='24\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nspace to another, it has metonymically shifted to mean the resulting dense vector in\\nthe latent space, and it is in this sense that we currently use the word.\\nBy the next decade, Bengio et al. (2003) and Bengio et al. (2006) showed that\\nneural language models could also be used to develop embeddings as part of the task\\nof word prediction. Collobert and Weston (2007), Collobert and Weston (2008), and\\nCollobert et al. (2011) then demonstrated that embeddings could be used to represent\\nword meanings for a number of NLP tasks. Turian et al. (2010) compared the value\\nof different kinds of embeddings for different NLP tasks. Mikolov et al. (2011)\\nshowed that recurrent neural nets could be used as language models. The idea of\\nsimplifying the hidden layer of these neural net language models to create the skip-\\ngram (and also CBOW) algorithms was proposed by Mikolov et al. (2013a). The\\nnegative sampling training algorithm was proposed in Mikolov et al. (2013b). There\\nare numerous surveys of static embeddings and their parameterizations (Bullinaria\\nand Levy 2007, Bullinaria and Levy 2012, Lapesa and Evert 2014, Kiela and Clark\\n2014, Levy et al. 2015).\\nSee Manning et al. (2008) and Chapter 11 for a deeper understanding of the role\\nof vectors in information retrieval, including how to compare queries with docu-\\nments, more details on tf-idf, and issues of scaling to very large datasets. See Kim\\n(2019) for a clear and comprehensive tutorial on word2vec. Cruse (2004) is a useful\\nintroductory linguistic text on lexical semantics.\\nExercises'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='Exercises\\n25\\nAgirre, E., C. Banea, C. Cardie, D. Cer, M. Diab,\\nA. Gonzalez-Agirre, W. Guo, I. Lopez-Gazpio, M. Mar-\\nitxalar, R. Mihalcea, G. Rigau, L. Uria, and J. Wiebe.\\n2015. SemEval-2015 task 2: Semantic textual similarity,\\nEnglish, Spanish and pilot on interpretability. SemEval-\\n15.\\nAgirre, E., M. Diab, D. Cer, and A. Gonzalez-Agirre. 2012.\\nSemEval-2012 task 6: A pilot on semantic textual simi-\\nlarity. SemEval-12.\\nAntoniak, M. and D. Mimno. 2018. Evaluating the stability\\nof embedding-based word similarities. TACL, 6:107‚Äì119.\\nBellegarda, J. R. 1997. A latent semantic analysis framework\\nfor large-span language modeling. EUROSPEECH.\\nBellegarda, J. R. 2000. Exploiting latent semantic informa-\\ntion in statistical language modeling. Proceedings of the\\nIEEE, 89(8):1279‚Äì1296.\\nBender, E. M. and A. Koller. 2020. Climbing towards NLU:\\nOn meaning, form, and understanding in the age of data.\\nACL.\\nBengio, Y., A. Courville, and P. Vincent. 2013. Represen-\\ntation learning: A review and new perspectives. IEEE\\nTransactions on Pattern Analysis and Machine Intelli-\\ngence, 35(8):1798‚Äì1828.\\nBengio, Y., R. Ducharme, P. Vincent, and C. Jauvin. 2003.\\nA neural probabilistic language model. JMLR, 3:1137‚Äì\\n1155.\\nBengio, Y., H. Schwenk, J.-S. Sen¬¥ecal, F. Morin, and J.-L.\\nGauvain. 2006. Neural probabilistic language models. In\\nInnovations in Machine Learning, 137‚Äì186. Springer.\\nBisk, Y., A. Holtzman, J. Thomason, J. Andreas, Y. Bengio,\\nJ. Chai, M. Lapata, A. Lazaridou, J. May, A. Nisnevich,\\nN. Pinto, and J. Turian. 2020. Experience grounds lan-\\nguage. EMNLP.\\nBlei, D. M., A. Y. Ng, and M. I. Jordan. 2003. Latent Dirich-\\nlet allocation. JMLR, 3(5):993‚Äì1022.\\nBlodgett, S. L., S. Barocas, H. Daum¬¥e III, and H. Wallach.\\n2020. Language (technology) is power: A critical survey\\nof ‚Äúbias‚Äù in NLP. ACL.\\nBojanowski, P., E. Grave, A. Joulin, and T. Mikolov. 2017.\\nEnriching word vectors with subword information. TACL,\\n5:135‚Äì146.\\nBolukbasi, T., K.-W. Chang, J. Zou, V. Saligrama, and A. T.\\nKalai. 2016. Man is to computer programmer as woman\\nis to homemaker? Debiasing word embeddings. NeurIPS.\\nBr¬¥eal, M. 1897. Essai de S¬¥emantique: Science des signiÔ¨Åca-\\ntions. Hachette.\\nBudanitsky, A. and G. Hirst. 2006.\\nEvaluating WordNet-\\nbased measures of lexical semantic relatedness. Compu-\\ntational Linguistics, 32(1):13‚Äì47.\\nBullinaria, J. A. and J. P. Levy. 2007. Extracting seman-\\ntic representations from word co-occurrence statistics:\\nA computational study.\\nBehavior research methods,\\n39(3):510‚Äì526.\\nBullinaria, J. A. and J. P. Levy. 2012. Extracting semantic\\nrepresentations from word co-occurrence statistics: stop-\\nlists, stemming, and SVD. Behavior research methods,\\n44(3):890‚Äì907.\\nCaliskan, A., J. J. Bryson, and A. Narayanan. 2017. Seman-\\ntics derived automatically from language corpora contain\\nhuman-like biases. Science, 356(6334):183‚Äì186.\\nCarlson, G. N. 1977. Reference to kinds in English. Ph.D.\\nthesis, University of Massachusetts, Amherst. Forward.\\nClark, E. 1987. The principle of contrast: A constraint on\\nlanguage acquisition. In B. MacWhinney, ed., Mecha-\\nnisms of language acquisition, 1‚Äì33. LEA.\\nCoccaro, N. and D. Jurafsky. 1998. Towards better integra-\\ntion of semantic predictors in statistical language model-\\ning. ICSLP.\\nCollobert, R. and J. Weston. 2007. Fast semantic extraction\\nusing a novel neural network architecture. ACL.\\nCollobert, R. and J. Weston. 2008. A uniÔ¨Åed architecture for\\nnatural language processing: Deep neural networks with\\nmultitask learning. ICML.\\nCollobert,\\nR.,\\nJ.\\nWeston,\\nL.\\nBottou,\\nM.\\nKarlen,\\nK. Kavukcuoglu, and P. Kuksa. 2011. Natural language\\nprocessing (almost) from scratch. JMLR, 12:2493‚Äì2537.\\nCordier, B. 1965. Factor-analysis of correspondences. COL-\\nING 1965.\\nCrawford, K. 2017.\\nThe trouble with bias.\\nKeynote at\\nNeurIPS.\\nCruse, D. A. 2004. Meaning in Language: an Introduction\\nto Semantics and Pragmatics. Oxford University Press.\\nSecond edition.\\nDavies, M. 2012.\\nExpanding horizons in historical lin-\\nguistics with the 400-million word Corpus of Historical\\nAmerican English. Corpora, 7(2):121‚Äì157.\\nDavies, M. 2015. The Wikipedia Corpus: 4.6 million arti-\\ncles, 1.9 billion words. Adapted from Wikipedia. https:\\n//www.english-corpora.org/wiki/.\\nDeerwester, S. C., S. T. Dumais, G. W. Furnas, R. A. Harsh-\\nman, T. K. Landauer, K. E. Lochbaum, and L. Streeter.\\n1988. Computer information retrieval using latent seman-\\ntic structure: US Patent 4,839,853.\\nDeerwester, S. C., S. T. Dumais, T. K. Landauer, G. W. Fur-\\nnas, and R. A. Harshman. 1990. Indexing by latent se-\\nmantics analysis. JASIS, 41(6):391‚Äì407.\\nEthayarajh, K., D. Duvenaud, and G. Hirst. 2019a. Towards\\nunderstanding linear word analogies. ACL.\\nEthayarajh, K., D. Duvenaud, and G. Hirst. 2019b. Under-\\nstanding undesirable word embedding associations. ACL.\\nFinkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin,\\nZ. Solan, G. Wolfman, and E. Ruppin. 2002.\\nPlacing\\nsearch in context: The concept revisited. ACM Trans-\\nactions on Information Systems, 20(1):116‚Äî-131.\\nFirth, J. R. 1957.\\nA synopsis of linguistic theory 1930‚Äì\\n1955. In Studies in Linguistic Analysis. Philological So-\\nciety. Reprinted in Palmer, F. (ed.) 1968. Selected Papers\\nof J. R. Firth. Longman, Harlow.\\nGarg, N., L. Schiebinger, D. Jurafsky, and J. Zou. 2018.\\nWord embeddings quantify 100 years of gender and eth-\\nnic stereotypes. Proceedings of the National Academy of\\nSciences, 115(16):E3635‚ÄìE3644.\\nGirard, G. 1718. La justesse de la langue franc¬∏oise: ou les\\ndiff¬¥erentes signiÔ¨Åcations des mots qui passent pour syn-\\nonimes. Laurent d‚ÄôHoury, Paris.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='26\\nChapter 5\\n‚Ä¢\\nEmbeddings\\nGiuliano,\\nV. E. 1965.\\nThe interpretation of word\\nassociations.\\nStatistical Association Methods For\\nMechanized\\nDocumentation.\\nSymposium\\nProceed-\\nings.\\nWashington,\\nD.C.,\\nUSA,\\nMarch\\n17,\\n1964.\\nhttps://nvlpubs.nist.gov/nistpubs/Legacy/\\nMP/nbsmiscellaneouspub269.pdf.\\nGladkova, A., A. Drozd, and S. Matsuoka. 2016. Analogy-\\nbased detection of morphological and semantic relations\\nwith word embeddings: what works and what doesn‚Äôt.\\nNAACL Student Research Workshop.\\nGlenberg, A. M. and D. A. Robertson. 2000. Symbol ground-\\ning and meaning: A comparison of high-dimensional and\\nembodied theories of meaning. Journal of memory and\\nlanguage, 43(3):379‚Äì401.\\nGonen, H. and Y. Goldberg. 2019. Lipstick on a pig: Debi-\\nasing methods cover up systematic gender biases in word\\nembeddings but do not remove them. NAACL HLT.\\nGould, S. J. 1980. The Panda‚Äôs Thumb. Penguin Group.\\nGreenwald, A. G., D. E. McGhee, and J. L. K. Schwartz.\\n1998. Measuring individual differences in implicit cogni-\\ntion: the implicit association test. Journal of personality\\nand social psychology, 74(6):1464‚Äì1480.\\nHamilton, W. L., J. Leskovec, and D. Jurafsky. 2016. Di-\\nachronic word embeddings reveal statistical laws of se-\\nmantic change. ACL.\\nHarris, Z. S. 1954. Distributional structure. Word, 10:146‚Äì\\n162.\\nHellrich,\\nJ. and U. Hahn. 2016.\\nBad company‚Äî\\nNeighborhoods in neural embedding spaces considered\\nharmful. COLING.\\nHill, F., R. Reichart, and A. Korhonen. 2015. Simlex-999:\\nEvaluating semantic models with (genuine) similarity es-\\ntimation. Computational Linguistics, 41(4):665‚Äì695.\\nHjelmslev, L. 1969. Prologomena to a Theory of Language.\\nUniversity of Wisconsin Press. Translated by Francis J.\\nWhitÔ¨Åeld; original Danish edition 1943.\\nHofmann, T. 1999. Probabilistic latent semantic indexing.\\nSIGIR-99.\\nHuang, E. H., R. Socher, C. D. Manning, and A. Y. Ng. 2012.\\nImproving word representations via global context and\\nmultiple word prototypes. ACL.\\nJia, S., T. Meng, J. Zhao, and K.-W. Chang. 2020. Mitigat-\\ning gender bias ampliÔ¨Åcation in distribution by posterior\\nregularization. ACL.\\nJones, M. P. and J. H. Martin. 1997. Contextual spelling cor-\\nrection using latent semantic analysis. ANLP.\\nJoos, M. 1950.\\nDescription of language design.\\nJASA,\\n22:701‚Äì708.\\nJurgens, D., S. M. Mohammad, P. Turney, and K. Holyoak.\\n2012. SemEval-2012 task 2: Measuring degrees of rela-\\ntional similarity. *SEM 2012.\\nKatz, J. J. and J. A. Fodor. 1963. The structure of a semantic\\ntheory. Language, 39:170‚Äì210.\\nKiela, D. and S. Clark. 2014. A systematic study of semantic\\nvector space model parameters. EACL 2nd Workshop on\\nContinuous Vector Space Models and their Composition-\\nality (CVSC).\\nKim,\\nE.\\n2019.\\nOptimize\\ncomputational\\nefÔ¨Åciency\\nof skip-gram with negative sampling.\\nhttps://\\naegis4048.github.io/optimize_computational_\\nefficiency_of_skip-gram_with_negative_\\nsampling.\\nLake, B. M. and G. L. Murphy. 2021.\\nWord meaning in\\nminds and machines. Psychological Review. In press.\\nLandauer, T. K. and S. T. Dumais. 1997. A solution to Plato‚Äôs\\nproblem: The Latent Semantic Analysis theory of acqui-\\nsition, induction, and representation of knowledge. Psy-\\nchological Review, 104:211‚Äì240.\\nLandauer, T. K., D. Laham, B. Rehder, and M. E. Schreiner.\\n1997. How well can passage meaning be derived with-\\nout using word order? A comparison of Latent Semantic\\nAnalysis and humans. COGSCI.\\nLapesa, G. and S. Evert. 2014. A large scale evaluation of\\ndistributional semantic models: Parameters, interactions\\nand model selection. TACL, 2:531‚Äì545.\\nLee, D. D. and H. S. Seung. 1999. Learning the parts of\\nobjects by non-negative matrix factorization.\\nNature,\\n401(6755):788‚Äì791.\\nLevy, O. and Y. Goldberg. 2014a. Dependency-based word\\nembeddings. ACL.\\nLevy, O. and Y. Goldberg. 2014b. Linguistic regularities in\\nsparse and explicit word representations. CoNLL.\\nLevy, O. and Y. Goldberg. 2014c. Neural word embedding\\nas implicit matrix factorization. NeurIPS.\\nLevy, O., Y. Goldberg, and I. Dagan. 2015. Improving dis-\\ntributional similarity with lessons learned from word em-\\nbeddings. TACL, 3:211‚Äì225.\\nLin, Y., J.-B. Michel, E. Lieberman Aiden, J. Orwant,\\nW. Brockman, and S. Petrov. 2012. Syntactic annotations\\nfor the Google Books NGram corpus. ACL.\\nLinzen, T. 2016. Issues in evaluating semantic spaces us-\\ning word analogies. 1st Workshop on Evaluating Vector-\\nSpace Representations for NLP.\\nManning, C. D., P. Raghavan, and H. Sch¬®utze. 2008. Intro-\\nduction to Information Retrieval. Cambridge.\\nMikolov, T., K. Chen, G. S. Corrado, and J. Dean. 2013a. Ef-\\nÔ¨Åcient estimation of word representations in vector space.\\nICLR 2013.\\nMikolov, T., S. Kombrink, L. Burget, J. H. ÀáCernock`y, and\\nS. Khudanpur. 2011. Extensions of recurrent neural net-\\nwork language model. ICASSP.\\nMikolov, T., I. Sutskever, K. Chen, G. S. Corrado, and\\nJ. Dean. 2013b. Distributed representations of words and\\nphrases and their compositionality. NeurIPS.\\nMikolov, T., W.-t. Yih, and G. Zweig. 2013c.\\nLinguis-\\ntic regularities in continuous space word representations.\\nNAACL HLT.\\nNosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002a.\\nHarvesting implicit group attitudes and beliefs from a\\ndemonstration web site. Group Dynamics: Theory, Re-\\nsearch, and Practice, 6(1):101.\\nNosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002b.\\nMath=male, me=female, therefore mathÃ∏= me. Journal of\\npersonality and social psychology, 83(1):44.\\nOsgood, C. E., G. J. Suci, and P. H. Tannenbaum. 1957. The\\nMeasurement of Meaning. University of Illinois Press.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'data\\\\embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 26}, page_content='Exercises\\n27\\nPennington, J., R. Socher, and C. D. Manning. 2014. GloVe:\\nGlobal vectors for word representation. EMNLP.\\nPeterson, J. C., D. Chen, and T. L. GrifÔ¨Åths. 2020. Parallelo-\\ngrams revisited: Exploring the limitations of vector space\\nmodels for simple analogies. Cognition, 205.\\nPilehvar, M. T. and J. Camacho-Collados. 2019. WiC: the\\nword-in-context dataset for evaluating context-sensitive\\nmeaning representations. NAACL HLT.\\nRehder, B., M. E. Schreiner, M. B. W. Wolfe, D. Laham,\\nT. K. Landauer, and W. Kintsch. 1998.\\nUsing Latent\\nSemantic Analysis to assess knowledge: Some technical\\nconsiderations. Discourse Processes, 25(2-3):337‚Äì354.\\nRohde, D. L. T., L. M. Gonnerman, and D. C. Plaut. 2006.\\nAn improved model of semantic similarity based on lexi-\\ncal co-occurrence. CACM, 8:627‚Äì633.\\nRumelhart, D. E. and A. A. Abrahamson. 1973. A model for\\nanalogical reasoning. Cognitive Psychology, 5(1):1‚Äì28.\\nSalton, G. 1971. The SMART Retrieval System: Experiments\\nin Automatic Document Processing. Prentice Hall.\\nSchluter, N. 2018. The word analogy testing caveat. NAACL\\nHLT.\\nSchone, P. and D. Jurafsky. 2000. Knowlege-free induction\\nof morphology using latent semantic analysis. CoNLL.\\nSchone, P. and D. Jurafsky. 2001a. Is knowledge-free in-\\nduction of multiword unit dictionary headwords a solved\\nproblem? EMNLP.\\nSchone, P. and D. Jurafsky. 2001b. Knowledge-free induc-\\ntion of inÔ¨Çectional morphologies. NAACL.\\nSch¬®utze, H. 1992. Dimensions of meaning. Proceedings of\\nSupercomputing ‚Äô92. IEEE Press.\\nSch¬®utze, H. 1997. Ambiguity Resolution in Language Learn-\\ning ‚Äì Computational and Cognitive Models. CSLI, Stan-\\nford, CA.\\nSch¬®utze, H., D. A. Hull, and J. Pedersen. 1995. A compar-\\nison of classiÔ¨Åers and document representations for the\\nrouting problem. SIGIR-95.\\nSch¬®utze, H. and J. Pedersen. 1993. A vector model for syn-\\ntagmatic and paradigmatic relatedness. 9th Annual Con-\\nference of the UW Centre for the New OED and Text Re-\\nsearch.\\nSparck Jones, K. 1972. A statistical interpretation of term\\nspeciÔ¨Åcity and its application in retrieval. Journal of Doc-\\numentation, 28(1):11‚Äì21.\\nSparck Jones, K. 1986. Synonymy and Semantic ClassiÔ¨Åca-\\ntion. Edinburgh University Press, Edinburgh. Republica-\\ntion of 1964 PhD Thesis.\\nSwitzer, P. 1965.\\nVector images in document retrieval.\\nStatistical Association Methods For Mechanized Docu-\\nmentation. Symposium Proceedings. Washington, D.C.,\\nUSA, March 17, 1964. https://nvlpubs.nist.gov/\\nnistpubs/Legacy/MP/nbsmiscellaneouspub269.\\npdf.\\nTian, Y., V. Kulkarni, B. Perozzi, and S. Skiena. 2016. On\\nthe convergent properties of word embedding methods.\\nArXiv preprint arXiv:1605.03956.\\nTurian, J., L. Ratinov, and Y. Bengio. 2010. Word represen-\\ntations: a simple and general method for semi-supervised\\nlearning. ACL.\\nTurney, P. D. and M. L. Littman. 2005. Corpus-based learn-\\ning of analogies and semantic relations. Machine Learn-\\ning, 60(1-3):251‚Äì278.\\nvan der Maaten, L. and G. E. Hinton. 2008. Visualizing high-\\ndimensional data using t-SNE. JMLR, 9:2579‚Äì2605.\\nWierzbicka, A. 1992. Semantics, Culture, and Cognition:\\nUniversity Human Concepts in Culture-SpeciÔ¨Åc ConÔ¨Ågu-\\nrations. Oxford University Press.\\nWierzbicka, A. 1996. Semantics: Primes and Universals.\\nOxford University Press.\\nWittgenstein, L. 1953. Philosophical Investigations. (Trans-\\nlated by Anscombe, G.E.M.). Blackwell.\\nZhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-\\nW. Chang. 2017.\\nMen also like shopping: Reducing\\ngender bias ampliÔ¨Åcation using corpus-level constraints.\\nEMNLP.\\nZhao, J., Y. Zhou, Z. Li, W. Wang, and K.-W. Chang. 2018.\\nLearning gender-neutral word embeddings. EMNLP.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader , PyMuPDFLoader\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "dir_loader = DirectoryLoader(\n",
    "    './data',\n",
    "     glob='**/*.pdf',\n",
    "     loader_cls = PyMuPDFLoader,\n",
    "     show_progress = False)\n",
    "\n",
    "pdf_document = dir_loader.load()\n",
    "print(pdf_document)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f36d5f",
   "metadata": {},
   "source": [
    "#### Pdf Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c225ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 0}, page_content='Speech and Language Processing.\\nDaniel Jurafsky & James H. Martin.\\nCopyright ¬© 2025.\\nAll\\nrights reserved.\\nDraft of August 24, 2025.\\nCHAPTER\\n5\\nEmbeddings\\nËçÉËÄÖÊâÄ‰ª•Âú®È±ºÔºåÂæóÈ±ºËÄåÂøòËçÉNets are for Ô¨Åsh;\\nOnce you get the Ô¨Åsh, you can forget the net.\\nË®ÄËÄÖÊâÄ‰ª•Âú®ÊÑèÔºåÂæóÊÑèËÄåÂøòË®ÄWords are for meaning;\\nOnce you get the meaning, you can forget the words\\nÂ∫ÑÂ≠ê(Zhuangzi), Chapter 26\\nThe asphalt that Los Angeles is famous for occurs mainly on its freeways. But\\nin the middle of the city is another patch of asphalt, the La Brea tar pits, and this\\nasphalt preserves millions of fossil bones from the last of the Ice Ages of the Pleis-\\ntocene Epoch. One of these fossils is the Smilodon, or saber-toothed tiger, instantly\\nrecognizable by its long canines. Five million years ago or so, a completely different\\nsaber-tooth tiger called Thylacosmilus lived\\nin Argentina and other parts of South Amer-\\nica. Thylacosmilus was a marsupial whereas\\nSmilodon was a placental mammal, but Thy-\\nlacosmilus had the same long upper canines\\nand, like Smilodon, had a protective bone\\nÔ¨Çange on the lower jaw.\\nThe similarity of\\nthese two mammals is one of many examples\\nof parallel or convergent evolution, in which particular contexts or environments\\nlead to the evolution of very similar structures in different species (Gould, 1980).\\nThe role of context is also important in the similarity of a less biological kind\\nof organism: the word. Words that occur in similar contexts tend to have similar\\nmeanings. This link between similarity in how words are distributed and similarity\\nin what they mean is called the distributional hypothesis. The hypothesis was\\ndistributional\\nhypothesis\\nÔ¨Årst formulated in the 1950s by linguists like Joos (1950), Harris (1954), and Firth\\n(1957), who noticed that words which are synonyms (like oculist and eye-doctor)\\ntended to occur in the same environment (e.g., near words like eye or examined)\\nwith the amount of meaning difference between two words ‚Äúcorresponding roughly\\nto the amount of difference in their environments‚Äù (Harris, 1954, p. 157).\\nIn this chapter we introduce embeddings, vector representations of the meaning\\nembeddings\\nof words that are learned directly from word distributions in texts. Embeddings lie\\nat the heart of large language models and other modern applications. The static em-\\nbeddings we introduce here underlie the more powerful dynamic or contextualized\\nembeddings like BERT that we will see in Chapter 10 and Chapter 8.\\nThe linguistic Ô¨Åeld that studies embeddings and their meanings is called vector\\nsemantics. Embeddings are also the Ô¨Årst example in this book of representation\\nvector\\nsemantics\\nlearning, automatically learning useful representations of the input text. Finding\\nrepresentation\\nlearning\\nsuch self-supervised ways to learn representations of language, instead of creat-\\ning representations by hand via feature engineering, is an important principle of\\nmodern NLP (Bengio et al., 2013).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 1}, page_content='2\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n5.1\\nLexical Semantics\\nLet‚Äôs begin by introducing some basic principles of word meaning. How should\\nwe represent the meaning of a word? In the n-gram models of Chapter 3, and in\\nclassical NLP applications, our only representation of a word is as a string of letters,\\nor an index in a vocabulary list. This representation is not that different from a\\ntradition in philosophy, perhaps you‚Äôve seen it in introductory logic classes, in which\\nthe meaning of words is represented by just spelling the word with small capital\\nletters; representing the meaning of ‚Äúdog‚Äù as DOG, and ‚Äúcat‚Äù as CAT, or by using an\\napostrophe (DOG‚Äô).\\nRepresenting the meaning of a word by capitalizing it is a pretty unsatisfactory\\nmodel. You might have seen a version of a joke due originally to semanticist Barbara\\nPartee (Carlson, 1977):\\nQ: What‚Äôs the meaning of life?\\nA: LIFE‚Äô\\nSurely we can do better than this! After all, we‚Äôll want a model of word meaning\\nto do all sorts of things for us. It should tell us that some words have similar mean-\\nings (cat is similar to dog), others are antonyms (cold is the opposite of hot), some\\nhave positive connotations (happy) while others have negative connotations (sad). It\\nshould represent the fact that the meanings of buy, sell, and pay offer differing per-\\nspectives on the same underlying purchasing event. (If I buy something from you,\\nyou‚Äôve probably sold it to me, and I likely paid you.) More generally, a model of\\nword meaning should allow us to draw inferences to address meaning-related tasks\\nlike question-answering or dialogue.\\nIn this section we summarize some of these desiderata, drawing on results in the\\nlinguistic study of word meaning, which is called lexical semantics; we‚Äôll return to\\nlexical\\nsemantics\\nand expand on this list in Appendix G and Chapter 21.\\nLemmas and Senses\\nLet‚Äôs start by looking at how one word (we‚Äôll choose mouse)\\nmight be deÔ¨Åned in a dictionary (simpliÔ¨Åed from the online dictionary WordNet):\\nmouse (N)\\n1.\\nany of numerous small rodents...\\n2.\\na hand-operated device that controls a cursor...\\nHere the form mouse is the lemma, also called the citation form. The form\\nlemma\\ncitation form\\nmouse would also be the lemma for the word mice; dictionaries don‚Äôt have separate\\ndeÔ¨Ånitions for inÔ¨Çected forms like mice. Similarly sing is the lemma for sing, sang,\\nsung. In many languages the inÔ¨Ånitive form is used as the lemma for the verb, so\\nSpanish dormir ‚Äúto sleep‚Äù is the lemma for duermes ‚Äúyou sleep‚Äù. The speciÔ¨Åc forms\\nsung or carpets or sing or duermes are called wordforms.\\nwordform\\nAs the example above shows, each lemma can have multiple meanings; the\\nlemma mouse can refer to the rodent or the cursor control device. We call each\\nof these aspects of the meaning of mouse a word sense. The fact that lemmas can\\nbe polysemous (have multiple senses) can make interpretation difÔ¨Åcult (is some-\\none who searches for ‚Äúmouse info‚Äù looking for a pet or a widget?). Chapter 10\\nand Appendix G will discuss the problem of polysemy, and introduce word sense\\ndisambiguation, the task of determining which sense of a word is being used in a\\nparticular context.\\nSynonymy\\nOne important component of word meaning is the relationship be-\\ntween word senses. For example when one word has a sense whose meaning is'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 2}, page_content='5.1\\n‚Ä¢\\nLEXICAL SEMANTICS\\n3\\nidentical to a sense of another word, or nearly identical, we say the two senses of\\nthose two words are synonyms. Synonyms include such pairs as\\nsynonym\\ncouch/sofa vomit/throw up Ô¨Ålbert/hazelnut car/automobile\\nA more formal deÔ¨Ånition of synonymy (between words rather than senses) is that\\ntwo words are synonymous if they are substitutable for one another in any sentence\\nwithout changing the truth conditions of the sentence, the situations in which the\\nsentence would be true.\\nWhile substitutions between some pairs of words like car / automobile or wa-\\nter / H2O are truth preserving, the words are still not identical in meaning. Indeed,\\nprobably no two words are absolutely identical in meaning. One of the fundamental\\ntenets of semantics, called the principle of contrast (Girard 1718, Br¬¥eal 1897, Clark\\nprinciple of\\ncontrast\\n1987), states that a difference in linguistic form is always associated with some dif-\\nference in meaning. For example, the word H2O is used in scientiÔ¨Åc contexts and\\nwould be inappropriate in a hiking guide‚Äîwater would be more appropriate‚Äî and\\nthis genre difference is part of the meaning of the word. In practice, the word syn-\\nonym is therefore used to describe a relationship of approximate or rough synonymy.\\nWord Similarity\\nWhile words don‚Äôt have many synonyms, most words do have\\nlots of similar words. Cat is not a synonym of dog, but cats and dogs are certainly\\nsimilar words. In moving from synonymy to similarity, it will be useful to shift from\\ntalking about relations between word senses (like synonymy) to relations between\\nwords (like similarity). Dealing with words avoids having to commit to a particular\\nrepresentation of word senses, which will turn out to simplify our task.\\nThe notion of word similarity is very useful in larger semantic tasks. Knowing\\nsimilarity\\nhow similar two words are can help in computing how similar the meaning of two\\nphrases or sentences are, a very important component of tasks like question answer-\\ning, paraphrasing, and summarization. One way of getting values for word similarity\\nis to ask humans to judge how similar one word is to another. A number of datasets\\nhave resulted from such experiments. For example the SimLex-999 dataset (Hill\\net al., 2015) gives values on a scale from 0 to 10, like the examples below, which\\nrange from near-synonyms (vanish, disappear) to pairs that scarcely seem to have\\nanything in common (hole, agreement):\\nvanish\\ndisappear\\n9.8\\nbelief\\nimpression 5.95\\nmuscle bone\\n3.65\\nmodest Ô¨Çexible\\n0.98\\nhole\\nagreement\\n0.3\\nWord Relatedness\\nThe meaning of two words can be related in ways other than\\nsimilarity. One such class of connections is called word relatedness (Budanitsky\\nrelatedness\\nand Hirst, 2006), also traditionally called word association in psychology.\\nassociation\\nConsider the meanings of the words coffee and cup. Coffee is not similar to cup;\\nthey share practically no features (coffee is a plant or a beverage, while a cup is a\\nmanufactured object with a particular shape). But coffee and cup are clearly related;\\nthey are associated by co-participating in an everyday event (the event of drinking\\ncoffee out of a cup). Similarly scalpel and surgeon are not similar but are related\\neventively (a surgeon tends to make use of a scalpel).\\nOne common kind of relatedness between words is if they belong to the same\\nsemantic Ô¨Åeld. A semantic Ô¨Åeld is a set of words which cover a particular semantic\\nsemantic Ô¨Åeld\\ndomain and bear structured relations with each other. For example, words might be'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 3}, page_content='4\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nrelated by being in the semantic Ô¨Åeld of hospitals (surgeon, scalpel, nurse, anes-\\nthetic, hospital), restaurants (waiter, menu, plate, food, chef), or houses (door, roof,\\nkitchen, family, bed). Semantic Ô¨Åelds are also related to topic models, like Latent\\ntopic models\\nDirichlet Allocation, LDA, which apply unsupervised learning on large sets of texts\\nto induce sets of associated words from text. Semantic Ô¨Åelds and topic models are\\nvery useful tools for discovering topical structure in documents.\\nIn Appendix G we‚Äôll introduce more relations between senses like hypernymy\\nor IS-A, antonymy (opposites) and meronymy (part-whole relations).\\nConnotation\\nFinally, words have affective meanings or connotations. The word\\nconnotations\\nconnotation has different meanings in different Ô¨Åelds, but here we use it to mean the\\naspects of a word‚Äôs meaning that are related to a writer or reader‚Äôs emotions, senti-\\nment, opinions, or evaluations. For example some words have positive connotations\\n(wonderful) while others have negative connotations (dreary). Even words whose\\nmeanings are similar in other ways can vary in connotation; consider the difference\\nin connotations between fake, knockoff, forgery, on the one hand, and copy, replica,\\nreproduction on the other, or innocent (positive connotation) and naive (negative\\nconnotation). Some words describe positive evaluation (great, love) and others neg-\\native evaluation (terrible, hate). Positive or negative evaluation language is called\\nsentiment, as we saw in Appendix K, and word sentiment plays a role in impor-\\nsentiment\\ntant tasks like sentiment analysis, stance detection, and applications of NLP to the\\nlanguage of politics and consumer reviews.\\nEarly work on affective meaning (Osgood et al., 1957) found that words varied\\nalong three important dimensions of affective meaning:\\nvalence: the pleasantness of the stimulus\\narousal: the intensity of emotion provoked by the stimulus\\ndominance: the degree of control exerted by the stimulus\\nThus words like happy or satisÔ¨Åed are high on valence, while unhappy or an-\\nnoyed are low on valence. Excited is high on arousal, while calm is low on arousal.\\nControlling is high on dominance, while awed or inÔ¨Çuenced are low on dominance.\\nEach word is thus represented by three numbers, corresponding to its value on each\\nof the three dimensions:\\nValence Arousal Dominance\\ncourageous 8.0\\n5.5\\n7.4\\nmusic\\n7.7\\n5.6\\n6.5\\nheartbreak\\n2.5\\n5.7\\n3.6\\ncub\\n6.7\\n4.0\\n4.2\\nOsgood et al. (1957) noticed that in using these 3 numbers to represent the\\nmeaning of a word, the model was representing each word as a point in a three-\\ndimensional space, a vector whose three dimensions corresponded to the word‚Äôs\\nrating on the three scales. This revolutionary idea that word meaning could be rep-\\nresented as a point in space (e.g., that part of the meaning of heartbreak can be\\nrepresented as the point [2.5,5.7,3.6]) was the Ô¨Årst expression of the vector seman-\\ntics models that we introduce next.\\n5.2\\nVector Semantics: The Intuition\\nVector semantics is the standard way to represent word meaning in NLP, helping\\nvector\\nsemantics'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 4}, page_content='5.2\\n‚Ä¢\\nVECTOR SEMANTICS: THE INTUITION\\n5\\nus model many of the aspects of word meaning we saw in the previous section. The\\nroots of the model lie in the 1950s when two big ideas converged: Osgood‚Äôs 1957\\nidea mentioned above to use a point in three-dimensional space to represent the\\nconnotation of a word, and the proposal by linguists like Joos (1950), Harris (1954),\\nand Firth (1957) to deÔ¨Åne the meaning of a word by its distribution in language\\nuse, meaning its neighboring words or grammatical environments. Their idea was\\nthat two words that occur in very similar distributions (whose neighboring words are\\nsimilar) have similar meanings.\\nFor example, suppose you didn‚Äôt know the meaning of the word ongchoi (a re-\\ncent borrowing from Cantonese) but you see it in the following contexts:\\n(5.1) Ongchoi is delicious sauteed with garlic.\\n(5.2) Ongchoi is superb over rice.\\n(5.3) ...ongchoi leaves with salty sauces...\\nAnd suppose that you had seen many of these context words in other contexts:\\n(5.4) ...spinach sauteed with garlic over rice...\\n(5.5) ...chard stems and leaves are delicious...\\n(5.6) ...collard greens and other salty leafy greens\\nThe fact that ongchoi occurs with words like rice and garlic and delicious and\\nsalty, as do words like spinach, chard, and collard greens might suggest that ongchoi\\nis a leafy green similar to these other leafy greens.1 We can implement the same\\nintuition computationally by just counting words in the context of ongchoi.\\nFigure 5.1\\nA two-dimensional (t-SNE) visualization of 200-dimensional word2vec em-\\nbeddings for some words close to the word sweet, showing that words with similar mean-\\nings are nearby in space. Visualization created using the TensorBoard Embedding Projector\\nhttps://projector.tensorflow.org/.\\nThe idea of vector semantics is to represent a word as a point in a multidimen-\\nsional semantic space that is derived (in different ways we‚Äôll see) from the distri-\\nbutions of word neighbors. Vectors for representing words are called embeddings.\\nembeddings\\nThe word ‚Äúembedding‚Äù derives historically from its mathematical sense as a map-\\nping from one space or structure to another, although the meaning has shifted; see\\nthe end of the chapter.\\nFig. 5.1 shows a visualization of embeddings learned by the word2vec algorithm,\\nshowing the location of selected words (neighbors of ‚Äúsweet‚Äù) projected down from\\n1\\nIt‚Äôs in fact Ipomoea aquatica, a relative of morning glory sometimes called water spinach in English.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 5}, page_content='6\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n200-dimensional space into a 2-dimensional space. Note that the nearest neighbors\\nof sweet are semantically related words like honey, candy, juice, chocolate. This idea\\nthat similar words are near each other in high-dimensional space is an important\\nthat offers enormous power to language models and other NLP applications. For\\nexample the sentiment classiÔ¨Åers of Chapter 4 depend on the same words appearing\\nin the training and test sets. But by representing words as embeddings, a classiÔ¨Åer\\ncan assign sentiment as long as it sees some words with similar meanings. And as\\nwe‚Äôll see, vector semantic models like the ones showed in Fig. 5.1 can be learned\\nautomatically from text without supervision.\\nIn this chapter we‚Äôll begin with a simple pedagogical model of embeddings in\\nwhich the meaning of a word is deÔ¨Åned by a vector with the counts of nearby words.\\nWe introduce this model as a helpful way to understand the concept of vectors and\\nwhat it means for a vector to be a representation of word meaning, but more sophis-\\nticated variants like the tf-idf model we will introduce in Chapter 11 are important\\nmethods you should understand. We will see that this method results in very long\\nvectors that are sparse, i.e. mostly zeros (since most words simply never occur in the\\ncontext of others). We‚Äôll then introduce the word2vec model family for constructing\\nshort, dense vectors that have even more useful semantic properties.\\nWe‚Äôll also introduce the cosine, the standard way to use embeddings to com-\\npute semantic similarity, between two words, two sentences, or two documents, an\\nimportant tool in practical applications.\\n5.3\\nSimple count-based embeddings\\n‚ÄúThe most important attributes of a vector in 3-space are {Location, Location, Location}‚Äù\\nRandall Munroe, the hover from https://xkcd.com/2358/\\nLet‚Äôs now introduce the Ô¨Årst way to compute word vector embeddings. This sim-\\nplest vector model of meaning is based on the co-occurrence matrix, a way of rep-\\nresenting how often words co-occur. We‚Äôll deÔ¨Åne a particular kind of co-occurrence\\nmatrix, the word-context matrix, in which each row in the matrix represents a word\\nword-context\\nmatrix\\nin the vocabulary and each column represents how often each other word in the vo-\\ncabulary appears nearby. This matrix is thus of dimensionality |V| √ó |V| and each\\ncell records the number of times the row (target) word and the column (context)\\nword co-occur nearby in some training corpus.\\nWhat do we mean by ‚Äònearby‚Äô? We could implement various methods, but let‚Äôs\\nstart with a very simple one: a context window around the word, let‚Äôs say of 4 words\\nto the left and 4 words to the right. If we do that, each cell will represents the\\nnumber of times (in some training corpus) the column word occurs in such a ¬±4\\nword window around the row word.\\nLet‚Äôs see how this works for 4 words: cherry, strawberry, digital, and informa-\\ntion. For each word we took a single instance from a corpus, and we show the ¬±4\\nword window from that instance:\\nis traditionally followed by cherry\\npie, a traditional dessert\\noften mixed, such as strawberry\\nrhubarb pie. Apple pie\\ncomputer peripherals and personal digital\\nassistants. These devices usually\\na computer. This includes information available on the internet\\nIf we then take every occurrence of each word in a large corpus and count the\\ncontext words around it, we get a word-context co-occurrence matrix. The full word-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 6}, page_content='5.3\\n‚Ä¢\\nSIMPLE COUNT-BASED EMBEDDINGS\\n7\\ncontext co-occurrence matrix is very large, because for each word in the vocabulary\\n(since |V|) we have to count how often it occurs with every other word in the vo-\\ncabulary, hence dimensionality |V|√ó|V|. Let‚Äôs therefore instead sketch the process\\non a smaller scale. Imagine that we are going to look at only the 4 words, and only\\nconsider the following 3 context words: a, computer, and pie. Furthermore let‚Äôs\\nassume we only count occurrences in the mini-corpus above.\\nSo before looking at Fig. 5.2, compute by hand the counts for these 3 context\\nwords for the four words cherry, strawberry, digital, and information.\\na\\ncomputer\\npie\\ncherry\\n1\\n0\\n1\\nstrawberry\\n0\\n0\\n2\\ndigital\\n0\\n1\\n0\\ninformation\\n1\\n1\\n0\\nFigure 5.2\\nCo-occurrence vectors for four words with counts from the 4 windows above,\\nshowing just 3 of the potential context word dimensions. The vector for cherry is outlined in\\nred. Note that a real vector would have vastly more dimensions and thus be even sparser.\\nHopefully your count matches what is shown in Fig. 5.2, so that each cell repre-\\nsents the number of times a particular word (deÔ¨Åned by the row) occurs in a partic-\\nular context (deÔ¨Åned by the word column).\\nEach row, then, is a vector representing a word. To review some basic linear\\nalgebra, a vector is, at heart, just a list or array of numbers. So cherry is represented\\nvector\\nas the list [1,0,1] (the Ô¨Årst row vector in Fig. 5.2) and information is represented as\\nthe list [1,1,0] (the fourth row vector).\\nA vector space is a collection of vectors, and is characterized by its dimension.\\nvector space\\ndimension\\nVectors in a 3-dimensional vector space have an element for each dimension of the\\nspace. We will loosely refer to a vector in a 3-dimensional space as a 3-dimensional\\nvector, with one element along each dimension. In the example in Fig. 5.2, we‚Äôve\\nchosen to make the document vectors of dimension 3, just so they Ô¨Åt on the page; in\\nreal term-document matrices, the document vectors would have dimensionality |V|,\\nthe vocabulary size.\\nThe ordering of the numbers in a vector space indicates the different dimensions\\non which documents vary. The third dimension for all these vectors corresponds\\nto the number of times pie occurs in the context. The second dimension for all of\\nthem corresponds to the number of times the word computer occurs. Notice that\\nthe vectors for information and digital have the same value (1) for this ‚Äúcomputer‚Äù\\ndimension.\\nIn reality, we don‚Äôt compute word vectors on a single context window. Instead,\\nwe compute them over an entire corpus. Let‚Äôs see what some real counts look like.\\nLet‚Äôs look at some vectors computed in this way. Fig. 5.3 shows a subset of the\\nword-word co-occurrence matrix for these four words, where, again because it‚Äôs\\nimpossible to visualize all |V| possible context words on the page of this textbook,\\nwe show a subset of 6 of the dimensions, with counts computed from the Wikipedia\\ncorpus (Davies, 2015).\\nNote in Fig. 5.3 that the two words cherry and strawberry are more similar to\\neach other (both pie and sugar tend to occur in their window) than they are to other\\nwords like digital; conversely, digital and information are more similar to each other\\nthan, say, to strawberry.\\nWe can think of the vector for a document as a point in |V|-dimensional space;\\nthus the documents in Fig. 5.3 are points in 3-dimensional space. Fig. 5.4 shows a\\nspatial visualization.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 7}, page_content='8\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\naardvark\\n...\\ncomputer\\ndata\\nresult\\npie\\nsugar\\n...\\ncherry\\n0\\n...\\n2\\n8\\n9\\n442\\n25\\n...\\nstrawberry\\n0\\n...\\n0\\n0\\n1\\n60\\n19\\n...\\ndigital\\n0\\n...\\n1670\\n1683\\n85\\n5\\n4\\n...\\ninformation\\n0\\n...\\n3325\\n3982\\n378\\n5\\n13\\n...\\nFigure 5.3\\nCo-occurrence vectors for four words in the Wikipedia corpus, showing six of\\nthe dimensions (hand-picked for pedagogical purposes). The vector for digital is outlined in\\nred. Note that a real vector would have vastly more dimensions and thus be much sparser, i.e.\\nwould have zero values in most dimensions.\\n1000 2000 3000 4000\\n1000\\n2000\\ndigital\\n [1683,1670]\\ncomputer\\n data\\ninformation\\n [3982,3325] \\n3000\\n4000\\nFigure 5.4\\nA spatial visualization of word vectors for digital and information, showing just\\ntwo of the dimensions, corresponding to the words data and computer.\\nNote that |V|, the dimensionality of the vector, is generally the size of the vo-\\ncabulary, often between 10,000 and 50,000 words (using the most frequent words\\nin the training corpus; keeping words after about the most frequent 50,000 or so is\\ngenerally not helpful). Since most of these numbers are zero these are sparse vector\\nrepresentations; there are efÔ¨Åcient algorithms for storing and computing with sparse\\nmatrices.\\nIt‚Äôs also possible to applying various kinds of weighting functions to the counts\\nin these cells. The most popular such weighting is tf-idf, which we‚Äôll introduce in\\nChapter 11, but there have historically been a wide variety of other weightings.\\nNow that we have some intuitions, let‚Äôs move on to examine the details of com-\\nputing word similarity.\\n5.4\\nCosine for measuring similarity\\nTo measure similarity between two target words v and w, we need a metric that\\ntakes two vectors (of the same dimensionality, either both with words as dimensions,\\nhence of length |V|, or both with documents as dimensions, of length |D|) and gives\\na measure of their similarity. By far the most common similarity metric is the cosine\\nof the angle between the vectors.\\nThe cosine‚Äîlike most measures for vector similarity used in NLP‚Äîis based on\\nthe dot product operator from linear algebra, also called the inner product:\\ndot product\\ninner product\\ndot product(v,w) = v ¬∑w =\\nN\\nX\\ni=1\\nviwi = v1w1 +v2w2 +...+vNwN\\n(5.7)\\nThe dot product acts as a similarity metric because it will tend to be high just when\\nthe two vectors have large values in the same dimensions. Alternatively, vectors that'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 8}, page_content='5.4\\n‚Ä¢\\nCOSINE FOR MEASURING SIMILARITY\\n9\\nhave zeros in different dimensions‚Äîorthogonal vectors‚Äîwill have a dot product of\\n0, representing their strong dissimilarity.\\nThis raw dot product, however, has a problem as a similarity metric: it favors\\nlong vectors. The vector length is deÔ¨Åned as\\nvector length\\n|v| =\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nv2\\ni\\n(5.8)\\nThe dot product is higher if a vector is longer, with higher values in each dimension.\\nMore frequent words have longer vectors, since they tend to co-occur with more\\nwords and have higher co-occurrence values with each of them. The raw dot product\\nthus will be higher for frequent words. But this is a problem; we‚Äôd like a similarity\\nmetric that tells us how similar two words are regardless of their frequency.\\nWe modify the dot product to normalize for the vector length by dividing the\\ndot product by the lengths of each of the two vectors. This normalized dot product\\nturns out to be the same as the cosine of the angle between the two vectors, following\\nfrom the deÔ¨Ånition of the dot product between two vectors a and b:\\na¬∑b = |a||b|cosŒ∏\\na¬∑b\\n|a||b| = cosŒ∏\\n(5.9)\\nThe cosine similarity metric between two vectors v and w thus can be computed as:\\ncosine\\ncosine(v,w) = v ¬∑w\\n|v||w| =\\nN\\nX\\ni=1\\nviwi\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nv2\\ni\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nw2\\ni\\n(5.10)\\nFor some applications we pre-normalize each vector, by dividing it by its length,\\ncreating a unit vector of length 1. Thus we could compute a unit vector from a by\\nunit vector\\ndividing it by |a|. For unit vectors, the dot product is the same as the cosine.\\nThe cosine value ranges from 1 for vectors pointing in the same direction, through\\n0 for orthogonal vectors, to -1 for vectors pointing in opposite directions. But since\\nraw frequency values are non-negative, the cosine for these vectors ranges from 0‚Äì1.\\nLet‚Äôs see how the cosine computes which of the words cherry or digital is closer\\nin meaning to information, just using raw counts from the following shortened table:\\npie\\ndata computer\\ncherry\\n442\\n8\\n2\\ndigital\\n5\\n1683\\n1670\\ninformation\\n5\\n3982\\n3325\\ncos(cherry,information) =\\n442‚àó5+8‚àó3982+2‚àó3325\\n‚àö\\n4422 +82 +22‚àö\\n52 +39822 +33252 = .018\\ncos(digital,information) =\\n5‚àó5+1683‚àó3982+1670‚àó3325\\n‚àö\\n52 +16832 +16702‚àö\\n52 +39822 +33252 = .996\\nThe model decides that information is way closer to digital than it is to cherry, a\\nresult that seems sensible. Fig. 5.5 shows a visualization.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 9}, page_content='10\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n500\\n1000\\n1500\\n2000\\n2500\\n3000\\n500\\ndigital\\ncherry\\ninformation\\nDimension 1: ‚Äòpie‚Äô\\nDimension 2: ‚Äòcomputer‚Äô\\nFigure 5.5\\nA (rough) graphical demonstration of cosine similarity, showing vectors for\\nthree words (cherry, digital, and information) in the two dimensional space deÔ¨Åned by counts\\nof the words computer and pie nearby. The Ô¨Ågure doesn‚Äôt show the cosine, but it highlights the\\nangles; note that the angle between digital and information is smaller than the angle between\\ncherry and information. When two vectors are more similar, the cosine is larger but the angle\\nis smaller; the cosine has its maximum (1) when the angle between two vectors is smallest\\n(0‚ó¶); the cosine of all other angles is less than 1.\\ncan be used to compute word similarity, for tasks like Ô¨Ånding word paraphrases,\\ntracking changes in word meaning, or automatically discovering meanings of words\\nin different corpora. For example, we can Ô¨Ånd the 10 most similar words to any\\ntarget word w by computing the cosines between w and each of the |V| ‚àí1 other\\nwords, sorting, and looking at the top 10.\\n5.5\\nWord2vec\\nIn the previous sections we saw how to represent a word as a sparse, long vector with\\ndimensions corresponding to words in the vocabulary. We now introduce a more\\npowerful word representation: embeddings, short dense vectors. Unlike the vectors\\nwe‚Äôve seen so far, embeddings are short, with number of dimensions d ranging from\\n50-1000, rather than the much larger vocabulary size |V|.These d dimensions don‚Äôt\\nhave a clear interpretation. And the vectors are dense: instead of vector entries\\nbeing sparse, mostly-zero counts or functions of counts, the values will be real-\\nvalued numbers that can be negative.\\nIt turns out that dense vectors work better in every NLP task than sparse vectors.\\nWhile we don‚Äôt completely understand all the reasons for this, we have some intu-\\nitions. Representing words as 300-dimensional dense vectors requires our classiÔ¨Åers\\nto learn far fewer weights than if we represented words as 50,000-dimensional vec-\\ntors, and the smaller parameter space possibly helps with generalization and avoid-\\ning overÔ¨Åtting. Dense vectors may also do a better job of capturing synonymy.\\nFor example, in a sparse vector representation, dimensions for synonyms like car\\nand automobile dimension are distinct and unrelated; sparse vectors may thus fail\\nto capture the similarity between a word with car as a neighbor and a word with\\nautomobile as a neighbor.\\nIn this section we introduce one method for computing embeddings: skip-gram\\nskip-gram\\nwith negative sampling, sometimes called SGNS. The skip-gram algorithm is one\\nSGNS\\nof two algorithms in a software package called word2vec, and so sometimes the\\nword2vec\\nalgorithm is loosely referred to as word2vec (Mikolov et al. 2013a, Mikolov et al.\\n2013b). The word2vec methods are fast, efÔ¨Åcient to train, and easily available on-\\nline with code and pretrained embeddings. Word2vec embeddings are static em-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 10}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n11\\nbeddings, meaning that the method learns one Ô¨Åxed embedding for each word in the\\nstatic\\nembeddings\\nvocabulary. In Chapter 10 we‚Äôll introduce methods for learning dynamic contextual\\nembeddings like the popular family of BERT representations, in which the vector\\nfor each word is different in different contexts.\\nThe intuition of word2vec is that instead of counting how often each word w oc-\\ncurs near, say, apricot, we‚Äôll instead train a classiÔ¨Åer on a binary prediction task: ‚ÄúIs\\nword w likely to show up near apricot?‚Äù We don‚Äôt actually care about this prediction\\ntask; instead we‚Äôll take the learned classiÔ¨Åer weights as the word embeddings.\\nThe revolutionary intuition here is that we can just use running text as implicitly\\nsupervised training data for such a classiÔ¨Åer; a word c that occurs near the target\\nword apricot acts as gold ‚Äòcorrect answer‚Äô to the question ‚ÄúIs word c likely to show\\nup near apricot?‚Äù This method, often called self-supervision, avoids the need for\\nself-supervision\\nany sort of hand-labeled supervision signal. This idea was Ô¨Årst proposed in the task\\nof neural language modeling, when Bengio et al. (2003) and Collobert et al. (2011)\\nshowed that a neural language model (a neural network that learned to predict the\\nnext word from prior words) could just use the next word in running text as its\\nsupervision signal, and could be used to learn an embedding representation for each\\nword as part of doing this prediction task.\\nWe‚Äôll see how to do neural networks in the next chapter, but word2vec is a\\nmuch simpler model than the neural network language model, in two ways. First,\\nword2vec simpliÔ¨Åes the task (making it binary classiÔ¨Åcation instead of word pre-\\ndiction). Second, word2vec simpliÔ¨Åes the architecture (training a logistic regression\\nclassiÔ¨Åer instead of a multi-layer neural network with hidden layers that demand\\nmore sophisticated training algorithms). The intuition of skip-gram is:\\n1. Treat the target word and a neighboring context word as positive examples.\\n2. Randomly sample other words in the lexicon to get negative samples.\\n3. Use logistic regression to train a classiÔ¨Åer to distinguish those two cases.\\n4. Use the learned weights as the embeddings.\\n5.5.1\\nThe classiÔ¨Åer\\nLet‚Äôs start by thinking about the classiÔ¨Åcation task, and then turn to how to train.\\nImagine a sentence like the following, with a target word apricot, and assume we‚Äôre\\nusing a window of ¬±2 context words:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nOur goal is to train a classiÔ¨Åer such that, given a tuple (w,c) of a target word\\nw paired with a candidate context word c (for example (apricot, jam), or perhaps\\n(apricot, aardvark)) it will return the probability that c is a real context word (true\\nfor jam, false for aardvark):\\nP(+|w,c)\\n(5.11)\\nThe probability that word c is not a real context word for w is just 1 minus\\nEq. 5.11:\\nP(‚àí|w,c) = 1‚àíP(+|w,c)\\n(5.12)\\nHow does the classiÔ¨Åer compute the probability P? The intuition of the skip-\\ngram model is to base this probability on embedding similarity: a word is likely to'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 11}, page_content='12\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\noccur near the target if its embedding vector is similar to the target embedding. To\\ncompute similarity between these dense embeddings, we rely on the intuition that\\ntwo vectors are similar if they have a high dot product (after all, cosine is just a\\nnormalized dot product). In other words:\\nSimilarity(w,c) ‚âàc¬∑w\\n(5.13)\\nThe dot product c ¬∑ w is not a probability, it‚Äôs just a number ranging from ‚àí‚àûto ‚àû\\n(since the elements in word2vec embeddings can be negative, the dot product can be\\nnegative). To turn the dot product into a probability, we‚Äôll use the logistic or sigmoid\\nfunction œÉ(x), the fundamental core of logistic regression:\\nœÉ(x) =\\n1\\n1+exp(‚àíx)\\n(5.14)\\nWe model the probability that word c is a real context word for target word w as:\\nP(+|w,c) = œÉ(c¬∑w) =\\n1\\n1+exp(‚àíc¬∑w)\\n(5.15)\\nThe sigmoid function returns a number between 0 and 1, but to make it a probability\\nwe‚Äôll also need the total probability of the two possible events (c is a context word,\\nand c isn‚Äôt a context word) to sum to 1. We thus estimate the probability that word c\\nis not a real context word for w as:\\nP(‚àí|w,c) = 1‚àíP(+|w,c)\\n= œÉ(‚àíc¬∑w) =\\n1\\n1+exp(c¬∑w)\\n(5.16)\\nEquation 5.15 gives us the probability for one word, but there are many context\\nwords in the window. Skip-gram makes the simplifying assumption that all context\\nwords are independent, allowing us to just multiply their probabilities:\\nP(+|w,c1:L) =\\nL\\nY\\ni=1\\nœÉ(ci ¬∑w)\\n(5.17)\\nlogP(+|w,c1:L) =\\nL\\nX\\ni=1\\nlogœÉ(ci ¬∑w)\\n(5.18)\\nIn summary, skip-gram trains a probabilistic classiÔ¨Åer that, given a test target word\\nw and its context window of L words c1:L, assigns a probability based on how similar\\nthis context window is to the target word. The probability is based on applying the\\nlogistic (sigmoid) function to the dot product of the embeddings of the target word\\nwith each context word. To compute this probability, we just need embeddings for\\neach target word and context word in the vocabulary.\\nFig. 5.6 shows the intuition of the parameters we‚Äôll need. Skip-gram actually\\nstores two embeddings for each word, one for the word as a target, and one for the\\nword considered as context. Thus the parameters we need to learn are two matrices\\nW and C, each containing an embedding for every one of the |V| words in the\\nvocabulary V.2 Let‚Äôs now turn to learning these embeddings (which is the real goal\\nof training this classiÔ¨Åer in the Ô¨Årst place).\\n2\\nIn principle the target matrix and the context matrix could use different vocabularies, but we‚Äôll simplify\\nby assuming one shared vocabulary V.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 12}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n13\\n1\\nW\\nC\\naardvark\\nzebra\\nzebra\\naardvark\\napricot\\napricot\\n|V|\\n|V|+1\\n2|V|\\nùúΩ =\\ntarget words\\ncontext & noise\\nwords\\n‚Ä¶\\n‚Ä¶\\n1..d\\n‚Ä¶\\n‚Ä¶\\nFigure 5.6\\nThe embeddings learned by the skipgram model. The algorithm stores two em-\\nbeddings for each word, the target embedding (sometimes called the input embedding) and\\nthe context embedding (sometimes called the output embedding). The parameter Œ∏ that the al-\\ngorithm learns is thus a matrix of 2|V| vectors, each of dimension d, formed by concatenating\\ntwo matrices, the target embeddings W and the context+noise embeddings C.\\n5.5.2\\nLearning skip-gram embeddings\\nThe learning algorithm for skip-gram embeddings takes as input a corpus of text,\\nand a chosen vocabulary size N. It begins by assigning a random embedding vector\\nfor each of the N vocabulary words, and then proceeds to iteratively shift the em-\\nbedding of each word w to be more like the embeddings of words that occur nearby\\nin texts, and less like the embeddings of words that don‚Äôt occur nearby. Let‚Äôs start\\nby considering a single piece of training data:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nThis example has a target word w (apricot), and 4 context words in the L = ¬±2\\nwindow, resulting in 4 positive training instances (on the left below):\\npositive examples +\\nw\\ncpos\\napricot tablespoon\\napricot of\\napricot jam\\napricot a\\nnegative examples -\\nw\\ncneg\\nw\\ncneg\\napricot aardvark apricot seven\\napricot my\\napricot forever\\napricot where\\napricot dear\\napricot coaxial\\napricot if\\nFor training a binary classiÔ¨Åer we also need negative examples. In fact skip-\\ngram with negative sampling (SGNS) uses more negative examples than positive\\nexamples (with the ratio between them set by a parameter k). So for each of these\\n(w,cpos) training instances we‚Äôll create k negative samples, each consisting of the\\ntarget w plus a ‚Äònoise word‚Äô cneg. A noise word is a random word from the lexicon,\\nconstrained not to be the target word w. The table right above shows the setting\\nwhere k = 2, so we‚Äôll have 2 negative examples in the negative training set ‚àífor\\neach positive example w,cpos.\\nThe noise words are chosen according to their weighted unigram probability\\npŒ±(w), where Œ± is a weight. If we were sampling according to unweighted proba-\\nbility P(w), it would mean that with unigram probability P(‚Äúthe‚Äù) we would choose\\nthe word the as a noise word, with unigram probability P(‚Äúaardvark‚Äù) we would\\nchoose aardvark, and so on. But in practice it is common to set Œ± = 0.75, i.e. use'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 13}, page_content='14\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nthe weighting P3\\n4 (w):\\nPŒ±(w) =\\ncount(w)Œ±\\nP\\nw‚Ä≤ count(w‚Ä≤)Œ±\\n(5.19)\\nSetting Œ± = .75 gives better performance because it gives rare noise words slightly\\nhigher probability: for rare words, PŒ±(w) > P(w). To illustrate this intuition, it\\nmight help to work out the probabilities for an example with Œ± = .75 and two events,\\nP(a) = 0.99 and P(b) = 0.01:\\nPŒ±(a) =\\n.99.75\\n.99.75 +.01.75 = 0.97\\nPŒ±(b) =\\n.01.75\\n.99.75 +.01.75 = 0.03\\n(5.20)\\nThus using Œ± = .75 increases the probability of the rare event b from 0.01 to 0.03.\\nGiven the set of positive and negative training instances, and an initial set of\\nembeddings, the goal of the learning algorithm is to adjust those embeddings to\\n‚Ä¢ Maximize the similarity of the target word, context word pairs (w,cpos) drawn\\nfrom the positive examples\\n‚Ä¢ Minimize the similarity of the (w,cneg) pairs from the negative examples.\\nIf we consider one word/context pair (w,cpos) with its k noise words cneg1...cnegk,\\nwe can express these two goals as the following loss function L to be minimized\\n(hence the ‚àí); here the Ô¨Årst term expresses that we want the classiÔ¨Åer to assign the\\nreal context word cpos a high probability of being a neighbor, and the second term\\nexpresses that we want to assign each of the noise words cnegi a high probability of\\nbeing a non-neighbor, all multiplied because we assume independence:\\nL = ‚àílog\\n\"\\nP(+|w,cpos)\\nkY\\ni=1\\nP(‚àí|w,cnegi)\\n#\\n= ‚àí\\n\"\\nlogP(+|w,cpos)+\\nk\\nX\\ni=1\\nlogP(‚àí|w,cnegi)\\n#\\n= ‚àí\\n\"\\nlogP(+|w,cpos)+\\nk\\nX\\ni=1\\nlog\\n\\x001‚àíP(+|w,cnegi)\\n\\x01\\n#\\n= ‚àí\\n\"\\nlogœÉ(cpos ¬∑w)+\\nk\\nX\\ni=1\\nlogœÉ(‚àícnegi ¬∑w)\\n#\\n(5.21)\\nThat is, we want to maximize the dot product of the word with the actual context\\nwords, and minimize the dot products of the word with the k negative sampled non-\\nneighbor words.\\nWe minimize this loss function using stochastic gradient descent. Fig. 5.7 shows\\nthe intuition of one step of learning.\\nTo get the gradient, we need to take the derivative of Eq. 5.21 with respect to\\nthe different embeddings. It turns out the derivatives are the following (we leave the'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 14}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n15\\nW\\nC\\nmove apricot and jam closer,\\nincreasing cpos z w\\naardvark\\nmove apricot and matrix apart\\ndecreasing cneg1 z w\\n‚Äú‚Ä¶apricot jam‚Ä¶‚Äù\\nw\\nzebra\\nzebra\\naardvark\\njam\\napricot\\ncpos\\nmatrix\\nTolstoy\\nmove apricot and Tolstoy apart\\ndecreasing cneg2 z w\\n!\\ncneg1\\ncneg2\\nk=2\\nFigure 5.7\\nIntuition of one step of gradient descent. The skip-gram model tries to shift em-\\nbeddings so the target embeddings (here for apricot) are closer to (have a higher dot product\\nwith) context embeddings for nearby words (here jam) and further from (lower dot product\\nwith) context embeddings for noise words that don‚Äôt occur nearby (here Tolstoy and matrix).\\nproof as an exercise at the end of the chapter):\\n‚àÇL\\n‚àÇcpos\\n= [œÉ(cpos ¬∑w)‚àí1]w\\n(5.22)\\n‚àÇL\\n‚àÇcneg\\n= [œÉ(cneg ¬∑w)]w\\n(5.23)\\n‚àÇL\\n‚àÇw = [œÉ(cpos ¬∑w)‚àí1]cpos +\\nk\\nX\\ni=1\\n[œÉ(cnegi ¬∑w)]cnegi\\n(5.24)\\nThe update equations going from time step t to t + 1 in stochastic gradient descent\\nare thus:\\nct+1\\npos\\n= ct\\npos ‚àíŒ∑[œÉ(ct\\npos ¬∑wt)‚àí1]wt\\n(5.25)\\nct+1\\nneg = ct\\nneg ‚àíŒ∑[œÉ(ct\\nneg ¬∑wt)]wt\\n(5.26)\\nwt+1 = wt ‚àíŒ∑\\n\"\\n[œÉ(ct\\npos ¬∑wt)‚àí1]ct\\npos +\\nk\\nX\\ni=1\\n[œÉ(ct\\nnegi ¬∑wt)]ct\\nnegi\\n#\\n(5.27)\\nJust as in logistic regression, then, the learning algorithm starts with randomly ini-\\ntialized W and C matrices, and then walks through the training corpus using gradient\\ndescent to move W and C so as to minimize the loss in Eq. 5.21 by making the up-\\ndates in (Eq. 5.25)-(Eq. 5.27).\\nRecall that the skip-gram model learns two separate embeddings for each word i:\\nthe target embedding wi and the context embedding ci, stored in two matrices, the\\ntarget\\nembedding\\ncontext\\nembedding\\ntarget matrix W and the context matrix C. It‚Äôs common to just add them together,\\nrepresenting word i with the vector wi +ci. Alternatively we can throw away the C\\nmatrix and just represent each word i by the vector wi.\\nAs with the simple count-based methods like tf-idf, the context window size L\\naffects the performance of skip-gram embeddings, and experiments often tune the\\nparameter L on a devset.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 15}, page_content='16\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n5.5.3\\nOther kinds of static embeddings\\nThere are many kinds of static embeddings. An extension of word2vec, fasttext\\nfasttext\\n(Bojanowski et al., 2017), addresses a problem with word2vec as we have presented\\nit so far: it has no good way to deal with unknown words‚Äîwords that appear in\\na test corpus but were unseen in the training corpus. A related problem is word\\nsparsity, such as in languages with rich morphology, where some of the many forms\\nfor each noun and verb may only occur rarely. Fasttext deals with these problems\\nby using subword models, representing each word as itself plus a bag of constituent\\nn-grams, with special boundary symbols < and > added to each word. For example,\\nwith n = 3 the word where would be represented by the sequence <where> plus the\\ncharacter n-grams:\\n<wh, whe, her, ere, re>\\nThen a skipgram embedding is learned for each constituent n-gram, and the word\\nwhere is represented by the sum of all of the embeddings of its constituent n-grams.\\nUnknown words can then be presented only by the sum of the constituent n-grams.\\nA fasttext open-source library, including pretrained embeddings for 157 languages,\\nis available at https://fasttext.cc.\\nAnother very widely used static embedding model is GloVe (Pennington et al.,\\n2014), short for Global Vectors, because the model is based on capturing global\\ncorpus statistics. GloVe is based on ratios of probabilities from the word-word co-\\noccurrence matrix.\\nIt turns out that dense embeddings like word2vec actually have an elegant math-\\nematical relationship with count-based embeddings, in which word2vec can be seen\\nas implicitly optimizing a function of a count matrix with a particular (PPMI) weight-\\ning (Levy and Goldberg, 2014c).\\n5.6\\nVisualizing Embeddings\\n‚ÄúI see well in many dimensions as long as the dimensions are around two.‚Äù\\nThe late economist Martin Shubik\\nVisualizing embeddings is an important goal in helping understand, apply, and\\nimprove these models of word meaning. But how can we visualize a (for example)\\n100-dimensional vector?\\nWRIST\\nANKLE\\nSHOULDER\\nARM\\nLEG\\nHAND\\nFOOT\\nHEAD\\nNOSE\\nFINGER\\nTOE\\nFACE\\nEAR\\nEYE\\nTOOTH\\nDOG\\nCAT\\nPUPPY\\nKITTEN\\nCOW\\nMOUSE\\nTURTLE\\nOYSTER\\nLION\\nBULL\\nCHICAGO\\nATLANTA\\nMONTREAL\\nNASHVILLE\\nTOKYO\\nCHINA\\nRUSSIA\\nAFRICA\\nASIA\\nEUROPE\\nAMERICA\\nBRAZIL\\nMOSCOW\\nFRANCE\\nHAWAII\\nThe simplest way to visualize the meaning of a word\\nw embedded in a space is to list the most similar words to\\nw by sorting the vectors for all words in the vocabulary by\\ntheir cosine with the vector for w. For example the 7 closest\\nwords to frog using a particular embeddings computed with\\nthe GloVe algorithm are: frogs, toad, litoria, leptodactyli-\\ndae, rana, lizard, and eleutherodactylus (Pennington et al.,\\n2014).\\nYet another visualization method is to use a clustering\\nalgorithm to show a hierarchical representation of which\\nwords are similar to others in the embedding space. The\\nuncaptioned Ô¨Ågure on the left uses hierarchical clustering\\nof some embedding vectors for nouns as a visualization\\nmethod (Rohde et al., 2006).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 16}, page_content='5.7\\n‚Ä¢\\nSEMANTIC PROPERTIES OF EMBEDDINGS\\n17\\nProbably the most common visualization method, how-\\never, is to project the 100 dimensions of a word down into 2\\ndimensions. Fig. 5.1 showed one such visualization, as does\\nFig. 5.9, using a projection method called t-SNE (van der\\nMaaten and Hinton, 2008).\\n5.7\\nSemantic properties of embeddings\\nIn this section we brieÔ¨Çy summarize some of the semantic properties of embeddings\\nthat have been studied.\\nDifferent types of similarity or association:\\nOne parameter of vector semantic\\nmodels that is relevant to both sparse PPMI vectors and dense word2vec vectors is\\nthe size of the context window used to collect counts. This is generally between 1\\nand 10 words on each side of the target word (for a total context of 2-20 words).\\nThe choice depends on the goals of the representation. Shorter context windows\\ntend to lead to representations that are a bit more syntactic, since the information is\\ncoming from immediately nearby words. When the vectors are computed from short\\ncontext windows, the most similar words to a target word w tend to be semantically\\nsimilar words with the same parts of speech. When vectors are computed from long\\ncontext windows, the highest cosine words to a target word w tend to be words that\\nare topically related but not similar.\\nFor example Levy and Goldberg (2014a) showed that using skip-gram with a\\nwindow of ¬±2, the most similar words to the word Hogwarts (from the Harry Potter\\nseries) were names of other Ô¨Åctional schools: Sunnydale (from Buffy the Vampire\\nSlayer) or Evernight (from a vampire series). With a window of ¬±5, the most similar\\nwords to Hogwarts were other words topically related to the Harry Potter series:\\nDumbledore, Malfoy, and half-blood.\\nIt‚Äôs also often useful to distinguish two kinds of similarity or association between\\nwords (Sch¬®utze and Pedersen, 1993). Two words have Ô¨Årst-order co-occurrence\\nÔ¨Årst-order\\nco-occurrence\\n(sometimes called syntagmatic association) if they are typically nearby each other.\\nThus wrote is a Ô¨Årst-order associate of book or poem. Two words have second-order\\nco-occurrence (sometimes called paradigmatic association) if they have similar\\nsecond-order\\nco-occurrence\\nneighbors. Thus wrote is a second-order associate of words like said or remarked.\\nAnalogy/Relational Similarity:\\nAnother semantic property of embeddings is their\\nability to capture relational meanings. In an important early vector space model of\\ncognition, Rumelhart and Abrahamson (1973) proposed the parallelogram model\\nparallelogram\\nmodel\\nfor solving simple analogy problems of the form a is to b as a* is to what?. In such\\nproblems, a system is given a problem like apple:tree::grape:?, i.e., apple is to tree\\nas grape is to\\n, and must Ô¨Åll in the word vine. In the parallelogram model, il-\\nlustrated in Fig. 5.8, the vector from the word apple to the word tree (= #   ¬ª\\ntree‚àí#       ¬ª\\napple)\\nis added to the vector for grape (#        ¬ª\\ngrape); the nearest word to that point is returned.\\nIn early work with sparse embeddings, scholars showed that sparse vector mod-\\nels of meaning could solve such analogy problems (Turney and Littman, 2005),\\nbut the parallelogram method received more modern attention because of its suc-\\ncess with word2vec or GloVe vectors (Mikolov et al. 2013c, Levy and Goldberg\\n2014b, Pennington et al. 2014). For example, the result of the expression #     ¬ª\\nking ‚àí\\n#     ¬ª\\nman + #            ¬ª\\nwoman is a vector close to #         ¬ª\\nqueen. Similarly, #      ¬ª\\nParis ‚àí#           ¬ª\\nFrance + #     ¬ª\\nItaly results\\nin a vector that is close to #         ¬ª\\nRome. The embedding model thus seems to be extract-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 17}, page_content='18\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\ntree\\napple\\ngrape\\nvine\\nFigure 5.8\\nThe parallelogram model for analogy problems (Rumelhart and Abrahamson,\\n1973): the location of #     ¬ª\\nvine can be found by subtracting #       ¬ª\\napple from #   ¬ª\\ntree and adding #       ¬ª\\ngrape.\\ning representations of relations like MALE-FEMALE, or CAPITAL-CITY-OF, or even\\nCOMPARATIVE/SUPERLATIVE, as shown in Fig. 5.9 from GloVe.\\n(a)\\n(b)\\nFigure 5.9\\nRelational properties of the GloVe vector space, shown by projecting vectors onto two dimensions.\\n(a) #     ¬ª\\nking‚àí#     ¬ª\\nman+ #            ¬ª\\nwoman is close to #        ¬ª\\nqueen. (b) offsets seem to capture comparative and superlative morphology\\n(Pennington et al., 2014).\\nFor a a : b :: a‚àó: b‚àóproblem, meaning the algorithm is given vectors a, b, and\\na‚àóand must Ô¨Ånd b‚àó, the parallelogram method is thus:\\nÀÜb‚àó= argmin\\nx\\ndistance(x,b‚àía+a‚àó)\\n(5.28)\\nwith some distance function, such as Euclidean distance.\\nThere are some caveats. For example, the closest value returned by the paral-\\nlelogram algorithm in word2vec or GloVe embedding spaces is usually not in fact\\nb* but one of the 3 input words or their morphological variants (i.e., cherry:red ::\\npotato:x returns potato or potatoes instead of brown), so these must be explicitly\\nexcluded. Furthermore while embedding spaces perform well if the task involves\\nfrequent words, small distances, and certain relations (like relating countries with\\ntheir capitals or verbs/nouns with their inÔ¨Çected forms), the parallelogram method\\nwith embeddings doesn‚Äôt work as well for other relations (Linzen 2016, Gladkova\\net al. 2016, Schluter 2018, Ethayarajh et al. 2019a), and indeed Peterson et al. (2020)\\nargue that the parallelogram method is in general too simple to model the human\\ncognitive process of forming analogies of this kind.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 18}, page_content='5.8\\n‚Ä¢\\nBIAS AND EMBEDDINGS\\n19\\n5.7.1\\nEmbeddings and Historical Semantics\\nEmbeddings can also be a useful tool for studying how meaning changes over time,\\nby computing multiple embedding spaces, each from texts written in a particular\\ntime period. For example Fig. 5.10 shows a visualization of changes in meaning in\\nEnglish words over the last two centuries, computed by building separate embedding\\nspaces for each decade from historical corpora like Google n-grams (Lin et al., 2012)\\nand the Corpus of Historical American English (Davies, 2012).\\nFigure 5.10\\nA t-SNE visualization of the semantic change of 3 words in English using\\nword2vec vectors. The modern sense of each word, and the grey context words, are com-\\nputed from the most recent (modern) time-point embedding space. Earlier points are com-\\nputed from earlier historical embedding spaces. The visualizations show the changes in the\\nword gay from meanings related to ‚Äúcheerful‚Äù or ‚Äúfrolicsome‚Äù to referring to homosexuality,\\nthe development of the modern ‚Äútransmission‚Äù sense of broadcast from its original sense of\\nsowing seeds, and the pejoration of the word awful as it shifted from meaning ‚Äúfull of awe‚Äù\\nto meaning ‚Äúterrible or appalling‚Äù (Hamilton et al., 2016).\\n5.8\\nBias and Embeddings\\nIn addition to their ability to learn word meaning from text, embeddings, alas,\\nalso reproduce the implicit biases and stereotypes that were latent in the text. As\\nthe prior section just showed, embeddings can roughly model relational similar-\\nity: ‚Äòqueen‚Äô as the closest word to ‚Äòking‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô implies the analogy\\nman:woman::king:queen. But these same embedding analogies also exhibit gender\\nstereotypes. For example Bolukbasi et al. (2016) Ô¨Ånd that the closest occupation\\nto ‚Äòcomputer programmer‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô in word2vec embeddings trained on\\nnews text is ‚Äòhomemaker‚Äô, and that the embeddings similarly suggest the analogy\\n‚Äòfather‚Äô is to ‚Äòdoctor‚Äô as ‚Äòmother‚Äô is to ‚Äònurse‚Äô. This could result in what Crawford\\n(2017) and Blodgett et al. (2020) call an allocational harm, when a system allo-\\nallocational\\nharm\\ncates resources (jobs or credit) unfairly to different groups. For example algorithms\\nthat use embeddings as part of a search for hiring potential programmers or doctors\\nmight thus incorrectly downweight documents with women‚Äôs names.\\nIt turns out that embeddings don‚Äôt just reÔ¨Çect the statistics of their input, but also\\namplify bias; gendered terms become more gendered in embedding space than they\\nbias\\nampliÔ¨Åcation\\nwere in the input text statistics (Zhao et al. 2017, Ethayarajh et al. 2019b, Jia et al.\\n2020), and biases are more exaggerated than in actual labor employment statistics\\n(Garg et al., 2018).\\nEmbeddings also encode the implicit associations that are a property of human\\nreasoning. The Implicit Association Test (Greenwald et al., 1998) measures peo-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 19}, page_content='20\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nple‚Äôs associations between concepts (like ‚ÄòÔ¨Çowers‚Äô or ‚Äòinsects‚Äô) and attributes (like\\n‚Äòpleasantness‚Äô and ‚Äòunpleasantness‚Äô) by measuring differences in the latency with\\nwhich they label words in the various categories.3 Using such methods, people\\nin the United States have been shown to associate African-American names with\\nunpleasant words (more than European-American names), male names more with\\nmathematics and female names with the arts, and old people‚Äôs names with unpleas-\\nant words (Greenwald et al. 1998, Nosek et al. 2002a, Nosek et al. 2002b). Caliskan\\net al. (2017) replicated all these Ô¨Åndings of implicit associations using GloVe vectors\\nand cosine similarity instead of human latencies. For example African-American\\nnames like ‚ÄòLeroy‚Äô and ‚ÄòShaniqua‚Äô had a higher GloVe cosine with unpleasant words\\nwhile European-American names (‚ÄòBrad‚Äô, ‚ÄòGreg‚Äô, ‚ÄòCourtney‚Äô) had a higher cosine\\nwith pleasant words. These problems with embeddings are an example of a repre-\\nsentational harm (Crawford 2017, Blodgett et al. 2020), which is a harm caused by\\nrepresentational\\nharm\\na system demeaning or even ignoring some social groups. Any embedding-aware al-\\ngorithm that made use of word sentiment could thus exacerbate bias against African\\nAmericans.\\nRecent research focuses on ways to try to remove these kinds of biases, for\\nexample by developing a transformation of the embedding space that removes gen-\\nder stereotypes but preserves deÔ¨Ånitional gender (Bolukbasi et al. 2016, Zhao et al.\\n2017) or changing the training procedure (Zhao et al., 2018). However, although\\nthese sorts of debiasing may reduce bias in embeddings, they do not eliminate it\\ndebiasing\\n(Gonen and Goldberg, 2019), and this remains an open problem.\\nHistorical embeddings are also being used to measure biases in the past. Garg\\net al. (2018) used embeddings from historical texts to measure the association be-\\ntween embeddings for occupations and embeddings for names of various ethnici-\\nties or genders (for example the relative cosine similarity of women‚Äôs names versus\\nmen‚Äôs to occupation words like ‚Äòlibrarian‚Äô or ‚Äòcarpenter‚Äô) across the 20th century.\\nThey found that the cosines correlate with the empirical historical percentages of\\nwomen or ethnic groups in those occupations. Historical embeddings also repli-\\ncated old surveys of ethnic stereotypes; the tendency of experimental participants in\\n1933 to associate adjectives like ‚Äòindustrious‚Äô or ‚Äòsuperstitious‚Äô with, e.g., Chinese\\nethnicity, correlates with the cosine between Chinese last names and those adjectives\\nusing embeddings trained on 1930s text. They also were able to document historical\\ngender biases, such as the fact that embeddings for adjectives related to competence\\n(‚Äòsmart‚Äô, ‚Äòwise‚Äô, ‚Äòthoughtful‚Äô, ‚Äòresourceful‚Äô) had a higher cosine with male than fe-\\nmale words, and showed that this bias has been slowly decreasing since 1960. We\\nreturn in later chapters to this question about the role of bias in natural language\\nprocessing.\\n5.9\\nEvaluating Vector Models\\nThe most important evaluation metric for vector models is extrinsic evaluation on\\ntasks, i.e., using vectors in an NLP task and seeing whether this improves perfor-\\nmance over some other model.\\n3\\nRoughly speaking, if humans associate ‚ÄòÔ¨Çowers‚Äô with ‚Äòpleasantness‚Äô and ‚Äòinsects‚Äô with ‚Äòunpleasant-\\nness‚Äô, when they are instructed to push a green button for ‚ÄòÔ¨Çowers‚Äô (daisy, iris, lilac) and ‚Äòpleasant words‚Äô\\n(love, laughter, pleasure) and a red button for ‚Äòinsects‚Äô (Ô¨Çea, spider, mosquito) and ‚Äòunpleasant words‚Äô\\n(abuse, hatred, ugly) they are faster than in an incongruous condition where they push a red button for\\n‚ÄòÔ¨Çowers‚Äô and ‚Äòunpleasant words‚Äô and a green button for ‚Äòinsects‚Äô and ‚Äòpleasant words‚Äô.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 20}, page_content='5.10\\n‚Ä¢\\nSUMMARY\\n21\\nNonetheless it is useful to have intrinsic evaluations. The most common metric\\nis to test their performance on similarity, computing the correlation between an\\nalgorithm‚Äôs word similarity scores and word similarity ratings assigned by humans.\\nWordSim-353 (Finkelstein et al., 2002) is a commonly used set of ratings from 0\\nto 10 for 353 noun pairs; for example (plane, car) had an average score of 5.77.\\nSimLex-999 (Hill et al., 2015) is a more complex dataset that quantiÔ¨Åes similarity\\n(cup, mug) rather than relatedness (cup, coffee), and includes concrete and abstract\\nadjective, noun and verb pairs. The TOEFL dataset is a set of 80 questions, each\\nconsisting of a target word with 4 additional word choices; the task is to choose\\nwhich is the correct synonym, as in the example: Levied is closest in meaning to:\\nimposed, believed, requested, correlated (Landauer and Dumais, 1997). All of these\\ndatasets present words without context.\\nSlightly more realistic are intrinsic similarity tasks that include context. The\\nStanford Contextual Word Similarity (SCWS) dataset (Huang et al., 2012) and the\\nWord-in-Context (WiC) dataset (Pilehvar and Camacho-Collados, 2019) offer richer\\nevaluation scenarios. SCWS gives human judgments on 2,003 pairs of words in\\ntheir sentential context, while WiC gives target words in two sentential contexts that\\nare either in the same or different senses; see Appendix G. The semantic textual\\nsimilarity task (Agirre et al. 2012, Agirre et al. 2015) evaluates the performance of\\nsentence-level similarity algorithms, consisting of a set of pairs of sentences, each\\npair with human-labeled similarity scores.\\nAnother task used for evaluation is the analogy task, discussed on page 17, where\\nthe system has to solve problems of the form a is to b as a* is to b*, given a, b, and a*\\nand having to Ô¨Ånd b* (Turney and Littman, 2005). A number of sets of tuples have\\nbeen created for this task (Mikolov et al. 2013a, Mikolov et al. 2013c, Gladkova\\net al. 2016), covering morphology (city:cities::child:children), lexicographic rela-\\ntions (leg:table::spout:teapot) and encyclopedia relations (Beijing:China::Dublin:Ireland),\\nsome drawing from the SemEval-2012 Task 2 dataset of 79 different relations (Jur-\\ngens et al., 2012).\\nAll embedding algorithms suffer from inherent variability. For example because\\nof randomness in the initialization and the random negative sampling, algorithms\\nlike word2vec may produce different results even from the same dataset, and in-\\ndividual documents in a collection may strongly impact the resulting embeddings\\n(Tian et al. 2016, Hellrich and Hahn 2016, Antoniak and Mimno 2018). When em-\\nbeddings are used to study word associations in particular corpora, therefore, it is\\nbest practice to train multiple embeddings with bootstrap sampling over documents\\nand average the results (Antoniak and Mimno, 2018).\\n5.10\\nSummary\\n‚Ä¢ In vector semantics, a word is modeled as a vector‚Äîa point in high-dimensional\\nspace, also called an embedding. In this chapter we focus on static embed-\\ndings, where each word is mapped to a Ô¨Åxed embedding.\\n‚Ä¢ Vector semantic models fall into two classes: sparse and dense. In sparse\\nmodels each dimension corresponds to a word in the vocabulary V and cells\\nare functions of co-occurrence counts. The word-context or term-term ma-\\ntrix has a row for each (target) word in the vocabulary and a column for each\\ncontext term in the vocabulary.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 21}, page_content='22\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n‚Ä¢ Dense vector models typically have dimensionality 50‚Äì1000. Word2vec al-\\ngorithms like skip-gram are a popular way to compute dense embeddings.\\nSkip-gram trains a logistic regression classiÔ¨Åer to compute the probability that\\ntwo words are ‚Äòlikely to occur nearby in text‚Äô. This probability is computed\\nfrom the dot product between the embeddings for the two words.\\n‚Ä¢ Skip-gram uses stochastic gradient descent to train the classiÔ¨Åer, by learning\\nembeddings that have a high dot product with embeddings of words that occur\\nnearby and a low dot product with noise words.\\n‚Ä¢ Other important embedding algorithms include GloVe, a method based on\\nratios of word co-occurrence probabilities.\\n‚Ä¢ Whether using sparse or dense vectors, word and document similarities are\\ncomputed by some function of the dot product between vectors. The cosine\\nof two vectors‚Äîa normalized dot product‚Äîis the most popular such metric.\\nHistorical Notes\\nThe idea of vector semantics arose out of research in the 1950s in three distinct\\nÔ¨Åelds: linguistics, psychology, and computer science, each of which contributed a\\nfundamental aspect of the model.\\nThe idea that meaning is related to the distribution of words in context was\\nwidespread in linguistic theory of the 1950s, among distributionalists like Zellig\\nHarris, Martin Joos, and J. R. Firth, and semioticians like Thomas Sebeok. As Joos\\n(1950) put it,\\nthe linguist‚Äôs ‚Äúmeaning‚Äù of a morpheme. . . is by deÔ¨Ånition the set of conditional\\nprobabilities of its occurrence in context with all other morphemes.\\nThe idea that the meaning of a word might be modeled as a point in a multi-\\ndimensional semantic space came from psychologists like Charles E. Osgood, who\\nhad been studying how people responded to the meaning of words by assigning val-\\nues along scales like happy/sad or hard/soft. Osgood et al. (1957) proposed that the\\nmeaning of a word in general could be modeled as a point in a multidimensional\\nEuclidean space, and that the similarity of meaning between two words could be\\nmodeled as the distance between these points in the space.\\nA Ô¨Ånal intellectual source in the 1950s and early 1960s was the Ô¨Åeld then called\\nmechanical indexing, now known as information retrieval. In what became known\\nmechanical\\nindexing\\nas the vector space model for information retrieval (Salton 1971, Sparck Jones\\n1986), researchers demonstrated new ways to deÔ¨Åne the meaning of words in terms\\nof vectors (Switzer, 1965), and reÔ¨Åned methods for word similarity based on mea-\\nsures of statistical association between words like mutual information (Giuliano,\\n1965) and idf (Sparck Jones, 1972), and showed that the meaning of documents\\ncould be represented in the same vector spaces used for words. Around the same\\ntime, (Cordier, 1965) showed that factor analysis of word association probabilities\\ncould be used to form dense vector representations of words.\\nSome of the philosophical underpinning of the distributional way of thinking\\ncame from the late writings of the philosopher Wittgenstein, who was skeptical of\\nthe possibility of building a completely formal theory of meaning deÔ¨Ånitions for\\neach word. Wittgenstein suggested instead that ‚Äúthe meaning of a word is its use in\\nthe language‚Äù (Wittgenstein, 1953, PI 43). That is, instead of using some logical lan-\\nguage to deÔ¨Åne each word, or drawing on denotations or truth values, Wittgenstein‚Äôs'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 22}, page_content='HISTORICAL NOTES\\n23\\nidea is that we should deÔ¨Åne a word by how it is used by people in speaking and un-\\nderstanding in their day-to-day interactions, thus preÔ¨Åguring the movement toward\\nembodied and experiential models in linguistics and NLP (Glenberg and Robertson\\n2000, Lake and Murphy 2021, Bisk et al. 2020, Bender and Koller 2020).\\nMore distantly related is the idea of deÔ¨Åning words by a vector of discrete fea-\\ntures, which has roots at least as far back as Descartes and Leibniz (Wierzbicka 1992,\\nWierzbicka 1996). By the middle of the 20th century, beginning with the work of\\nHjelmslev (Hjelmslev, 1969) (originally 1943) and Ô¨Çeshed out in early models of\\ngenerative grammar (Katz and Fodor, 1963), the idea arose of representing mean-\\ning with semantic features, symbols that represent some sort of primitive meaning.\\nsemantic\\nfeature\\nFor example words like hen, rooster, or chick, have something in common (they all\\ndescribe chickens) and something different (their age and sex), representable as:\\nhen\\n+female, +chicken, +adult\\nrooster -female, +chicken, +adult\\nchick\\n+chicken, -adult\\nThe dimensions used by vector models of meaning to deÔ¨Åne words, however, are\\nonly abstractly related to this idea of a small Ô¨Åxed number of hand-built dimensions.\\nNonetheless, there has been some attempt to show that certain dimensions of em-\\nbedding models do contribute some speciÔ¨Åc compositional aspect of meaning like\\nthese early semantic features.\\nThe use of dense vectors to model word meaning, and indeed the term embed-\\nding, grew out of the latent semantic indexing (LSI) model (Deerwester et al.,\\n1988) recast as LSA (latent semantic analysis) (Deerwester et al., 1990). In LSA\\nsingular value decomposition‚ÄîSVD‚Äî is applied to a term-document matrix (each\\nSVD\\ncell weighted by log frequency and normalized by entropy), and then the Ô¨Årst 300\\ndimensions are used as the LSA embedding. Singular Value Decomposition (SVD)\\nis a method for Ô¨Ånding the most important dimensions of a data set, those dimen-\\nsions along which the data varies the most. LSA was then quickly widely applied:\\nas a cognitive model (Landauer and Dumais, 1997), and for tasks like spell checking\\n(Jones and Martin, 1997), language modeling (Bellegarda 1997, Coccaro and Ju-\\nrafsky 1998, Bellegarda 2000), morphology induction (Schone and Jurafsky 2000,\\nSchone and Jurafsky 2001b), multiword expressions (MWEs) (Schone and Jurafsky,\\n2001a), and essay grading (Rehder et al., 1998). Related models were simultane-\\nously developed and applied to word sense disambiguation by Sch¬®utze (1992). LSA\\nalso led to the earliest use of embeddings to represent words in a probabilistic clas-\\nsiÔ¨Åer, in the logistic regression document router of Sch¬®utze et al. (1995). The idea of\\nSVD on the term-term matrix (rather than the term-document matrix) as a model of\\nmeaning for NLP was proposed soon after LSA by Sch¬®utze (1992). Sch¬®utze applied\\nthe low-rank (97-dimensional) embeddings produced by SVD to the task of word\\nsense disambiguation, analyzed the resulting semantic space, and also suggested\\npossible techniques like dropping high-order dimensions. See Sch¬®utze (1997).\\nA number of alternative matrix models followed on from the early SVD work,\\nincluding Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 1999), Latent\\nDirichlet Allocation (LDA) (Blei et al., 2003), and Non-negative Matrix Factoriza-\\ntion (NMF) (Lee and Seung, 1999).\\nThe LSA community seems to have Ô¨Årst used the word ‚Äúembedding‚Äù in Landauer\\net al. (1997), in a variant of its mathematical meaning as a mapping from one space\\nor mathematical structure to another. In LSA, the word embedding seems to have\\ndescribed the mapping from the space of sparse count vectors to the latent space of\\nSVD dense vectors. Although the word thus originally meant the mapping from one'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 23}, page_content='24\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nspace to another, it has metonymically shifted to mean the resulting dense vector in\\nthe latent space, and it is in this sense that we currently use the word.\\nBy the next decade, Bengio et al. (2003) and Bengio et al. (2006) showed that\\nneural language models could also be used to develop embeddings as part of the task\\nof word prediction. Collobert and Weston (2007), Collobert and Weston (2008), and\\nCollobert et al. (2011) then demonstrated that embeddings could be used to represent\\nword meanings for a number of NLP tasks. Turian et al. (2010) compared the value\\nof different kinds of embeddings for different NLP tasks. Mikolov et al. (2011)\\nshowed that recurrent neural nets could be used as language models. The idea of\\nsimplifying the hidden layer of these neural net language models to create the skip-\\ngram (and also CBOW) algorithms was proposed by Mikolov et al. (2013a). The\\nnegative sampling training algorithm was proposed in Mikolov et al. (2013b). There\\nare numerous surveys of static embeddings and their parameterizations (Bullinaria\\nand Levy 2007, Bullinaria and Levy 2012, Lapesa and Evert 2014, Kiela and Clark\\n2014, Levy et al. 2015).\\nSee Manning et al. (2008) and Chapter 11 for a deeper understanding of the role\\nof vectors in information retrieval, including how to compare queries with docu-\\nments, more details on tf-idf, and issues of scaling to very large datasets. See Kim\\n(2019) for a clear and comprehensive tutorial on word2vec. Cruse (2004) is a useful\\nintroductory linguistic text on lexical semantics.\\nExercises'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='Exercises\\n25\\nAgirre, E., C. Banea, C. Cardie, D. Cer, M. Diab,\\nA. Gonzalez-Agirre, W. Guo, I. Lopez-Gazpio, M. Mar-\\nitxalar, R. Mihalcea, G. Rigau, L. Uria, and J. Wiebe.\\n2015. SemEval-2015 task 2: Semantic textual similarity,\\nEnglish, Spanish and pilot on interpretability. SemEval-\\n15.\\nAgirre, E., M. Diab, D. Cer, and A. Gonzalez-Agirre. 2012.\\nSemEval-2012 task 6: A pilot on semantic textual simi-\\nlarity. SemEval-12.\\nAntoniak, M. and D. Mimno. 2018. Evaluating the stability\\nof embedding-based word similarities. TACL, 6:107‚Äì119.\\nBellegarda, J. R. 1997. A latent semantic analysis framework\\nfor large-span language modeling. EUROSPEECH.\\nBellegarda, J. R. 2000. Exploiting latent semantic informa-\\ntion in statistical language modeling. Proceedings of the\\nIEEE, 89(8):1279‚Äì1296.\\nBender, E. M. and A. Koller. 2020. Climbing towards NLU:\\nOn meaning, form, and understanding in the age of data.\\nACL.\\nBengio, Y., A. Courville, and P. Vincent. 2013. Represen-\\ntation learning: A review and new perspectives. IEEE\\nTransactions on Pattern Analysis and Machine Intelli-\\ngence, 35(8):1798‚Äì1828.\\nBengio, Y., R. Ducharme, P. Vincent, and C. Jauvin. 2003.\\nA neural probabilistic language model. JMLR, 3:1137‚Äì\\n1155.\\nBengio, Y., H. Schwenk, J.-S. Sen¬¥ecal, F. Morin, and J.-L.\\nGauvain. 2006. Neural probabilistic language models. In\\nInnovations in Machine Learning, 137‚Äì186. Springer.\\nBisk, Y., A. Holtzman, J. Thomason, J. Andreas, Y. Bengio,\\nJ. Chai, M. Lapata, A. Lazaridou, J. May, A. Nisnevich,\\nN. Pinto, and J. Turian. 2020. Experience grounds lan-\\nguage. EMNLP.\\nBlei, D. M., A. Y. Ng, and M. I. Jordan. 2003. Latent Dirich-\\nlet allocation. JMLR, 3(5):993‚Äì1022.\\nBlodgett, S. L., S. Barocas, H. Daum¬¥e III, and H. Wallach.\\n2020. Language (technology) is power: A critical survey\\nof ‚Äúbias‚Äù in NLP. ACL.\\nBojanowski, P., E. Grave, A. Joulin, and T. Mikolov. 2017.\\nEnriching word vectors with subword information. TACL,\\n5:135‚Äì146.\\nBolukbasi, T., K.-W. Chang, J. Zou, V. Saligrama, and A. T.\\nKalai. 2016. Man is to computer programmer as woman\\nis to homemaker? Debiasing word embeddings. NeurIPS.\\nBr¬¥eal, M. 1897. Essai de S¬¥emantique: Science des signiÔ¨Åca-\\ntions. Hachette.\\nBudanitsky, A. and G. Hirst. 2006.\\nEvaluating WordNet-\\nbased measures of lexical semantic relatedness. Compu-\\ntational Linguistics, 32(1):13‚Äì47.\\nBullinaria, J. A. and J. P. Levy. 2007. Extracting seman-\\ntic representations from word co-occurrence statistics:\\nA computational study.\\nBehavior research methods,\\n39(3):510‚Äì526.\\nBullinaria, J. A. and J. P. Levy. 2012. Extracting semantic\\nrepresentations from word co-occurrence statistics: stop-\\nlists, stemming, and SVD. Behavior research methods,\\n44(3):890‚Äì907.\\nCaliskan, A., J. J. Bryson, and A. Narayanan. 2017. Seman-\\ntics derived automatically from language corpora contain\\nhuman-like biases. Science, 356(6334):183‚Äì186.\\nCarlson, G. N. 1977. Reference to kinds in English. Ph.D.\\nthesis, University of Massachusetts, Amherst. Forward.\\nClark, E. 1987. The principle of contrast: A constraint on\\nlanguage acquisition. In B. MacWhinney, ed., Mecha-\\nnisms of language acquisition, 1‚Äì33. LEA.\\nCoccaro, N. and D. Jurafsky. 1998. Towards better integra-\\ntion of semantic predictors in statistical language model-\\ning. ICSLP.\\nCollobert, R. and J. Weston. 2007. Fast semantic extraction\\nusing a novel neural network architecture. ACL.\\nCollobert, R. and J. Weston. 2008. A uniÔ¨Åed architecture for\\nnatural language processing: Deep neural networks with\\nmultitask learning. ICML.\\nCollobert,\\nR.,\\nJ.\\nWeston,\\nL.\\nBottou,\\nM.\\nKarlen,\\nK. Kavukcuoglu, and P. Kuksa. 2011. Natural language\\nprocessing (almost) from scratch. JMLR, 12:2493‚Äì2537.\\nCordier, B. 1965. Factor-analysis of correspondences. COL-\\nING 1965.\\nCrawford, K. 2017.\\nThe trouble with bias.\\nKeynote at\\nNeurIPS.\\nCruse, D. A. 2004. Meaning in Language: an Introduction\\nto Semantics and Pragmatics. Oxford University Press.\\nSecond edition.\\nDavies, M. 2012.\\nExpanding horizons in historical lin-\\nguistics with the 400-million word Corpus of Historical\\nAmerican English. Corpora, 7(2):121‚Äì157.\\nDavies, M. 2015. The Wikipedia Corpus: 4.6 million arti-\\ncles, 1.9 billion words. Adapted from Wikipedia. https:\\n//www.english-corpora.org/wiki/.\\nDeerwester, S. C., S. T. Dumais, G. W. Furnas, R. A. Harsh-\\nman, T. K. Landauer, K. E. Lochbaum, and L. Streeter.\\n1988. Computer information retrieval using latent seman-\\ntic structure: US Patent 4,839,853.\\nDeerwester, S. C., S. T. Dumais, T. K. Landauer, G. W. Fur-\\nnas, and R. A. Harshman. 1990. Indexing by latent se-\\nmantics analysis. JASIS, 41(6):391‚Äì407.\\nEthayarajh, K., D. Duvenaud, and G. Hirst. 2019a. Towards\\nunderstanding linear word analogies. ACL.\\nEthayarajh, K., D. Duvenaud, and G. Hirst. 2019b. Under-\\nstanding undesirable word embedding associations. ACL.\\nFinkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin,\\nZ. Solan, G. Wolfman, and E. Ruppin. 2002.\\nPlacing\\nsearch in context: The concept revisited. ACM Trans-\\nactions on Information Systems, 20(1):116‚Äî-131.\\nFirth, J. R. 1957.\\nA synopsis of linguistic theory 1930‚Äì\\n1955. In Studies in Linguistic Analysis. Philological So-\\nciety. Reprinted in Palmer, F. (ed.) 1968. Selected Papers\\nof J. R. Firth. Longman, Harlow.\\nGarg, N., L. Schiebinger, D. Jurafsky, and J. Zou. 2018.\\nWord embeddings quantify 100 years of gender and eth-\\nnic stereotypes. Proceedings of the National Academy of\\nSciences, 115(16):E3635‚ÄìE3644.\\nGirard, G. 1718. La justesse de la langue franc¬∏oise: ou les\\ndiff¬¥erentes signiÔ¨Åcations des mots qui passent pour syn-\\nonimes. Laurent d‚ÄôHoury, Paris.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='26\\nChapter 5\\n‚Ä¢\\nEmbeddings\\nGiuliano,\\nV. E. 1965.\\nThe interpretation of word\\nassociations.\\nStatistical Association Methods For\\nMechanized\\nDocumentation.\\nSymposium\\nProceed-\\nings.\\nWashington,\\nD.C.,\\nUSA,\\nMarch\\n17,\\n1964.\\nhttps://nvlpubs.nist.gov/nistpubs/Legacy/\\nMP/nbsmiscellaneouspub269.pdf.\\nGladkova, A., A. Drozd, and S. Matsuoka. 2016. Analogy-\\nbased detection of morphological and semantic relations\\nwith word embeddings: what works and what doesn‚Äôt.\\nNAACL Student Research Workshop.\\nGlenberg, A. M. and D. A. Robertson. 2000. Symbol ground-\\ning and meaning: A comparison of high-dimensional and\\nembodied theories of meaning. Journal of memory and\\nlanguage, 43(3):379‚Äì401.\\nGonen, H. and Y. Goldberg. 2019. Lipstick on a pig: Debi-\\nasing methods cover up systematic gender biases in word\\nembeddings but do not remove them. NAACL HLT.\\nGould, S. J. 1980. The Panda‚Äôs Thumb. Penguin Group.\\nGreenwald, A. G., D. E. McGhee, and J. L. K. Schwartz.\\n1998. Measuring individual differences in implicit cogni-\\ntion: the implicit association test. Journal of personality\\nand social psychology, 74(6):1464‚Äì1480.\\nHamilton, W. L., J. Leskovec, and D. Jurafsky. 2016. Di-\\nachronic word embeddings reveal statistical laws of se-\\nmantic change. ACL.\\nHarris, Z. S. 1954. Distributional structure. Word, 10:146‚Äì\\n162.\\nHellrich,\\nJ. and U. Hahn. 2016.\\nBad company‚Äî\\nNeighborhoods in neural embedding spaces considered\\nharmful. COLING.\\nHill, F., R. Reichart, and A. Korhonen. 2015. Simlex-999:\\nEvaluating semantic models with (genuine) similarity es-\\ntimation. Computational Linguistics, 41(4):665‚Äì695.\\nHjelmslev, L. 1969. Prologomena to a Theory of Language.\\nUniversity of Wisconsin Press. Translated by Francis J.\\nWhitÔ¨Åeld; original Danish edition 1943.\\nHofmann, T. 1999. Probabilistic latent semantic indexing.\\nSIGIR-99.\\nHuang, E. H., R. Socher, C. D. Manning, and A. Y. Ng. 2012.\\nImproving word representations via global context and\\nmultiple word prototypes. ACL.\\nJia, S., T. Meng, J. Zhao, and K.-W. Chang. 2020. Mitigat-\\ning gender bias ampliÔ¨Åcation in distribution by posterior\\nregularization. ACL.\\nJones, M. P. and J. H. Martin. 1997. Contextual spelling cor-\\nrection using latent semantic analysis. ANLP.\\nJoos, M. 1950.\\nDescription of language design.\\nJASA,\\n22:701‚Äì708.\\nJurgens, D., S. M. Mohammad, P. Turney, and K. Holyoak.\\n2012. SemEval-2012 task 2: Measuring degrees of rela-\\ntional similarity. *SEM 2012.\\nKatz, J. J. and J. A. Fodor. 1963. The structure of a semantic\\ntheory. Language, 39:170‚Äì210.\\nKiela, D. and S. Clark. 2014. A systematic study of semantic\\nvector space model parameters. EACL 2nd Workshop on\\nContinuous Vector Space Models and their Composition-\\nality (CVSC).\\nKim,\\nE.\\n2019.\\nOptimize\\ncomputational\\nefÔ¨Åciency\\nof skip-gram with negative sampling.\\nhttps://\\naegis4048.github.io/optimize_computational_\\nefficiency_of_skip-gram_with_negative_\\nsampling.\\nLake, B. M. and G. L. Murphy. 2021.\\nWord meaning in\\nminds and machines. Psychological Review. In press.\\nLandauer, T. K. and S. T. Dumais. 1997. A solution to Plato‚Äôs\\nproblem: The Latent Semantic Analysis theory of acqui-\\nsition, induction, and representation of knowledge. Psy-\\nchological Review, 104:211‚Äì240.\\nLandauer, T. K., D. Laham, B. Rehder, and M. E. Schreiner.\\n1997. How well can passage meaning be derived with-\\nout using word order? A comparison of Latent Semantic\\nAnalysis and humans. COGSCI.\\nLapesa, G. and S. Evert. 2014. A large scale evaluation of\\ndistributional semantic models: Parameters, interactions\\nand model selection. TACL, 2:531‚Äì545.\\nLee, D. D. and H. S. Seung. 1999. Learning the parts of\\nobjects by non-negative matrix factorization.\\nNature,\\n401(6755):788‚Äì791.\\nLevy, O. and Y. Goldberg. 2014a. Dependency-based word\\nembeddings. ACL.\\nLevy, O. and Y. Goldberg. 2014b. Linguistic regularities in\\nsparse and explicit word representations. CoNLL.\\nLevy, O. and Y. Goldberg. 2014c. Neural word embedding\\nas implicit matrix factorization. NeurIPS.\\nLevy, O., Y. Goldberg, and I. Dagan. 2015. Improving dis-\\ntributional similarity with lessons learned from word em-\\nbeddings. TACL, 3:211‚Äì225.\\nLin, Y., J.-B. Michel, E. Lieberman Aiden, J. Orwant,\\nW. Brockman, and S. Petrov. 2012. Syntactic annotations\\nfor the Google Books NGram corpus. ACL.\\nLinzen, T. 2016. Issues in evaluating semantic spaces us-\\ning word analogies. 1st Workshop on Evaluating Vector-\\nSpace Representations for NLP.\\nManning, C. D., P. Raghavan, and H. Sch¬®utze. 2008. Intro-\\nduction to Information Retrieval. Cambridge.\\nMikolov, T., K. Chen, G. S. Corrado, and J. Dean. 2013a. Ef-\\nÔ¨Åcient estimation of word representations in vector space.\\nICLR 2013.\\nMikolov, T., S. Kombrink, L. Burget, J. H. ÀáCernock`y, and\\nS. Khudanpur. 2011. Extensions of recurrent neural net-\\nwork language model. ICASSP.\\nMikolov, T., I. Sutskever, K. Chen, G. S. Corrado, and\\nJ. Dean. 2013b. Distributed representations of words and\\nphrases and their compositionality. NeurIPS.\\nMikolov, T., W.-t. Yih, and G. Zweig. 2013c.\\nLinguis-\\ntic regularities in continuous space word representations.\\nNAACL HLT.\\nNosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002a.\\nHarvesting implicit group attitudes and beliefs from a\\ndemonstration web site. Group Dynamics: Theory, Re-\\nsearch, and Practice, 6(1):101.\\nNosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002b.\\nMath=male, me=female, therefore mathÃ∏= me. Journal of\\npersonality and social psychology, 83(1):44.\\nOsgood, C. E., G. J. Suci, and P. H. Tannenbaum. 1957. The\\nMeasurement of Meaning. University of Illinois Press.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': './data/embeddings.pdf', 'file_path': './data/embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 26}, page_content='Exercises\\n27\\nPennington, J., R. Socher, and C. D. Manning. 2014. GloVe:\\nGlobal vectors for word representation. EMNLP.\\nPeterson, J. C., D. Chen, and T. L. GrifÔ¨Åths. 2020. Parallelo-\\ngrams revisited: Exploring the limitations of vector space\\nmodels for simple analogies. Cognition, 205.\\nPilehvar, M. T. and J. Camacho-Collados. 2019. WiC: the\\nword-in-context dataset for evaluating context-sensitive\\nmeaning representations. NAACL HLT.\\nRehder, B., M. E. Schreiner, M. B. W. Wolfe, D. Laham,\\nT. K. Landauer, and W. Kintsch. 1998.\\nUsing Latent\\nSemantic Analysis to assess knowledge: Some technical\\nconsiderations. Discourse Processes, 25(2-3):337‚Äì354.\\nRohde, D. L. T., L. M. Gonnerman, and D. C. Plaut. 2006.\\nAn improved model of semantic similarity based on lexi-\\ncal co-occurrence. CACM, 8:627‚Äì633.\\nRumelhart, D. E. and A. A. Abrahamson. 1973. A model for\\nanalogical reasoning. Cognitive Psychology, 5(1):1‚Äì28.\\nSalton, G. 1971. The SMART Retrieval System: Experiments\\nin Automatic Document Processing. Prentice Hall.\\nSchluter, N. 2018. The word analogy testing caveat. NAACL\\nHLT.\\nSchone, P. and D. Jurafsky. 2000. Knowlege-free induction\\nof morphology using latent semantic analysis. CoNLL.\\nSchone, P. and D. Jurafsky. 2001a. Is knowledge-free in-\\nduction of multiword unit dictionary headwords a solved\\nproblem? EMNLP.\\nSchone, P. and D. Jurafsky. 2001b. Knowledge-free induc-\\ntion of inÔ¨Çectional morphologies. NAACL.\\nSch¬®utze, H. 1992. Dimensions of meaning. Proceedings of\\nSupercomputing ‚Äô92. IEEE Press.\\nSch¬®utze, H. 1997. Ambiguity Resolution in Language Learn-\\ning ‚Äì Computational and Cognitive Models. CSLI, Stan-\\nford, CA.\\nSch¬®utze, H., D. A. Hull, and J. Pedersen. 1995. A compar-\\nison of classiÔ¨Åers and document representations for the\\nrouting problem. SIGIR-95.\\nSch¬®utze, H. and J. Pedersen. 1993. A vector model for syn-\\ntagmatic and paradigmatic relatedness. 9th Annual Con-\\nference of the UW Centre for the New OED and Text Re-\\nsearch.\\nSparck Jones, K. 1972. A statistical interpretation of term\\nspeciÔ¨Åcity and its application in retrieval. Journal of Doc-\\numentation, 28(1):11‚Äì21.\\nSparck Jones, K. 1986. Synonymy and Semantic ClassiÔ¨Åca-\\ntion. Edinburgh University Press, Edinburgh. Republica-\\ntion of 1964 PhD Thesis.\\nSwitzer, P. 1965.\\nVector images in document retrieval.\\nStatistical Association Methods For Mechanized Docu-\\nmentation. Symposium Proceedings. Washington, D.C.,\\nUSA, March 17, 1964. https://nvlpubs.nist.gov/\\nnistpubs/Legacy/MP/nbsmiscellaneouspub269.\\npdf.\\nTian, Y., V. Kulkarni, B. Perozzi, and S. Skiena. 2016. On\\nthe convergent properties of word embedding methods.\\nArXiv preprint arXiv:1605.03956.\\nTurian, J., L. Ratinov, and Y. Bengio. 2010. Word represen-\\ntations: a simple and general method for semi-supervised\\nlearning. ACL.\\nTurney, P. D. and M. L. Littman. 2005. Corpus-based learn-\\ning of analogies and semantic relations. Machine Learn-\\ning, 60(1-3):251‚Äì278.\\nvan der Maaten, L. and G. E. Hinton. 2008. Visualizing high-\\ndimensional data using t-SNE. JMLR, 9:2579‚Äì2605.\\nWierzbicka, A. 1992. Semantics, Culture, and Cognition:\\nUniversity Human Concepts in Culture-SpeciÔ¨Åc ConÔ¨Ågu-\\nrations. Oxford University Press.\\nWierzbicka, A. 1996. Semantics: Primes and Universals.\\nOxford University Press.\\nWittgenstein, L. 1953. Philosophical Investigations. (Trans-\\nlated by Anscombe, G.E.M.). Blackwell.\\nZhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-\\nW. Chang. 2017.\\nMen also like shopping: Reducing\\ngender bias ampliÔ¨Åcation using corpus-level constraints.\\nEMNLP.\\nZhao, J., Y. Zhou, Z. Li, W. Wang, and K.-W. Chang. 2018.\\nLearning gender-neutral word embeddings. EMNLP.')]\n"
     ]
    }
   ],
   "source": [
    "pdf_loader = PyMuPDFLoader('./data/embeddings.pdf')\n",
    "documents = pdf_loader.load()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79f217",
   "metadata": {},
   "source": [
    "RAG Full PipeLine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a39f49b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "def process_all_pdf(pdf_directory):\n",
    "    all_documents = []\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "\n",
    "    print(f\"found {len(pdf_files)} pdf files to process\") \n",
    "\n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\" processing {pdf_file.name}\")\n",
    "        loader = PyMuPDFLoader(str(pdf_file))\n",
    "        document = loader.load()\n",
    "\n",
    "        for doc in document:\n",
    "            doc.metadata['source'] = pdf_file.name\n",
    "        \n",
    "        all_documents.extend(document)\n",
    "\n",
    "        \n",
    "    return all_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a760d966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 2 pdf files to process\n",
      " processing Darshan_resume.pdf\n",
      " processing embeddings.pdf\n",
      "[Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 0}, page_content='Darshan Hiremath \\n8904691801 | darshanah2002@gmail.com \\n \\nProfile \\nAI & Machine Learning enthusiast with hands-on experience in Statistical Models, Transformer \\nModels, and Large Language Models (LLMs). Passionate about model explainability, fine-tuning \\ntechniques, and AI-powered applications. Skilled in integrating LIME, SHAP, and LLMs (GPT-\\n4, Gemini AI) to enhance interpretability. Experienced in efficient fine-tuning (LoRA, PEFT) and \\noptimizing large models for real-world use. \\n \\nTechnical Skills \\nProgramming: Python \\n‚Ä¢ \\nExplainable AI: SHAP, LIME, Grad-CAM, Integrated Gradients \\n‚Ä¢ \\nLLM : Llama 3.1  \\n‚Ä¢ \\nDeep Learning: CNNs, Transformers, LLMs   \\n‚Ä¢ \\nNLP Models: GPT-2, DistilBERT   \\n‚Ä¢ \\nLLM Fine-Tuning: LoRA, PEFT, Quantization (4-bit, 8-bit)   \\n‚Ä¢ \\nFrameworks: PyTorch, TensorFlow , Hugging Face   \\n‚Ä¢ \\nTools: Gemini AI, GPT-4   \\n‚Ä¢ \\nDomains: XAI, NLP, Deep Learning , Model Interpretability \\n \\nWork Experience \\nAI & Machine Learning Engineer   \\nL&T Technology Services | July 2024 ‚Äì Present   \\n \\nExplainable AI ‚Äì Statistical Models (Honda Use Case) \\n\\uf0b7 \\nApplied LIME and SHAP to explain predictions of a statistical sensor-based quality \\nmodel (Gx, Gy, Gz). \\n\\uf0b7 \\nDelivered instance-level and global feature attributions for ‚ÄúGood / No-Good‚Äù \\nclassifications. \\n\\uf0b7 \\nIntegrated GPT-4 and Gemini AI to automatically convert XAI outputs into \\nbusiness-friendly explanations for non-technical stakeholders. \\n\\uf0b7 \\nPresented explainability results through visual reports and demo videos to cross-\\nfunctional teams. \\n \\nExplainability in Transformer Models \\n\\uf0b7 Investigated feasibility of applying SHAP to transformer architectures. \\n\\uf0b7 Fine-tuned GPT-2 and DistilBERT on Amazon Reviews for sentiment \\nclassification. \\n\\uf0b7 Identified and resolved incorrect attribution issues by improving fine-tuning strategy. \\n\\uf0b7 Successfully generated token-level and feature-level explanations for transformer \\npredictions. \\n \\nExploration of LLMs & Efficient Fine-Tuning \\n\\uf0b7 Explored explainability extensions for Large Language Models (LLMs). \\n\\uf0b7 Experimented with 4-bit and 8-bit quantized model loading for memory-efficient \\ninference. \\n\\uf0b7 Implemented PEFT techniques, including LoRA, to fine-tune LLMs with reduced \\ncompute cost. \\n\\uf0b7 Evaluated trade-offs between performance, memory usage, and interpretability.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 1}, page_content='Hackathon  \\n\\uf0b7 \\nParticipated in L&T internal hackathon focused on applied AI solutions. \\n\\uf0b7 \\nImplemented Grad-CAM on ResNet for eye disease classification, highlighting \\nclass-discriminative regions. \\n\\uf0b7 \\nDemonstrated how CNN models learn visual patterns and validated predictions using \\nsaliency maps. \\nEDUCATION \\nBapuji Institute Of Engineering And Technology                                                    2020 ‚Äì 2024 \\nComputer Science & Engineering                                                                              \\n7.8/10 CGPA  \\nVishwaachetana Vidyaniketana Pu College                                                              2018 - 2020 \\n 73 percent  \\nOM National PU College                                                                                          2018 \\n71 percent'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 2}, page_content=''), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 0}, page_content='Speech and Language Processing.\\nDaniel Jurafsky & James H. Martin.\\nCopyright ¬© 2025.\\nAll\\nrights reserved.\\nDraft of August 24, 2025.\\nCHAPTER\\n5\\nEmbeddings\\nËçÉËÄÖÊâÄ‰ª•Âú®È±ºÔºåÂæóÈ±ºËÄåÂøòËçÉNets are for Ô¨Åsh;\\nOnce you get the Ô¨Åsh, you can forget the net.\\nË®ÄËÄÖÊâÄ‰ª•Âú®ÊÑèÔºåÂæóÊÑèËÄåÂøòË®ÄWords are for meaning;\\nOnce you get the meaning, you can forget the words\\nÂ∫ÑÂ≠ê(Zhuangzi), Chapter 26\\nThe asphalt that Los Angeles is famous for occurs mainly on its freeways. But\\nin the middle of the city is another patch of asphalt, the La Brea tar pits, and this\\nasphalt preserves millions of fossil bones from the last of the Ice Ages of the Pleis-\\ntocene Epoch. One of these fossils is the Smilodon, or saber-toothed tiger, instantly\\nrecognizable by its long canines. Five million years ago or so, a completely different\\nsaber-tooth tiger called Thylacosmilus lived\\nin Argentina and other parts of South Amer-\\nica. Thylacosmilus was a marsupial whereas\\nSmilodon was a placental mammal, but Thy-\\nlacosmilus had the same long upper canines\\nand, like Smilodon, had a protective bone\\nÔ¨Çange on the lower jaw.\\nThe similarity of\\nthese two mammals is one of many examples\\nof parallel or convergent evolution, in which particular contexts or environments\\nlead to the evolution of very similar structures in different species (Gould, 1980).\\nThe role of context is also important in the similarity of a less biological kind\\nof organism: the word. Words that occur in similar contexts tend to have similar\\nmeanings. This link between similarity in how words are distributed and similarity\\nin what they mean is called the distributional hypothesis. The hypothesis was\\ndistributional\\nhypothesis\\nÔ¨Årst formulated in the 1950s by linguists like Joos (1950), Harris (1954), and Firth\\n(1957), who noticed that words which are synonyms (like oculist and eye-doctor)\\ntended to occur in the same environment (e.g., near words like eye or examined)\\nwith the amount of meaning difference between two words ‚Äúcorresponding roughly\\nto the amount of difference in their environments‚Äù (Harris, 1954, p. 157).\\nIn this chapter we introduce embeddings, vector representations of the meaning\\nembeddings\\nof words that are learned directly from word distributions in texts. Embeddings lie\\nat the heart of large language models and other modern applications. The static em-\\nbeddings we introduce here underlie the more powerful dynamic or contextualized\\nembeddings like BERT that we will see in Chapter 10 and Chapter 8.\\nThe linguistic Ô¨Åeld that studies embeddings and their meanings is called vector\\nsemantics. Embeddings are also the Ô¨Årst example in this book of representation\\nvector\\nsemantics\\nlearning, automatically learning useful representations of the input text. Finding\\nrepresentation\\nlearning\\nsuch self-supervised ways to learn representations of language, instead of creat-\\ning representations by hand via feature engineering, is an important principle of\\nmodern NLP (Bengio et al., 2013).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 1}, page_content='2\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n5.1\\nLexical Semantics\\nLet‚Äôs begin by introducing some basic principles of word meaning. How should\\nwe represent the meaning of a word? In the n-gram models of Chapter 3, and in\\nclassical NLP applications, our only representation of a word is as a string of letters,\\nor an index in a vocabulary list. This representation is not that different from a\\ntradition in philosophy, perhaps you‚Äôve seen it in introductory logic classes, in which\\nthe meaning of words is represented by just spelling the word with small capital\\nletters; representing the meaning of ‚Äúdog‚Äù as DOG, and ‚Äúcat‚Äù as CAT, or by using an\\napostrophe (DOG‚Äô).\\nRepresenting the meaning of a word by capitalizing it is a pretty unsatisfactory\\nmodel. You might have seen a version of a joke due originally to semanticist Barbara\\nPartee (Carlson, 1977):\\nQ: What‚Äôs the meaning of life?\\nA: LIFE‚Äô\\nSurely we can do better than this! After all, we‚Äôll want a model of word meaning\\nto do all sorts of things for us. It should tell us that some words have similar mean-\\nings (cat is similar to dog), others are antonyms (cold is the opposite of hot), some\\nhave positive connotations (happy) while others have negative connotations (sad). It\\nshould represent the fact that the meanings of buy, sell, and pay offer differing per-\\nspectives on the same underlying purchasing event. (If I buy something from you,\\nyou‚Äôve probably sold it to me, and I likely paid you.) More generally, a model of\\nword meaning should allow us to draw inferences to address meaning-related tasks\\nlike question-answering or dialogue.\\nIn this section we summarize some of these desiderata, drawing on results in the\\nlinguistic study of word meaning, which is called lexical semantics; we‚Äôll return to\\nlexical\\nsemantics\\nand expand on this list in Appendix G and Chapter 21.\\nLemmas and Senses\\nLet‚Äôs start by looking at how one word (we‚Äôll choose mouse)\\nmight be deÔ¨Åned in a dictionary (simpliÔ¨Åed from the online dictionary WordNet):\\nmouse (N)\\n1.\\nany of numerous small rodents...\\n2.\\na hand-operated device that controls a cursor...\\nHere the form mouse is the lemma, also called the citation form. The form\\nlemma\\ncitation form\\nmouse would also be the lemma for the word mice; dictionaries don‚Äôt have separate\\ndeÔ¨Ånitions for inÔ¨Çected forms like mice. Similarly sing is the lemma for sing, sang,\\nsung. In many languages the inÔ¨Ånitive form is used as the lemma for the verb, so\\nSpanish dormir ‚Äúto sleep‚Äù is the lemma for duermes ‚Äúyou sleep‚Äù. The speciÔ¨Åc forms\\nsung or carpets or sing or duermes are called wordforms.\\nwordform\\nAs the example above shows, each lemma can have multiple meanings; the\\nlemma mouse can refer to the rodent or the cursor control device. We call each\\nof these aspects of the meaning of mouse a word sense. The fact that lemmas can\\nbe polysemous (have multiple senses) can make interpretation difÔ¨Åcult (is some-\\none who searches for ‚Äúmouse info‚Äù looking for a pet or a widget?). Chapter 10\\nand Appendix G will discuss the problem of polysemy, and introduce word sense\\ndisambiguation, the task of determining which sense of a word is being used in a\\nparticular context.\\nSynonymy\\nOne important component of word meaning is the relationship be-\\ntween word senses. For example when one word has a sense whose meaning is'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 2}, page_content='5.1\\n‚Ä¢\\nLEXICAL SEMANTICS\\n3\\nidentical to a sense of another word, or nearly identical, we say the two senses of\\nthose two words are synonyms. Synonyms include such pairs as\\nsynonym\\ncouch/sofa vomit/throw up Ô¨Ålbert/hazelnut car/automobile\\nA more formal deÔ¨Ånition of synonymy (between words rather than senses) is that\\ntwo words are synonymous if they are substitutable for one another in any sentence\\nwithout changing the truth conditions of the sentence, the situations in which the\\nsentence would be true.\\nWhile substitutions between some pairs of words like car / automobile or wa-\\nter / H2O are truth preserving, the words are still not identical in meaning. Indeed,\\nprobably no two words are absolutely identical in meaning. One of the fundamental\\ntenets of semantics, called the principle of contrast (Girard 1718, Br¬¥eal 1897, Clark\\nprinciple of\\ncontrast\\n1987), states that a difference in linguistic form is always associated with some dif-\\nference in meaning. For example, the word H2O is used in scientiÔ¨Åc contexts and\\nwould be inappropriate in a hiking guide‚Äîwater would be more appropriate‚Äî and\\nthis genre difference is part of the meaning of the word. In practice, the word syn-\\nonym is therefore used to describe a relationship of approximate or rough synonymy.\\nWord Similarity\\nWhile words don‚Äôt have many synonyms, most words do have\\nlots of similar words. Cat is not a synonym of dog, but cats and dogs are certainly\\nsimilar words. In moving from synonymy to similarity, it will be useful to shift from\\ntalking about relations between word senses (like synonymy) to relations between\\nwords (like similarity). Dealing with words avoids having to commit to a particular\\nrepresentation of word senses, which will turn out to simplify our task.\\nThe notion of word similarity is very useful in larger semantic tasks. Knowing\\nsimilarity\\nhow similar two words are can help in computing how similar the meaning of two\\nphrases or sentences are, a very important component of tasks like question answer-\\ning, paraphrasing, and summarization. One way of getting values for word similarity\\nis to ask humans to judge how similar one word is to another. A number of datasets\\nhave resulted from such experiments. For example the SimLex-999 dataset (Hill\\net al., 2015) gives values on a scale from 0 to 10, like the examples below, which\\nrange from near-synonyms (vanish, disappear) to pairs that scarcely seem to have\\nanything in common (hole, agreement):\\nvanish\\ndisappear\\n9.8\\nbelief\\nimpression 5.95\\nmuscle bone\\n3.65\\nmodest Ô¨Çexible\\n0.98\\nhole\\nagreement\\n0.3\\nWord Relatedness\\nThe meaning of two words can be related in ways other than\\nsimilarity. One such class of connections is called word relatedness (Budanitsky\\nrelatedness\\nand Hirst, 2006), also traditionally called word association in psychology.\\nassociation\\nConsider the meanings of the words coffee and cup. Coffee is not similar to cup;\\nthey share practically no features (coffee is a plant or a beverage, while a cup is a\\nmanufactured object with a particular shape). But coffee and cup are clearly related;\\nthey are associated by co-participating in an everyday event (the event of drinking\\ncoffee out of a cup). Similarly scalpel and surgeon are not similar but are related\\neventively (a surgeon tends to make use of a scalpel).\\nOne common kind of relatedness between words is if they belong to the same\\nsemantic Ô¨Åeld. A semantic Ô¨Åeld is a set of words which cover a particular semantic\\nsemantic Ô¨Åeld\\ndomain and bear structured relations with each other. For example, words might be'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 3}, page_content='4\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nrelated by being in the semantic Ô¨Åeld of hospitals (surgeon, scalpel, nurse, anes-\\nthetic, hospital), restaurants (waiter, menu, plate, food, chef), or houses (door, roof,\\nkitchen, family, bed). Semantic Ô¨Åelds are also related to topic models, like Latent\\ntopic models\\nDirichlet Allocation, LDA, which apply unsupervised learning on large sets of texts\\nto induce sets of associated words from text. Semantic Ô¨Åelds and topic models are\\nvery useful tools for discovering topical structure in documents.\\nIn Appendix G we‚Äôll introduce more relations between senses like hypernymy\\nor IS-A, antonymy (opposites) and meronymy (part-whole relations).\\nConnotation\\nFinally, words have affective meanings or connotations. The word\\nconnotations\\nconnotation has different meanings in different Ô¨Åelds, but here we use it to mean the\\naspects of a word‚Äôs meaning that are related to a writer or reader‚Äôs emotions, senti-\\nment, opinions, or evaluations. For example some words have positive connotations\\n(wonderful) while others have negative connotations (dreary). Even words whose\\nmeanings are similar in other ways can vary in connotation; consider the difference\\nin connotations between fake, knockoff, forgery, on the one hand, and copy, replica,\\nreproduction on the other, or innocent (positive connotation) and naive (negative\\nconnotation). Some words describe positive evaluation (great, love) and others neg-\\native evaluation (terrible, hate). Positive or negative evaluation language is called\\nsentiment, as we saw in Appendix K, and word sentiment plays a role in impor-\\nsentiment\\ntant tasks like sentiment analysis, stance detection, and applications of NLP to the\\nlanguage of politics and consumer reviews.\\nEarly work on affective meaning (Osgood et al., 1957) found that words varied\\nalong three important dimensions of affective meaning:\\nvalence: the pleasantness of the stimulus\\narousal: the intensity of emotion provoked by the stimulus\\ndominance: the degree of control exerted by the stimulus\\nThus words like happy or satisÔ¨Åed are high on valence, while unhappy or an-\\nnoyed are low on valence. Excited is high on arousal, while calm is low on arousal.\\nControlling is high on dominance, while awed or inÔ¨Çuenced are low on dominance.\\nEach word is thus represented by three numbers, corresponding to its value on each\\nof the three dimensions:\\nValence Arousal Dominance\\ncourageous 8.0\\n5.5\\n7.4\\nmusic\\n7.7\\n5.6\\n6.5\\nheartbreak\\n2.5\\n5.7\\n3.6\\ncub\\n6.7\\n4.0\\n4.2\\nOsgood et al. (1957) noticed that in using these 3 numbers to represent the\\nmeaning of a word, the model was representing each word as a point in a three-\\ndimensional space, a vector whose three dimensions corresponded to the word‚Äôs\\nrating on the three scales. This revolutionary idea that word meaning could be rep-\\nresented as a point in space (e.g., that part of the meaning of heartbreak can be\\nrepresented as the point [2.5,5.7,3.6]) was the Ô¨Årst expression of the vector seman-\\ntics models that we introduce next.\\n5.2\\nVector Semantics: The Intuition\\nVector semantics is the standard way to represent word meaning in NLP, helping\\nvector\\nsemantics'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 4}, page_content='5.2\\n‚Ä¢\\nVECTOR SEMANTICS: THE INTUITION\\n5\\nus model many of the aspects of word meaning we saw in the previous section. The\\nroots of the model lie in the 1950s when two big ideas converged: Osgood‚Äôs 1957\\nidea mentioned above to use a point in three-dimensional space to represent the\\nconnotation of a word, and the proposal by linguists like Joos (1950), Harris (1954),\\nand Firth (1957) to deÔ¨Åne the meaning of a word by its distribution in language\\nuse, meaning its neighboring words or grammatical environments. Their idea was\\nthat two words that occur in very similar distributions (whose neighboring words are\\nsimilar) have similar meanings.\\nFor example, suppose you didn‚Äôt know the meaning of the word ongchoi (a re-\\ncent borrowing from Cantonese) but you see it in the following contexts:\\n(5.1) Ongchoi is delicious sauteed with garlic.\\n(5.2) Ongchoi is superb over rice.\\n(5.3) ...ongchoi leaves with salty sauces...\\nAnd suppose that you had seen many of these context words in other contexts:\\n(5.4) ...spinach sauteed with garlic over rice...\\n(5.5) ...chard stems and leaves are delicious...\\n(5.6) ...collard greens and other salty leafy greens\\nThe fact that ongchoi occurs with words like rice and garlic and delicious and\\nsalty, as do words like spinach, chard, and collard greens might suggest that ongchoi\\nis a leafy green similar to these other leafy greens.1 We can implement the same\\nintuition computationally by just counting words in the context of ongchoi.\\nFigure 5.1\\nA two-dimensional (t-SNE) visualization of 200-dimensional word2vec em-\\nbeddings for some words close to the word sweet, showing that words with similar mean-\\nings are nearby in space. Visualization created using the TensorBoard Embedding Projector\\nhttps://projector.tensorflow.org/.\\nThe idea of vector semantics is to represent a word as a point in a multidimen-\\nsional semantic space that is derived (in different ways we‚Äôll see) from the distri-\\nbutions of word neighbors. Vectors for representing words are called embeddings.\\nembeddings\\nThe word ‚Äúembedding‚Äù derives historically from its mathematical sense as a map-\\nping from one space or structure to another, although the meaning has shifted; see\\nthe end of the chapter.\\nFig. 5.1 shows a visualization of embeddings learned by the word2vec algorithm,\\nshowing the location of selected words (neighbors of ‚Äúsweet‚Äù) projected down from\\n1\\nIt‚Äôs in fact Ipomoea aquatica, a relative of morning glory sometimes called water spinach in English.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 5}, page_content='6\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n200-dimensional space into a 2-dimensional space. Note that the nearest neighbors\\nof sweet are semantically related words like honey, candy, juice, chocolate. This idea\\nthat similar words are near each other in high-dimensional space is an important\\nthat offers enormous power to language models and other NLP applications. For\\nexample the sentiment classiÔ¨Åers of Chapter 4 depend on the same words appearing\\nin the training and test sets. But by representing words as embeddings, a classiÔ¨Åer\\ncan assign sentiment as long as it sees some words with similar meanings. And as\\nwe‚Äôll see, vector semantic models like the ones showed in Fig. 5.1 can be learned\\nautomatically from text without supervision.\\nIn this chapter we‚Äôll begin with a simple pedagogical model of embeddings in\\nwhich the meaning of a word is deÔ¨Åned by a vector with the counts of nearby words.\\nWe introduce this model as a helpful way to understand the concept of vectors and\\nwhat it means for a vector to be a representation of word meaning, but more sophis-\\nticated variants like the tf-idf model we will introduce in Chapter 11 are important\\nmethods you should understand. We will see that this method results in very long\\nvectors that are sparse, i.e. mostly zeros (since most words simply never occur in the\\ncontext of others). We‚Äôll then introduce the word2vec model family for constructing\\nshort, dense vectors that have even more useful semantic properties.\\nWe‚Äôll also introduce the cosine, the standard way to use embeddings to com-\\npute semantic similarity, between two words, two sentences, or two documents, an\\nimportant tool in practical applications.\\n5.3\\nSimple count-based embeddings\\n‚ÄúThe most important attributes of a vector in 3-space are {Location, Location, Location}‚Äù\\nRandall Munroe, the hover from https://xkcd.com/2358/\\nLet‚Äôs now introduce the Ô¨Årst way to compute word vector embeddings. This sim-\\nplest vector model of meaning is based on the co-occurrence matrix, a way of rep-\\nresenting how often words co-occur. We‚Äôll deÔ¨Åne a particular kind of co-occurrence\\nmatrix, the word-context matrix, in which each row in the matrix represents a word\\nword-context\\nmatrix\\nin the vocabulary and each column represents how often each other word in the vo-\\ncabulary appears nearby. This matrix is thus of dimensionality |V| √ó |V| and each\\ncell records the number of times the row (target) word and the column (context)\\nword co-occur nearby in some training corpus.\\nWhat do we mean by ‚Äònearby‚Äô? We could implement various methods, but let‚Äôs\\nstart with a very simple one: a context window around the word, let‚Äôs say of 4 words\\nto the left and 4 words to the right. If we do that, each cell will represents the\\nnumber of times (in some training corpus) the column word occurs in such a ¬±4\\nword window around the row word.\\nLet‚Äôs see how this works for 4 words: cherry, strawberry, digital, and informa-\\ntion. For each word we took a single instance from a corpus, and we show the ¬±4\\nword window from that instance:\\nis traditionally followed by cherry\\npie, a traditional dessert\\noften mixed, such as strawberry\\nrhubarb pie. Apple pie\\ncomputer peripherals and personal digital\\nassistants. These devices usually\\na computer. This includes information available on the internet\\nIf we then take every occurrence of each word in a large corpus and count the\\ncontext words around it, we get a word-context co-occurrence matrix. The full word-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 6}, page_content='5.3\\n‚Ä¢\\nSIMPLE COUNT-BASED EMBEDDINGS\\n7\\ncontext co-occurrence matrix is very large, because for each word in the vocabulary\\n(since |V|) we have to count how often it occurs with every other word in the vo-\\ncabulary, hence dimensionality |V|√ó|V|. Let‚Äôs therefore instead sketch the process\\non a smaller scale. Imagine that we are going to look at only the 4 words, and only\\nconsider the following 3 context words: a, computer, and pie. Furthermore let‚Äôs\\nassume we only count occurrences in the mini-corpus above.\\nSo before looking at Fig. 5.2, compute by hand the counts for these 3 context\\nwords for the four words cherry, strawberry, digital, and information.\\na\\ncomputer\\npie\\ncherry\\n1\\n0\\n1\\nstrawberry\\n0\\n0\\n2\\ndigital\\n0\\n1\\n0\\ninformation\\n1\\n1\\n0\\nFigure 5.2\\nCo-occurrence vectors for four words with counts from the 4 windows above,\\nshowing just 3 of the potential context word dimensions. The vector for cherry is outlined in\\nred. Note that a real vector would have vastly more dimensions and thus be even sparser.\\nHopefully your count matches what is shown in Fig. 5.2, so that each cell repre-\\nsents the number of times a particular word (deÔ¨Åned by the row) occurs in a partic-\\nular context (deÔ¨Åned by the word column).\\nEach row, then, is a vector representing a word. To review some basic linear\\nalgebra, a vector is, at heart, just a list or array of numbers. So cherry is represented\\nvector\\nas the list [1,0,1] (the Ô¨Årst row vector in Fig. 5.2) and information is represented as\\nthe list [1,1,0] (the fourth row vector).\\nA vector space is a collection of vectors, and is characterized by its dimension.\\nvector space\\ndimension\\nVectors in a 3-dimensional vector space have an element for each dimension of the\\nspace. We will loosely refer to a vector in a 3-dimensional space as a 3-dimensional\\nvector, with one element along each dimension. In the example in Fig. 5.2, we‚Äôve\\nchosen to make the document vectors of dimension 3, just so they Ô¨Åt on the page; in\\nreal term-document matrices, the document vectors would have dimensionality |V|,\\nthe vocabulary size.\\nThe ordering of the numbers in a vector space indicates the different dimensions\\non which documents vary. The third dimension for all these vectors corresponds\\nto the number of times pie occurs in the context. The second dimension for all of\\nthem corresponds to the number of times the word computer occurs. Notice that\\nthe vectors for information and digital have the same value (1) for this ‚Äúcomputer‚Äù\\ndimension.\\nIn reality, we don‚Äôt compute word vectors on a single context window. Instead,\\nwe compute them over an entire corpus. Let‚Äôs see what some real counts look like.\\nLet‚Äôs look at some vectors computed in this way. Fig. 5.3 shows a subset of the\\nword-word co-occurrence matrix for these four words, where, again because it‚Äôs\\nimpossible to visualize all |V| possible context words on the page of this textbook,\\nwe show a subset of 6 of the dimensions, with counts computed from the Wikipedia\\ncorpus (Davies, 2015).\\nNote in Fig. 5.3 that the two words cherry and strawberry are more similar to\\neach other (both pie and sugar tend to occur in their window) than they are to other\\nwords like digital; conversely, digital and information are more similar to each other\\nthan, say, to strawberry.\\nWe can think of the vector for a document as a point in |V|-dimensional space;\\nthus the documents in Fig. 5.3 are points in 3-dimensional space. Fig. 5.4 shows a\\nspatial visualization.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 7}, page_content='8\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\naardvark\\n...\\ncomputer\\ndata\\nresult\\npie\\nsugar\\n...\\ncherry\\n0\\n...\\n2\\n8\\n9\\n442\\n25\\n...\\nstrawberry\\n0\\n...\\n0\\n0\\n1\\n60\\n19\\n...\\ndigital\\n0\\n...\\n1670\\n1683\\n85\\n5\\n4\\n...\\ninformation\\n0\\n...\\n3325\\n3982\\n378\\n5\\n13\\n...\\nFigure 5.3\\nCo-occurrence vectors for four words in the Wikipedia corpus, showing six of\\nthe dimensions (hand-picked for pedagogical purposes). The vector for digital is outlined in\\nred. Note that a real vector would have vastly more dimensions and thus be much sparser, i.e.\\nwould have zero values in most dimensions.\\n1000 2000 3000 4000\\n1000\\n2000\\ndigital\\n [1683,1670]\\ncomputer\\n data\\ninformation\\n [3982,3325] \\n3000\\n4000\\nFigure 5.4\\nA spatial visualization of word vectors for digital and information, showing just\\ntwo of the dimensions, corresponding to the words data and computer.\\nNote that |V|, the dimensionality of the vector, is generally the size of the vo-\\ncabulary, often between 10,000 and 50,000 words (using the most frequent words\\nin the training corpus; keeping words after about the most frequent 50,000 or so is\\ngenerally not helpful). Since most of these numbers are zero these are sparse vector\\nrepresentations; there are efÔ¨Åcient algorithms for storing and computing with sparse\\nmatrices.\\nIt‚Äôs also possible to applying various kinds of weighting functions to the counts\\nin these cells. The most popular such weighting is tf-idf, which we‚Äôll introduce in\\nChapter 11, but there have historically been a wide variety of other weightings.\\nNow that we have some intuitions, let‚Äôs move on to examine the details of com-\\nputing word similarity.\\n5.4\\nCosine for measuring similarity\\nTo measure similarity between two target words v and w, we need a metric that\\ntakes two vectors (of the same dimensionality, either both with words as dimensions,\\nhence of length |V|, or both with documents as dimensions, of length |D|) and gives\\na measure of their similarity. By far the most common similarity metric is the cosine\\nof the angle between the vectors.\\nThe cosine‚Äîlike most measures for vector similarity used in NLP‚Äîis based on\\nthe dot product operator from linear algebra, also called the inner product:\\ndot product\\ninner product\\ndot product(v,w) = v ¬∑w =\\nN\\nX\\ni=1\\nviwi = v1w1 +v2w2 +...+vNwN\\n(5.7)\\nThe dot product acts as a similarity metric because it will tend to be high just when\\nthe two vectors have large values in the same dimensions. Alternatively, vectors that'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 8}, page_content='5.4\\n‚Ä¢\\nCOSINE FOR MEASURING SIMILARITY\\n9\\nhave zeros in different dimensions‚Äîorthogonal vectors‚Äîwill have a dot product of\\n0, representing their strong dissimilarity.\\nThis raw dot product, however, has a problem as a similarity metric: it favors\\nlong vectors. The vector length is deÔ¨Åned as\\nvector length\\n|v| =\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nv2\\ni\\n(5.8)\\nThe dot product is higher if a vector is longer, with higher values in each dimension.\\nMore frequent words have longer vectors, since they tend to co-occur with more\\nwords and have higher co-occurrence values with each of them. The raw dot product\\nthus will be higher for frequent words. But this is a problem; we‚Äôd like a similarity\\nmetric that tells us how similar two words are regardless of their frequency.\\nWe modify the dot product to normalize for the vector length by dividing the\\ndot product by the lengths of each of the two vectors. This normalized dot product\\nturns out to be the same as the cosine of the angle between the two vectors, following\\nfrom the deÔ¨Ånition of the dot product between two vectors a and b:\\na¬∑b = |a||b|cosŒ∏\\na¬∑b\\n|a||b| = cosŒ∏\\n(5.9)\\nThe cosine similarity metric between two vectors v and w thus can be computed as:\\ncosine\\ncosine(v,w) = v ¬∑w\\n|v||w| =\\nN\\nX\\ni=1\\nviwi\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nv2\\ni\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nw2\\ni\\n(5.10)\\nFor some applications we pre-normalize each vector, by dividing it by its length,\\ncreating a unit vector of length 1. Thus we could compute a unit vector from a by\\nunit vector\\ndividing it by |a|. For unit vectors, the dot product is the same as the cosine.\\nThe cosine value ranges from 1 for vectors pointing in the same direction, through\\n0 for orthogonal vectors, to -1 for vectors pointing in opposite directions. But since\\nraw frequency values are non-negative, the cosine for these vectors ranges from 0‚Äì1.\\nLet‚Äôs see how the cosine computes which of the words cherry or digital is closer\\nin meaning to information, just using raw counts from the following shortened table:\\npie\\ndata computer\\ncherry\\n442\\n8\\n2\\ndigital\\n5\\n1683\\n1670\\ninformation\\n5\\n3982\\n3325\\ncos(cherry,information) =\\n442‚àó5+8‚àó3982+2‚àó3325\\n‚àö\\n4422 +82 +22‚àö\\n52 +39822 +33252 = .018\\ncos(digital,information) =\\n5‚àó5+1683‚àó3982+1670‚àó3325\\n‚àö\\n52 +16832 +16702‚àö\\n52 +39822 +33252 = .996\\nThe model decides that information is way closer to digital than it is to cherry, a\\nresult that seems sensible. Fig. 5.5 shows a visualization.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 9}, page_content='10\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n500\\n1000\\n1500\\n2000\\n2500\\n3000\\n500\\ndigital\\ncherry\\ninformation\\nDimension 1: ‚Äòpie‚Äô\\nDimension 2: ‚Äòcomputer‚Äô\\nFigure 5.5\\nA (rough) graphical demonstration of cosine similarity, showing vectors for\\nthree words (cherry, digital, and information) in the two dimensional space deÔ¨Åned by counts\\nof the words computer and pie nearby. The Ô¨Ågure doesn‚Äôt show the cosine, but it highlights the\\nangles; note that the angle between digital and information is smaller than the angle between\\ncherry and information. When two vectors are more similar, the cosine is larger but the angle\\nis smaller; the cosine has its maximum (1) when the angle between two vectors is smallest\\n(0‚ó¶); the cosine of all other angles is less than 1.\\ncan be used to compute word similarity, for tasks like Ô¨Ånding word paraphrases,\\ntracking changes in word meaning, or automatically discovering meanings of words\\nin different corpora. For example, we can Ô¨Ånd the 10 most similar words to any\\ntarget word w by computing the cosines between w and each of the |V| ‚àí1 other\\nwords, sorting, and looking at the top 10.\\n5.5\\nWord2vec\\nIn the previous sections we saw how to represent a word as a sparse, long vector with\\ndimensions corresponding to words in the vocabulary. We now introduce a more\\npowerful word representation: embeddings, short dense vectors. Unlike the vectors\\nwe‚Äôve seen so far, embeddings are short, with number of dimensions d ranging from\\n50-1000, rather than the much larger vocabulary size |V|.These d dimensions don‚Äôt\\nhave a clear interpretation. And the vectors are dense: instead of vector entries\\nbeing sparse, mostly-zero counts or functions of counts, the values will be real-\\nvalued numbers that can be negative.\\nIt turns out that dense vectors work better in every NLP task than sparse vectors.\\nWhile we don‚Äôt completely understand all the reasons for this, we have some intu-\\nitions. Representing words as 300-dimensional dense vectors requires our classiÔ¨Åers\\nto learn far fewer weights than if we represented words as 50,000-dimensional vec-\\ntors, and the smaller parameter space possibly helps with generalization and avoid-\\ning overÔ¨Åtting. Dense vectors may also do a better job of capturing synonymy.\\nFor example, in a sparse vector representation, dimensions for synonyms like car\\nand automobile dimension are distinct and unrelated; sparse vectors may thus fail\\nto capture the similarity between a word with car as a neighbor and a word with\\nautomobile as a neighbor.\\nIn this section we introduce one method for computing embeddings: skip-gram\\nskip-gram\\nwith negative sampling, sometimes called SGNS. The skip-gram algorithm is one\\nSGNS\\nof two algorithms in a software package called word2vec, and so sometimes the\\nword2vec\\nalgorithm is loosely referred to as word2vec (Mikolov et al. 2013a, Mikolov et al.\\n2013b). The word2vec methods are fast, efÔ¨Åcient to train, and easily available on-\\nline with code and pretrained embeddings. Word2vec embeddings are static em-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 10}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n11\\nbeddings, meaning that the method learns one Ô¨Åxed embedding for each word in the\\nstatic\\nembeddings\\nvocabulary. In Chapter 10 we‚Äôll introduce methods for learning dynamic contextual\\nembeddings like the popular family of BERT representations, in which the vector\\nfor each word is different in different contexts.\\nThe intuition of word2vec is that instead of counting how often each word w oc-\\ncurs near, say, apricot, we‚Äôll instead train a classiÔ¨Åer on a binary prediction task: ‚ÄúIs\\nword w likely to show up near apricot?‚Äù We don‚Äôt actually care about this prediction\\ntask; instead we‚Äôll take the learned classiÔ¨Åer weights as the word embeddings.\\nThe revolutionary intuition here is that we can just use running text as implicitly\\nsupervised training data for such a classiÔ¨Åer; a word c that occurs near the target\\nword apricot acts as gold ‚Äòcorrect answer‚Äô to the question ‚ÄúIs word c likely to show\\nup near apricot?‚Äù This method, often called self-supervision, avoids the need for\\nself-supervision\\nany sort of hand-labeled supervision signal. This idea was Ô¨Årst proposed in the task\\nof neural language modeling, when Bengio et al. (2003) and Collobert et al. (2011)\\nshowed that a neural language model (a neural network that learned to predict the\\nnext word from prior words) could just use the next word in running text as its\\nsupervision signal, and could be used to learn an embedding representation for each\\nword as part of doing this prediction task.\\nWe‚Äôll see how to do neural networks in the next chapter, but word2vec is a\\nmuch simpler model than the neural network language model, in two ways. First,\\nword2vec simpliÔ¨Åes the task (making it binary classiÔ¨Åcation instead of word pre-\\ndiction). Second, word2vec simpliÔ¨Åes the architecture (training a logistic regression\\nclassiÔ¨Åer instead of a multi-layer neural network with hidden layers that demand\\nmore sophisticated training algorithms). The intuition of skip-gram is:\\n1. Treat the target word and a neighboring context word as positive examples.\\n2. Randomly sample other words in the lexicon to get negative samples.\\n3. Use logistic regression to train a classiÔ¨Åer to distinguish those two cases.\\n4. Use the learned weights as the embeddings.\\n5.5.1\\nThe classiÔ¨Åer\\nLet‚Äôs start by thinking about the classiÔ¨Åcation task, and then turn to how to train.\\nImagine a sentence like the following, with a target word apricot, and assume we‚Äôre\\nusing a window of ¬±2 context words:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nOur goal is to train a classiÔ¨Åer such that, given a tuple (w,c) of a target word\\nw paired with a candidate context word c (for example (apricot, jam), or perhaps\\n(apricot, aardvark)) it will return the probability that c is a real context word (true\\nfor jam, false for aardvark):\\nP(+|w,c)\\n(5.11)\\nThe probability that word c is not a real context word for w is just 1 minus\\nEq. 5.11:\\nP(‚àí|w,c) = 1‚àíP(+|w,c)\\n(5.12)\\nHow does the classiÔ¨Åer compute the probability P? The intuition of the skip-\\ngram model is to base this probability on embedding similarity: a word is likely to'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 11}, page_content='12\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\noccur near the target if its embedding vector is similar to the target embedding. To\\ncompute similarity between these dense embeddings, we rely on the intuition that\\ntwo vectors are similar if they have a high dot product (after all, cosine is just a\\nnormalized dot product). In other words:\\nSimilarity(w,c) ‚âàc¬∑w\\n(5.13)\\nThe dot product c ¬∑ w is not a probability, it‚Äôs just a number ranging from ‚àí‚àûto ‚àû\\n(since the elements in word2vec embeddings can be negative, the dot product can be\\nnegative). To turn the dot product into a probability, we‚Äôll use the logistic or sigmoid\\nfunction œÉ(x), the fundamental core of logistic regression:\\nœÉ(x) =\\n1\\n1+exp(‚àíx)\\n(5.14)\\nWe model the probability that word c is a real context word for target word w as:\\nP(+|w,c) = œÉ(c¬∑w) =\\n1\\n1+exp(‚àíc¬∑w)\\n(5.15)\\nThe sigmoid function returns a number between 0 and 1, but to make it a probability\\nwe‚Äôll also need the total probability of the two possible events (c is a context word,\\nand c isn‚Äôt a context word) to sum to 1. We thus estimate the probability that word c\\nis not a real context word for w as:\\nP(‚àí|w,c) = 1‚àíP(+|w,c)\\n= œÉ(‚àíc¬∑w) =\\n1\\n1+exp(c¬∑w)\\n(5.16)\\nEquation 5.15 gives us the probability for one word, but there are many context\\nwords in the window. Skip-gram makes the simplifying assumption that all context\\nwords are independent, allowing us to just multiply their probabilities:\\nP(+|w,c1:L) =\\nL\\nY\\ni=1\\nœÉ(ci ¬∑w)\\n(5.17)\\nlogP(+|w,c1:L) =\\nL\\nX\\ni=1\\nlogœÉ(ci ¬∑w)\\n(5.18)\\nIn summary, skip-gram trains a probabilistic classiÔ¨Åer that, given a test target word\\nw and its context window of L words c1:L, assigns a probability based on how similar\\nthis context window is to the target word. The probability is based on applying the\\nlogistic (sigmoid) function to the dot product of the embeddings of the target word\\nwith each context word. To compute this probability, we just need embeddings for\\neach target word and context word in the vocabulary.\\nFig. 5.6 shows the intuition of the parameters we‚Äôll need. Skip-gram actually\\nstores two embeddings for each word, one for the word as a target, and one for the\\nword considered as context. Thus the parameters we need to learn are two matrices\\nW and C, each containing an embedding for every one of the |V| words in the\\nvocabulary V.2 Let‚Äôs now turn to learning these embeddings (which is the real goal\\nof training this classiÔ¨Åer in the Ô¨Årst place).\\n2\\nIn principle the target matrix and the context matrix could use different vocabularies, but we‚Äôll simplify\\nby assuming one shared vocabulary V.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 12}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n13\\n1\\nW\\nC\\naardvark\\nzebra\\nzebra\\naardvark\\napricot\\napricot\\n|V|\\n|V|+1\\n2|V|\\nùúΩ =\\ntarget words\\ncontext & noise\\nwords\\n‚Ä¶\\n‚Ä¶\\n1..d\\n‚Ä¶\\n‚Ä¶\\nFigure 5.6\\nThe embeddings learned by the skipgram model. The algorithm stores two em-\\nbeddings for each word, the target embedding (sometimes called the input embedding) and\\nthe context embedding (sometimes called the output embedding). The parameter Œ∏ that the al-\\ngorithm learns is thus a matrix of 2|V| vectors, each of dimension d, formed by concatenating\\ntwo matrices, the target embeddings W and the context+noise embeddings C.\\n5.5.2\\nLearning skip-gram embeddings\\nThe learning algorithm for skip-gram embeddings takes as input a corpus of text,\\nand a chosen vocabulary size N. It begins by assigning a random embedding vector\\nfor each of the N vocabulary words, and then proceeds to iteratively shift the em-\\nbedding of each word w to be more like the embeddings of words that occur nearby\\nin texts, and less like the embeddings of words that don‚Äôt occur nearby. Let‚Äôs start\\nby considering a single piece of training data:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nThis example has a target word w (apricot), and 4 context words in the L = ¬±2\\nwindow, resulting in 4 positive training instances (on the left below):\\npositive examples +\\nw\\ncpos\\napricot tablespoon\\napricot of\\napricot jam\\napricot a\\nnegative examples -\\nw\\ncneg\\nw\\ncneg\\napricot aardvark apricot seven\\napricot my\\napricot forever\\napricot where\\napricot dear\\napricot coaxial\\napricot if\\nFor training a binary classiÔ¨Åer we also need negative examples. In fact skip-\\ngram with negative sampling (SGNS) uses more negative examples than positive\\nexamples (with the ratio between them set by a parameter k). So for each of these\\n(w,cpos) training instances we‚Äôll create k negative samples, each consisting of the\\ntarget w plus a ‚Äònoise word‚Äô cneg. A noise word is a random word from the lexicon,\\nconstrained not to be the target word w. The table right above shows the setting\\nwhere k = 2, so we‚Äôll have 2 negative examples in the negative training set ‚àífor\\neach positive example w,cpos.\\nThe noise words are chosen according to their weighted unigram probability\\npŒ±(w), where Œ± is a weight. If we were sampling according to unweighted proba-\\nbility P(w), it would mean that with unigram probability P(‚Äúthe‚Äù) we would choose\\nthe word the as a noise word, with unigram probability P(‚Äúaardvark‚Äù) we would\\nchoose aardvark, and so on. But in practice it is common to set Œ± = 0.75, i.e. use'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 13}, page_content='14\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nthe weighting P3\\n4 (w):\\nPŒ±(w) =\\ncount(w)Œ±\\nP\\nw‚Ä≤ count(w‚Ä≤)Œ±\\n(5.19)\\nSetting Œ± = .75 gives better performance because it gives rare noise words slightly\\nhigher probability: for rare words, PŒ±(w) > P(w). To illustrate this intuition, it\\nmight help to work out the probabilities for an example with Œ± = .75 and two events,\\nP(a) = 0.99 and P(b) = 0.01:\\nPŒ±(a) =\\n.99.75\\n.99.75 +.01.75 = 0.97\\nPŒ±(b) =\\n.01.75\\n.99.75 +.01.75 = 0.03\\n(5.20)\\nThus using Œ± = .75 increases the probability of the rare event b from 0.01 to 0.03.\\nGiven the set of positive and negative training instances, and an initial set of\\nembeddings, the goal of the learning algorithm is to adjust those embeddings to\\n‚Ä¢ Maximize the similarity of the target word, context word pairs (w,cpos) drawn\\nfrom the positive examples\\n‚Ä¢ Minimize the similarity of the (w,cneg) pairs from the negative examples.\\nIf we consider one word/context pair (w,cpos) with its k noise words cneg1...cnegk,\\nwe can express these two goals as the following loss function L to be minimized\\n(hence the ‚àí); here the Ô¨Årst term expresses that we want the classiÔ¨Åer to assign the\\nreal context word cpos a high probability of being a neighbor, and the second term\\nexpresses that we want to assign each of the noise words cnegi a high probability of\\nbeing a non-neighbor, all multiplied because we assume independence:\\nL = ‚àílog\\n\"\\nP(+|w,cpos)\\nkY\\ni=1\\nP(‚àí|w,cnegi)\\n#\\n= ‚àí\\n\"\\nlogP(+|w,cpos)+\\nk\\nX\\ni=1\\nlogP(‚àí|w,cnegi)\\n#\\n= ‚àí\\n\"\\nlogP(+|w,cpos)+\\nk\\nX\\ni=1\\nlog\\n\\x001‚àíP(+|w,cnegi)\\n\\x01\\n#\\n= ‚àí\\n\"\\nlogœÉ(cpos ¬∑w)+\\nk\\nX\\ni=1\\nlogœÉ(‚àícnegi ¬∑w)\\n#\\n(5.21)\\nThat is, we want to maximize the dot product of the word with the actual context\\nwords, and minimize the dot products of the word with the k negative sampled non-\\nneighbor words.\\nWe minimize this loss function using stochastic gradient descent. Fig. 5.7 shows\\nthe intuition of one step of learning.\\nTo get the gradient, we need to take the derivative of Eq. 5.21 with respect to\\nthe different embeddings. It turns out the derivatives are the following (we leave the'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 14}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n15\\nW\\nC\\nmove apricot and jam closer,\\nincreasing cpos z w\\naardvark\\nmove apricot and matrix apart\\ndecreasing cneg1 z w\\n‚Äú‚Ä¶apricot jam‚Ä¶‚Äù\\nw\\nzebra\\nzebra\\naardvark\\njam\\napricot\\ncpos\\nmatrix\\nTolstoy\\nmove apricot and Tolstoy apart\\ndecreasing cneg2 z w\\n!\\ncneg1\\ncneg2\\nk=2\\nFigure 5.7\\nIntuition of one step of gradient descent. The skip-gram model tries to shift em-\\nbeddings so the target embeddings (here for apricot) are closer to (have a higher dot product\\nwith) context embeddings for nearby words (here jam) and further from (lower dot product\\nwith) context embeddings for noise words that don‚Äôt occur nearby (here Tolstoy and matrix).\\nproof as an exercise at the end of the chapter):\\n‚àÇL\\n‚àÇcpos\\n= [œÉ(cpos ¬∑w)‚àí1]w\\n(5.22)\\n‚àÇL\\n‚àÇcneg\\n= [œÉ(cneg ¬∑w)]w\\n(5.23)\\n‚àÇL\\n‚àÇw = [œÉ(cpos ¬∑w)‚àí1]cpos +\\nk\\nX\\ni=1\\n[œÉ(cnegi ¬∑w)]cnegi\\n(5.24)\\nThe update equations going from time step t to t + 1 in stochastic gradient descent\\nare thus:\\nct+1\\npos\\n= ct\\npos ‚àíŒ∑[œÉ(ct\\npos ¬∑wt)‚àí1]wt\\n(5.25)\\nct+1\\nneg = ct\\nneg ‚àíŒ∑[œÉ(ct\\nneg ¬∑wt)]wt\\n(5.26)\\nwt+1 = wt ‚àíŒ∑\\n\"\\n[œÉ(ct\\npos ¬∑wt)‚àí1]ct\\npos +\\nk\\nX\\ni=1\\n[œÉ(ct\\nnegi ¬∑wt)]ct\\nnegi\\n#\\n(5.27)\\nJust as in logistic regression, then, the learning algorithm starts with randomly ini-\\ntialized W and C matrices, and then walks through the training corpus using gradient\\ndescent to move W and C so as to minimize the loss in Eq. 5.21 by making the up-\\ndates in (Eq. 5.25)-(Eq. 5.27).\\nRecall that the skip-gram model learns two separate embeddings for each word i:\\nthe target embedding wi and the context embedding ci, stored in two matrices, the\\ntarget\\nembedding\\ncontext\\nembedding\\ntarget matrix W and the context matrix C. It‚Äôs common to just add them together,\\nrepresenting word i with the vector wi +ci. Alternatively we can throw away the C\\nmatrix and just represent each word i by the vector wi.\\nAs with the simple count-based methods like tf-idf, the context window size L\\naffects the performance of skip-gram embeddings, and experiments often tune the\\nparameter L on a devset.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 15}, page_content='16\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n5.5.3\\nOther kinds of static embeddings\\nThere are many kinds of static embeddings. An extension of word2vec, fasttext\\nfasttext\\n(Bojanowski et al., 2017), addresses a problem with word2vec as we have presented\\nit so far: it has no good way to deal with unknown words‚Äîwords that appear in\\na test corpus but were unseen in the training corpus. A related problem is word\\nsparsity, such as in languages with rich morphology, where some of the many forms\\nfor each noun and verb may only occur rarely. Fasttext deals with these problems\\nby using subword models, representing each word as itself plus a bag of constituent\\nn-grams, with special boundary symbols < and > added to each word. For example,\\nwith n = 3 the word where would be represented by the sequence <where> plus the\\ncharacter n-grams:\\n<wh, whe, her, ere, re>\\nThen a skipgram embedding is learned for each constituent n-gram, and the word\\nwhere is represented by the sum of all of the embeddings of its constituent n-grams.\\nUnknown words can then be presented only by the sum of the constituent n-grams.\\nA fasttext open-source library, including pretrained embeddings for 157 languages,\\nis available at https://fasttext.cc.\\nAnother very widely used static embedding model is GloVe (Pennington et al.,\\n2014), short for Global Vectors, because the model is based on capturing global\\ncorpus statistics. GloVe is based on ratios of probabilities from the word-word co-\\noccurrence matrix.\\nIt turns out that dense embeddings like word2vec actually have an elegant math-\\nematical relationship with count-based embeddings, in which word2vec can be seen\\nas implicitly optimizing a function of a count matrix with a particular (PPMI) weight-\\ning (Levy and Goldberg, 2014c).\\n5.6\\nVisualizing Embeddings\\n‚ÄúI see well in many dimensions as long as the dimensions are around two.‚Äù\\nThe late economist Martin Shubik\\nVisualizing embeddings is an important goal in helping understand, apply, and\\nimprove these models of word meaning. But how can we visualize a (for example)\\n100-dimensional vector?\\nWRIST\\nANKLE\\nSHOULDER\\nARM\\nLEG\\nHAND\\nFOOT\\nHEAD\\nNOSE\\nFINGER\\nTOE\\nFACE\\nEAR\\nEYE\\nTOOTH\\nDOG\\nCAT\\nPUPPY\\nKITTEN\\nCOW\\nMOUSE\\nTURTLE\\nOYSTER\\nLION\\nBULL\\nCHICAGO\\nATLANTA\\nMONTREAL\\nNASHVILLE\\nTOKYO\\nCHINA\\nRUSSIA\\nAFRICA\\nASIA\\nEUROPE\\nAMERICA\\nBRAZIL\\nMOSCOW\\nFRANCE\\nHAWAII\\nThe simplest way to visualize the meaning of a word\\nw embedded in a space is to list the most similar words to\\nw by sorting the vectors for all words in the vocabulary by\\ntheir cosine with the vector for w. For example the 7 closest\\nwords to frog using a particular embeddings computed with\\nthe GloVe algorithm are: frogs, toad, litoria, leptodactyli-\\ndae, rana, lizard, and eleutherodactylus (Pennington et al.,\\n2014).\\nYet another visualization method is to use a clustering\\nalgorithm to show a hierarchical representation of which\\nwords are similar to others in the embedding space. The\\nuncaptioned Ô¨Ågure on the left uses hierarchical clustering\\nof some embedding vectors for nouns as a visualization\\nmethod (Rohde et al., 2006).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 16}, page_content='5.7\\n‚Ä¢\\nSEMANTIC PROPERTIES OF EMBEDDINGS\\n17\\nProbably the most common visualization method, how-\\never, is to project the 100 dimensions of a word down into 2\\ndimensions. Fig. 5.1 showed one such visualization, as does\\nFig. 5.9, using a projection method called t-SNE (van der\\nMaaten and Hinton, 2008).\\n5.7\\nSemantic properties of embeddings\\nIn this section we brieÔ¨Çy summarize some of the semantic properties of embeddings\\nthat have been studied.\\nDifferent types of similarity or association:\\nOne parameter of vector semantic\\nmodels that is relevant to both sparse PPMI vectors and dense word2vec vectors is\\nthe size of the context window used to collect counts. This is generally between 1\\nand 10 words on each side of the target word (for a total context of 2-20 words).\\nThe choice depends on the goals of the representation. Shorter context windows\\ntend to lead to representations that are a bit more syntactic, since the information is\\ncoming from immediately nearby words. When the vectors are computed from short\\ncontext windows, the most similar words to a target word w tend to be semantically\\nsimilar words with the same parts of speech. When vectors are computed from long\\ncontext windows, the highest cosine words to a target word w tend to be words that\\nare topically related but not similar.\\nFor example Levy and Goldberg (2014a) showed that using skip-gram with a\\nwindow of ¬±2, the most similar words to the word Hogwarts (from the Harry Potter\\nseries) were names of other Ô¨Åctional schools: Sunnydale (from Buffy the Vampire\\nSlayer) or Evernight (from a vampire series). With a window of ¬±5, the most similar\\nwords to Hogwarts were other words topically related to the Harry Potter series:\\nDumbledore, Malfoy, and half-blood.\\nIt‚Äôs also often useful to distinguish two kinds of similarity or association between\\nwords (Sch¬®utze and Pedersen, 1993). Two words have Ô¨Årst-order co-occurrence\\nÔ¨Årst-order\\nco-occurrence\\n(sometimes called syntagmatic association) if they are typically nearby each other.\\nThus wrote is a Ô¨Årst-order associate of book or poem. Two words have second-order\\nco-occurrence (sometimes called paradigmatic association) if they have similar\\nsecond-order\\nco-occurrence\\nneighbors. Thus wrote is a second-order associate of words like said or remarked.\\nAnalogy/Relational Similarity:\\nAnother semantic property of embeddings is their\\nability to capture relational meanings. In an important early vector space model of\\ncognition, Rumelhart and Abrahamson (1973) proposed the parallelogram model\\nparallelogram\\nmodel\\nfor solving simple analogy problems of the form a is to b as a* is to what?. In such\\nproblems, a system is given a problem like apple:tree::grape:?, i.e., apple is to tree\\nas grape is to\\n, and must Ô¨Åll in the word vine. In the parallelogram model, il-\\nlustrated in Fig. 5.8, the vector from the word apple to the word tree (= #   ¬ª\\ntree‚àí#       ¬ª\\napple)\\nis added to the vector for grape (#        ¬ª\\ngrape); the nearest word to that point is returned.\\nIn early work with sparse embeddings, scholars showed that sparse vector mod-\\nels of meaning could solve such analogy problems (Turney and Littman, 2005),\\nbut the parallelogram method received more modern attention because of its suc-\\ncess with word2vec or GloVe vectors (Mikolov et al. 2013c, Levy and Goldberg\\n2014b, Pennington et al. 2014). For example, the result of the expression #     ¬ª\\nking ‚àí\\n#     ¬ª\\nman + #            ¬ª\\nwoman is a vector close to #         ¬ª\\nqueen. Similarly, #      ¬ª\\nParis ‚àí#           ¬ª\\nFrance + #     ¬ª\\nItaly results\\nin a vector that is close to #         ¬ª\\nRome. The embedding model thus seems to be extract-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 17}, page_content='18\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\ntree\\napple\\ngrape\\nvine\\nFigure 5.8\\nThe parallelogram model for analogy problems (Rumelhart and Abrahamson,\\n1973): the location of #     ¬ª\\nvine can be found by subtracting #       ¬ª\\napple from #   ¬ª\\ntree and adding #       ¬ª\\ngrape.\\ning representations of relations like MALE-FEMALE, or CAPITAL-CITY-OF, or even\\nCOMPARATIVE/SUPERLATIVE, as shown in Fig. 5.9 from GloVe.\\n(a)\\n(b)\\nFigure 5.9\\nRelational properties of the GloVe vector space, shown by projecting vectors onto two dimensions.\\n(a) #     ¬ª\\nking‚àí#     ¬ª\\nman+ #            ¬ª\\nwoman is close to #        ¬ª\\nqueen. (b) offsets seem to capture comparative and superlative morphology\\n(Pennington et al., 2014).\\nFor a a : b :: a‚àó: b‚àóproblem, meaning the algorithm is given vectors a, b, and\\na‚àóand must Ô¨Ånd b‚àó, the parallelogram method is thus:\\nÀÜb‚àó= argmin\\nx\\ndistance(x,b‚àía+a‚àó)\\n(5.28)\\nwith some distance function, such as Euclidean distance.\\nThere are some caveats. For example, the closest value returned by the paral-\\nlelogram algorithm in word2vec or GloVe embedding spaces is usually not in fact\\nb* but one of the 3 input words or their morphological variants (i.e., cherry:red ::\\npotato:x returns potato or potatoes instead of brown), so these must be explicitly\\nexcluded. Furthermore while embedding spaces perform well if the task involves\\nfrequent words, small distances, and certain relations (like relating countries with\\ntheir capitals or verbs/nouns with their inÔ¨Çected forms), the parallelogram method\\nwith embeddings doesn‚Äôt work as well for other relations (Linzen 2016, Gladkova\\net al. 2016, Schluter 2018, Ethayarajh et al. 2019a), and indeed Peterson et al. (2020)\\nargue that the parallelogram method is in general too simple to model the human\\ncognitive process of forming analogies of this kind.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 18}, page_content='5.8\\n‚Ä¢\\nBIAS AND EMBEDDINGS\\n19\\n5.7.1\\nEmbeddings and Historical Semantics\\nEmbeddings can also be a useful tool for studying how meaning changes over time,\\nby computing multiple embedding spaces, each from texts written in a particular\\ntime period. For example Fig. 5.10 shows a visualization of changes in meaning in\\nEnglish words over the last two centuries, computed by building separate embedding\\nspaces for each decade from historical corpora like Google n-grams (Lin et al., 2012)\\nand the Corpus of Historical American English (Davies, 2012).\\nFigure 5.10\\nA t-SNE visualization of the semantic change of 3 words in English using\\nword2vec vectors. The modern sense of each word, and the grey context words, are com-\\nputed from the most recent (modern) time-point embedding space. Earlier points are com-\\nputed from earlier historical embedding spaces. The visualizations show the changes in the\\nword gay from meanings related to ‚Äúcheerful‚Äù or ‚Äúfrolicsome‚Äù to referring to homosexuality,\\nthe development of the modern ‚Äútransmission‚Äù sense of broadcast from its original sense of\\nsowing seeds, and the pejoration of the word awful as it shifted from meaning ‚Äúfull of awe‚Äù\\nto meaning ‚Äúterrible or appalling‚Äù (Hamilton et al., 2016).\\n5.8\\nBias and Embeddings\\nIn addition to their ability to learn word meaning from text, embeddings, alas,\\nalso reproduce the implicit biases and stereotypes that were latent in the text. As\\nthe prior section just showed, embeddings can roughly model relational similar-\\nity: ‚Äòqueen‚Äô as the closest word to ‚Äòking‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô implies the analogy\\nman:woman::king:queen. But these same embedding analogies also exhibit gender\\nstereotypes. For example Bolukbasi et al. (2016) Ô¨Ånd that the closest occupation\\nto ‚Äòcomputer programmer‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô in word2vec embeddings trained on\\nnews text is ‚Äòhomemaker‚Äô, and that the embeddings similarly suggest the analogy\\n‚Äòfather‚Äô is to ‚Äòdoctor‚Äô as ‚Äòmother‚Äô is to ‚Äònurse‚Äô. This could result in what Crawford\\n(2017) and Blodgett et al. (2020) call an allocational harm, when a system allo-\\nallocational\\nharm\\ncates resources (jobs or credit) unfairly to different groups. For example algorithms\\nthat use embeddings as part of a search for hiring potential programmers or doctors\\nmight thus incorrectly downweight documents with women‚Äôs names.\\nIt turns out that embeddings don‚Äôt just reÔ¨Çect the statistics of their input, but also\\namplify bias; gendered terms become more gendered in embedding space than they\\nbias\\nampliÔ¨Åcation\\nwere in the input text statistics (Zhao et al. 2017, Ethayarajh et al. 2019b, Jia et al.\\n2020), and biases are more exaggerated than in actual labor employment statistics\\n(Garg et al., 2018).\\nEmbeddings also encode the implicit associations that are a property of human\\nreasoning. The Implicit Association Test (Greenwald et al., 1998) measures peo-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 19}, page_content='20\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nple‚Äôs associations between concepts (like ‚ÄòÔ¨Çowers‚Äô or ‚Äòinsects‚Äô) and attributes (like\\n‚Äòpleasantness‚Äô and ‚Äòunpleasantness‚Äô) by measuring differences in the latency with\\nwhich they label words in the various categories.3 Using such methods, people\\nin the United States have been shown to associate African-American names with\\nunpleasant words (more than European-American names), male names more with\\nmathematics and female names with the arts, and old people‚Äôs names with unpleas-\\nant words (Greenwald et al. 1998, Nosek et al. 2002a, Nosek et al. 2002b). Caliskan\\net al. (2017) replicated all these Ô¨Åndings of implicit associations using GloVe vectors\\nand cosine similarity instead of human latencies. For example African-American\\nnames like ‚ÄòLeroy‚Äô and ‚ÄòShaniqua‚Äô had a higher GloVe cosine with unpleasant words\\nwhile European-American names (‚ÄòBrad‚Äô, ‚ÄòGreg‚Äô, ‚ÄòCourtney‚Äô) had a higher cosine\\nwith pleasant words. These problems with embeddings are an example of a repre-\\nsentational harm (Crawford 2017, Blodgett et al. 2020), which is a harm caused by\\nrepresentational\\nharm\\na system demeaning or even ignoring some social groups. Any embedding-aware al-\\ngorithm that made use of word sentiment could thus exacerbate bias against African\\nAmericans.\\nRecent research focuses on ways to try to remove these kinds of biases, for\\nexample by developing a transformation of the embedding space that removes gen-\\nder stereotypes but preserves deÔ¨Ånitional gender (Bolukbasi et al. 2016, Zhao et al.\\n2017) or changing the training procedure (Zhao et al., 2018). However, although\\nthese sorts of debiasing may reduce bias in embeddings, they do not eliminate it\\ndebiasing\\n(Gonen and Goldberg, 2019), and this remains an open problem.\\nHistorical embeddings are also being used to measure biases in the past. Garg\\net al. (2018) used embeddings from historical texts to measure the association be-\\ntween embeddings for occupations and embeddings for names of various ethnici-\\nties or genders (for example the relative cosine similarity of women‚Äôs names versus\\nmen‚Äôs to occupation words like ‚Äòlibrarian‚Äô or ‚Äòcarpenter‚Äô) across the 20th century.\\nThey found that the cosines correlate with the empirical historical percentages of\\nwomen or ethnic groups in those occupations. Historical embeddings also repli-\\ncated old surveys of ethnic stereotypes; the tendency of experimental participants in\\n1933 to associate adjectives like ‚Äòindustrious‚Äô or ‚Äòsuperstitious‚Äô with, e.g., Chinese\\nethnicity, correlates with the cosine between Chinese last names and those adjectives\\nusing embeddings trained on 1930s text. They also were able to document historical\\ngender biases, such as the fact that embeddings for adjectives related to competence\\n(‚Äòsmart‚Äô, ‚Äòwise‚Äô, ‚Äòthoughtful‚Äô, ‚Äòresourceful‚Äô) had a higher cosine with male than fe-\\nmale words, and showed that this bias has been slowly decreasing since 1960. We\\nreturn in later chapters to this question about the role of bias in natural language\\nprocessing.\\n5.9\\nEvaluating Vector Models\\nThe most important evaluation metric for vector models is extrinsic evaluation on\\ntasks, i.e., using vectors in an NLP task and seeing whether this improves perfor-\\nmance over some other model.\\n3\\nRoughly speaking, if humans associate ‚ÄòÔ¨Çowers‚Äô with ‚Äòpleasantness‚Äô and ‚Äòinsects‚Äô with ‚Äòunpleasant-\\nness‚Äô, when they are instructed to push a green button for ‚ÄòÔ¨Çowers‚Äô (daisy, iris, lilac) and ‚Äòpleasant words‚Äô\\n(love, laughter, pleasure) and a red button for ‚Äòinsects‚Äô (Ô¨Çea, spider, mosquito) and ‚Äòunpleasant words‚Äô\\n(abuse, hatred, ugly) they are faster than in an incongruous condition where they push a red button for\\n‚ÄòÔ¨Çowers‚Äô and ‚Äòunpleasant words‚Äô and a green button for ‚Äòinsects‚Äô and ‚Äòpleasant words‚Äô.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 20}, page_content='5.10\\n‚Ä¢\\nSUMMARY\\n21\\nNonetheless it is useful to have intrinsic evaluations. The most common metric\\nis to test their performance on similarity, computing the correlation between an\\nalgorithm‚Äôs word similarity scores and word similarity ratings assigned by humans.\\nWordSim-353 (Finkelstein et al., 2002) is a commonly used set of ratings from 0\\nto 10 for 353 noun pairs; for example (plane, car) had an average score of 5.77.\\nSimLex-999 (Hill et al., 2015) is a more complex dataset that quantiÔ¨Åes similarity\\n(cup, mug) rather than relatedness (cup, coffee), and includes concrete and abstract\\nadjective, noun and verb pairs. The TOEFL dataset is a set of 80 questions, each\\nconsisting of a target word with 4 additional word choices; the task is to choose\\nwhich is the correct synonym, as in the example: Levied is closest in meaning to:\\nimposed, believed, requested, correlated (Landauer and Dumais, 1997). All of these\\ndatasets present words without context.\\nSlightly more realistic are intrinsic similarity tasks that include context. The\\nStanford Contextual Word Similarity (SCWS) dataset (Huang et al., 2012) and the\\nWord-in-Context (WiC) dataset (Pilehvar and Camacho-Collados, 2019) offer richer\\nevaluation scenarios. SCWS gives human judgments on 2,003 pairs of words in\\ntheir sentential context, while WiC gives target words in two sentential contexts that\\nare either in the same or different senses; see Appendix G. The semantic textual\\nsimilarity task (Agirre et al. 2012, Agirre et al. 2015) evaluates the performance of\\nsentence-level similarity algorithms, consisting of a set of pairs of sentences, each\\npair with human-labeled similarity scores.\\nAnother task used for evaluation is the analogy task, discussed on page 17, where\\nthe system has to solve problems of the form a is to b as a* is to b*, given a, b, and a*\\nand having to Ô¨Ånd b* (Turney and Littman, 2005). A number of sets of tuples have\\nbeen created for this task (Mikolov et al. 2013a, Mikolov et al. 2013c, Gladkova\\net al. 2016), covering morphology (city:cities::child:children), lexicographic rela-\\ntions (leg:table::spout:teapot) and encyclopedia relations (Beijing:China::Dublin:Ireland),\\nsome drawing from the SemEval-2012 Task 2 dataset of 79 different relations (Jur-\\ngens et al., 2012).\\nAll embedding algorithms suffer from inherent variability. For example because\\nof randomness in the initialization and the random negative sampling, algorithms\\nlike word2vec may produce different results even from the same dataset, and in-\\ndividual documents in a collection may strongly impact the resulting embeddings\\n(Tian et al. 2016, Hellrich and Hahn 2016, Antoniak and Mimno 2018). When em-\\nbeddings are used to study word associations in particular corpora, therefore, it is\\nbest practice to train multiple embeddings with bootstrap sampling over documents\\nand average the results (Antoniak and Mimno, 2018).\\n5.10\\nSummary\\n‚Ä¢ In vector semantics, a word is modeled as a vector‚Äîa point in high-dimensional\\nspace, also called an embedding. In this chapter we focus on static embed-\\ndings, where each word is mapped to a Ô¨Åxed embedding.\\n‚Ä¢ Vector semantic models fall into two classes: sparse and dense. In sparse\\nmodels each dimension corresponds to a word in the vocabulary V and cells\\nare functions of co-occurrence counts. The word-context or term-term ma-\\ntrix has a row for each (target) word in the vocabulary and a column for each\\ncontext term in the vocabulary.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 21}, page_content='22\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n‚Ä¢ Dense vector models typically have dimensionality 50‚Äì1000. Word2vec al-\\ngorithms like skip-gram are a popular way to compute dense embeddings.\\nSkip-gram trains a logistic regression classiÔ¨Åer to compute the probability that\\ntwo words are ‚Äòlikely to occur nearby in text‚Äô. This probability is computed\\nfrom the dot product between the embeddings for the two words.\\n‚Ä¢ Skip-gram uses stochastic gradient descent to train the classiÔ¨Åer, by learning\\nembeddings that have a high dot product with embeddings of words that occur\\nnearby and a low dot product with noise words.\\n‚Ä¢ Other important embedding algorithms include GloVe, a method based on\\nratios of word co-occurrence probabilities.\\n‚Ä¢ Whether using sparse or dense vectors, word and document similarities are\\ncomputed by some function of the dot product between vectors. The cosine\\nof two vectors‚Äîa normalized dot product‚Äîis the most popular such metric.\\nHistorical Notes\\nThe idea of vector semantics arose out of research in the 1950s in three distinct\\nÔ¨Åelds: linguistics, psychology, and computer science, each of which contributed a\\nfundamental aspect of the model.\\nThe idea that meaning is related to the distribution of words in context was\\nwidespread in linguistic theory of the 1950s, among distributionalists like Zellig\\nHarris, Martin Joos, and J. R. Firth, and semioticians like Thomas Sebeok. As Joos\\n(1950) put it,\\nthe linguist‚Äôs ‚Äúmeaning‚Äù of a morpheme. . . is by deÔ¨Ånition the set of conditional\\nprobabilities of its occurrence in context with all other morphemes.\\nThe idea that the meaning of a word might be modeled as a point in a multi-\\ndimensional semantic space came from psychologists like Charles E. Osgood, who\\nhad been studying how people responded to the meaning of words by assigning val-\\nues along scales like happy/sad or hard/soft. Osgood et al. (1957) proposed that the\\nmeaning of a word in general could be modeled as a point in a multidimensional\\nEuclidean space, and that the similarity of meaning between two words could be\\nmodeled as the distance between these points in the space.\\nA Ô¨Ånal intellectual source in the 1950s and early 1960s was the Ô¨Åeld then called\\nmechanical indexing, now known as information retrieval. In what became known\\nmechanical\\nindexing\\nas the vector space model for information retrieval (Salton 1971, Sparck Jones\\n1986), researchers demonstrated new ways to deÔ¨Åne the meaning of words in terms\\nof vectors (Switzer, 1965), and reÔ¨Åned methods for word similarity based on mea-\\nsures of statistical association between words like mutual information (Giuliano,\\n1965) and idf (Sparck Jones, 1972), and showed that the meaning of documents\\ncould be represented in the same vector spaces used for words. Around the same\\ntime, (Cordier, 1965) showed that factor analysis of word association probabilities\\ncould be used to form dense vector representations of words.\\nSome of the philosophical underpinning of the distributional way of thinking\\ncame from the late writings of the philosopher Wittgenstein, who was skeptical of\\nthe possibility of building a completely formal theory of meaning deÔ¨Ånitions for\\neach word. Wittgenstein suggested instead that ‚Äúthe meaning of a word is its use in\\nthe language‚Äù (Wittgenstein, 1953, PI 43). That is, instead of using some logical lan-\\nguage to deÔ¨Åne each word, or drawing on denotations or truth values, Wittgenstein‚Äôs'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 22}, page_content='HISTORICAL NOTES\\n23\\nidea is that we should deÔ¨Åne a word by how it is used by people in speaking and un-\\nderstanding in their day-to-day interactions, thus preÔ¨Åguring the movement toward\\nembodied and experiential models in linguistics and NLP (Glenberg and Robertson\\n2000, Lake and Murphy 2021, Bisk et al. 2020, Bender and Koller 2020).\\nMore distantly related is the idea of deÔ¨Åning words by a vector of discrete fea-\\ntures, which has roots at least as far back as Descartes and Leibniz (Wierzbicka 1992,\\nWierzbicka 1996). By the middle of the 20th century, beginning with the work of\\nHjelmslev (Hjelmslev, 1969) (originally 1943) and Ô¨Çeshed out in early models of\\ngenerative grammar (Katz and Fodor, 1963), the idea arose of representing mean-\\ning with semantic features, symbols that represent some sort of primitive meaning.\\nsemantic\\nfeature\\nFor example words like hen, rooster, or chick, have something in common (they all\\ndescribe chickens) and something different (their age and sex), representable as:\\nhen\\n+female, +chicken, +adult\\nrooster -female, +chicken, +adult\\nchick\\n+chicken, -adult\\nThe dimensions used by vector models of meaning to deÔ¨Åne words, however, are\\nonly abstractly related to this idea of a small Ô¨Åxed number of hand-built dimensions.\\nNonetheless, there has been some attempt to show that certain dimensions of em-\\nbedding models do contribute some speciÔ¨Åc compositional aspect of meaning like\\nthese early semantic features.\\nThe use of dense vectors to model word meaning, and indeed the term embed-\\nding, grew out of the latent semantic indexing (LSI) model (Deerwester et al.,\\n1988) recast as LSA (latent semantic analysis) (Deerwester et al., 1990). In LSA\\nsingular value decomposition‚ÄîSVD‚Äî is applied to a term-document matrix (each\\nSVD\\ncell weighted by log frequency and normalized by entropy), and then the Ô¨Årst 300\\ndimensions are used as the LSA embedding. Singular Value Decomposition (SVD)\\nis a method for Ô¨Ånding the most important dimensions of a data set, those dimen-\\nsions along which the data varies the most. LSA was then quickly widely applied:\\nas a cognitive model (Landauer and Dumais, 1997), and for tasks like spell checking\\n(Jones and Martin, 1997), language modeling (Bellegarda 1997, Coccaro and Ju-\\nrafsky 1998, Bellegarda 2000), morphology induction (Schone and Jurafsky 2000,\\nSchone and Jurafsky 2001b), multiword expressions (MWEs) (Schone and Jurafsky,\\n2001a), and essay grading (Rehder et al., 1998). Related models were simultane-\\nously developed and applied to word sense disambiguation by Sch¬®utze (1992). LSA\\nalso led to the earliest use of embeddings to represent words in a probabilistic clas-\\nsiÔ¨Åer, in the logistic regression document router of Sch¬®utze et al. (1995). The idea of\\nSVD on the term-term matrix (rather than the term-document matrix) as a model of\\nmeaning for NLP was proposed soon after LSA by Sch¬®utze (1992). Sch¬®utze applied\\nthe low-rank (97-dimensional) embeddings produced by SVD to the task of word\\nsense disambiguation, analyzed the resulting semantic space, and also suggested\\npossible techniques like dropping high-order dimensions. See Sch¬®utze (1997).\\nA number of alternative matrix models followed on from the early SVD work,\\nincluding Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 1999), Latent\\nDirichlet Allocation (LDA) (Blei et al., 2003), and Non-negative Matrix Factoriza-\\ntion (NMF) (Lee and Seung, 1999).\\nThe LSA community seems to have Ô¨Årst used the word ‚Äúembedding‚Äù in Landauer\\net al. (1997), in a variant of its mathematical meaning as a mapping from one space\\nor mathematical structure to another. In LSA, the word embedding seems to have\\ndescribed the mapping from the space of sparse count vectors to the latent space of\\nSVD dense vectors. Although the word thus originally meant the mapping from one'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 23}, page_content='24\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nspace to another, it has metonymically shifted to mean the resulting dense vector in\\nthe latent space, and it is in this sense that we currently use the word.\\nBy the next decade, Bengio et al. (2003) and Bengio et al. (2006) showed that\\nneural language models could also be used to develop embeddings as part of the task\\nof word prediction. Collobert and Weston (2007), Collobert and Weston (2008), and\\nCollobert et al. (2011) then demonstrated that embeddings could be used to represent\\nword meanings for a number of NLP tasks. Turian et al. (2010) compared the value\\nof different kinds of embeddings for different NLP tasks. Mikolov et al. (2011)\\nshowed that recurrent neural nets could be used as language models. The idea of\\nsimplifying the hidden layer of these neural net language models to create the skip-\\ngram (and also CBOW) algorithms was proposed by Mikolov et al. (2013a). The\\nnegative sampling training algorithm was proposed in Mikolov et al. (2013b). There\\nare numerous surveys of static embeddings and their parameterizations (Bullinaria\\nand Levy 2007, Bullinaria and Levy 2012, Lapesa and Evert 2014, Kiela and Clark\\n2014, Levy et al. 2015).\\nSee Manning et al. (2008) and Chapter 11 for a deeper understanding of the role\\nof vectors in information retrieval, including how to compare queries with docu-\\nments, more details on tf-idf, and issues of scaling to very large datasets. See Kim\\n(2019) for a clear and comprehensive tutorial on word2vec. Cruse (2004) is a useful\\nintroductory linguistic text on lexical semantics.\\nExercises'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='Exercises\\n25\\nAgirre, E., C. Banea, C. Cardie, D. Cer, M. Diab,\\nA. Gonzalez-Agirre, W. Guo, I. Lopez-Gazpio, M. Mar-\\nitxalar, R. Mihalcea, G. Rigau, L. Uria, and J. Wiebe.\\n2015. SemEval-2015 task 2: Semantic textual similarity,\\nEnglish, Spanish and pilot on interpretability. SemEval-\\n15.\\nAgirre, E., M. Diab, D. Cer, and A. Gonzalez-Agirre. 2012.\\nSemEval-2012 task 6: A pilot on semantic textual simi-\\nlarity. SemEval-12.\\nAntoniak, M. and D. Mimno. 2018. Evaluating the stability\\nof embedding-based word similarities. TACL, 6:107‚Äì119.\\nBellegarda, J. R. 1997. A latent semantic analysis framework\\nfor large-span language modeling. EUROSPEECH.\\nBellegarda, J. R. 2000. Exploiting latent semantic informa-\\ntion in statistical language modeling. Proceedings of the\\nIEEE, 89(8):1279‚Äì1296.\\nBender, E. M. and A. Koller. 2020. Climbing towards NLU:\\nOn meaning, form, and understanding in the age of data.\\nACL.\\nBengio, Y., A. Courville, and P. Vincent. 2013. Represen-\\ntation learning: A review and new perspectives. IEEE\\nTransactions on Pattern Analysis and Machine Intelli-\\ngence, 35(8):1798‚Äì1828.\\nBengio, Y., R. Ducharme, P. Vincent, and C. Jauvin. 2003.\\nA neural probabilistic language model. JMLR, 3:1137‚Äì\\n1155.\\nBengio, Y., H. Schwenk, J.-S. Sen¬¥ecal, F. Morin, and J.-L.\\nGauvain. 2006. Neural probabilistic language models. In\\nInnovations in Machine Learning, 137‚Äì186. Springer.\\nBisk, Y., A. Holtzman, J. Thomason, J. Andreas, Y. Bengio,\\nJ. Chai, M. Lapata, A. Lazaridou, J. May, A. Nisnevich,\\nN. Pinto, and J. Turian. 2020. Experience grounds lan-\\nguage. EMNLP.\\nBlei, D. M., A. Y. Ng, and M. I. Jordan. 2003. Latent Dirich-\\nlet allocation. JMLR, 3(5):993‚Äì1022.\\nBlodgett, S. L., S. Barocas, H. Daum¬¥e III, and H. Wallach.\\n2020. Language (technology) is power: A critical survey\\nof ‚Äúbias‚Äù in NLP. ACL.\\nBojanowski, P., E. Grave, A. Joulin, and T. Mikolov. 2017.\\nEnriching word vectors with subword information. TACL,\\n5:135‚Äì146.\\nBolukbasi, T., K.-W. Chang, J. Zou, V. Saligrama, and A. T.\\nKalai. 2016. Man is to computer programmer as woman\\nis to homemaker? Debiasing word embeddings. NeurIPS.\\nBr¬¥eal, M. 1897. Essai de S¬¥emantique: Science des signiÔ¨Åca-\\ntions. Hachette.\\nBudanitsky, A. and G. Hirst. 2006.\\nEvaluating WordNet-\\nbased measures of lexical semantic relatedness. Compu-\\ntational Linguistics, 32(1):13‚Äì47.\\nBullinaria, J. A. and J. P. Levy. 2007. Extracting seman-\\ntic representations from word co-occurrence statistics:\\nA computational study.\\nBehavior research methods,\\n39(3):510‚Äì526.\\nBullinaria, J. A. and J. P. Levy. 2012. Extracting semantic\\nrepresentations from word co-occurrence statistics: stop-\\nlists, stemming, and SVD. Behavior research methods,\\n44(3):890‚Äì907.\\nCaliskan, A., J. J. Bryson, and A. Narayanan. 2017. Seman-\\ntics derived automatically from language corpora contain\\nhuman-like biases. Science, 356(6334):183‚Äì186.\\nCarlson, G. N. 1977. Reference to kinds in English. Ph.D.\\nthesis, University of Massachusetts, Amherst. Forward.\\nClark, E. 1987. The principle of contrast: A constraint on\\nlanguage acquisition. In B. MacWhinney, ed., Mecha-\\nnisms of language acquisition, 1‚Äì33. LEA.\\nCoccaro, N. and D. Jurafsky. 1998. Towards better integra-\\ntion of semantic predictors in statistical language model-\\ning. ICSLP.\\nCollobert, R. and J. Weston. 2007. Fast semantic extraction\\nusing a novel neural network architecture. ACL.\\nCollobert, R. and J. Weston. 2008. A uniÔ¨Åed architecture for\\nnatural language processing: Deep neural networks with\\nmultitask learning. ICML.\\nCollobert,\\nR.,\\nJ.\\nWeston,\\nL.\\nBottou,\\nM.\\nKarlen,\\nK. Kavukcuoglu, and P. Kuksa. 2011. Natural language\\nprocessing (almost) from scratch. JMLR, 12:2493‚Äì2537.\\nCordier, B. 1965. Factor-analysis of correspondences. COL-\\nING 1965.\\nCrawford, K. 2017.\\nThe trouble with bias.\\nKeynote at\\nNeurIPS.\\nCruse, D. A. 2004. Meaning in Language: an Introduction\\nto Semantics and Pragmatics. Oxford University Press.\\nSecond edition.\\nDavies, M. 2012.\\nExpanding horizons in historical lin-\\nguistics with the 400-million word Corpus of Historical\\nAmerican English. Corpora, 7(2):121‚Äì157.\\nDavies, M. 2015. The Wikipedia Corpus: 4.6 million arti-\\ncles, 1.9 billion words. Adapted from Wikipedia. https:\\n//www.english-corpora.org/wiki/.\\nDeerwester, S. C., S. T. Dumais, G. W. Furnas, R. A. Harsh-\\nman, T. K. Landauer, K. E. Lochbaum, and L. Streeter.\\n1988. Computer information retrieval using latent seman-\\ntic structure: US Patent 4,839,853.\\nDeerwester, S. C., S. T. Dumais, T. K. Landauer, G. W. Fur-\\nnas, and R. A. Harshman. 1990. Indexing by latent se-\\nmantics analysis. JASIS, 41(6):391‚Äì407.\\nEthayarajh, K., D. Duvenaud, and G. Hirst. 2019a. Towards\\nunderstanding linear word analogies. ACL.\\nEthayarajh, K., D. Duvenaud, and G. Hirst. 2019b. Under-\\nstanding undesirable word embedding associations. ACL.\\nFinkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin,\\nZ. Solan, G. Wolfman, and E. Ruppin. 2002.\\nPlacing\\nsearch in context: The concept revisited. ACM Trans-\\nactions on Information Systems, 20(1):116‚Äî-131.\\nFirth, J. R. 1957.\\nA synopsis of linguistic theory 1930‚Äì\\n1955. In Studies in Linguistic Analysis. Philological So-\\nciety. Reprinted in Palmer, F. (ed.) 1968. Selected Papers\\nof J. R. Firth. Longman, Harlow.\\nGarg, N., L. Schiebinger, D. Jurafsky, and J. Zou. 2018.\\nWord embeddings quantify 100 years of gender and eth-\\nnic stereotypes. Proceedings of the National Academy of\\nSciences, 115(16):E3635‚ÄìE3644.\\nGirard, G. 1718. La justesse de la langue franc¬∏oise: ou les\\ndiff¬¥erentes signiÔ¨Åcations des mots qui passent pour syn-\\nonimes. Laurent d‚ÄôHoury, Paris.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='26\\nChapter 5\\n‚Ä¢\\nEmbeddings\\nGiuliano,\\nV. E. 1965.\\nThe interpretation of word\\nassociations.\\nStatistical Association Methods For\\nMechanized\\nDocumentation.\\nSymposium\\nProceed-\\nings.\\nWashington,\\nD.C.,\\nUSA,\\nMarch\\n17,\\n1964.\\nhttps://nvlpubs.nist.gov/nistpubs/Legacy/\\nMP/nbsmiscellaneouspub269.pdf.\\nGladkova, A., A. Drozd, and S. Matsuoka. 2016. Analogy-\\nbased detection of morphological and semantic relations\\nwith word embeddings: what works and what doesn‚Äôt.\\nNAACL Student Research Workshop.\\nGlenberg, A. M. and D. A. Robertson. 2000. Symbol ground-\\ning and meaning: A comparison of high-dimensional and\\nembodied theories of meaning. Journal of memory and\\nlanguage, 43(3):379‚Äì401.\\nGonen, H. and Y. Goldberg. 2019. Lipstick on a pig: Debi-\\nasing methods cover up systematic gender biases in word\\nembeddings but do not remove them. NAACL HLT.\\nGould, S. J. 1980. The Panda‚Äôs Thumb. Penguin Group.\\nGreenwald, A. G., D. E. McGhee, and J. L. K. Schwartz.\\n1998. Measuring individual differences in implicit cogni-\\ntion: the implicit association test. Journal of personality\\nand social psychology, 74(6):1464‚Äì1480.\\nHamilton, W. L., J. Leskovec, and D. Jurafsky. 2016. Di-\\nachronic word embeddings reveal statistical laws of se-\\nmantic change. ACL.\\nHarris, Z. S. 1954. Distributional structure. Word, 10:146‚Äì\\n162.\\nHellrich,\\nJ. and U. Hahn. 2016.\\nBad company‚Äî\\nNeighborhoods in neural embedding spaces considered\\nharmful. COLING.\\nHill, F., R. Reichart, and A. Korhonen. 2015. Simlex-999:\\nEvaluating semantic models with (genuine) similarity es-\\ntimation. Computational Linguistics, 41(4):665‚Äì695.\\nHjelmslev, L. 1969. Prologomena to a Theory of Language.\\nUniversity of Wisconsin Press. Translated by Francis J.\\nWhitÔ¨Åeld; original Danish edition 1943.\\nHofmann, T. 1999. Probabilistic latent semantic indexing.\\nSIGIR-99.\\nHuang, E. H., R. Socher, C. D. Manning, and A. Y. Ng. 2012.\\nImproving word representations via global context and\\nmultiple word prototypes. ACL.\\nJia, S., T. Meng, J. Zhao, and K.-W. Chang. 2020. Mitigat-\\ning gender bias ampliÔ¨Åcation in distribution by posterior\\nregularization. ACL.\\nJones, M. P. and J. H. Martin. 1997. Contextual spelling cor-\\nrection using latent semantic analysis. ANLP.\\nJoos, M. 1950.\\nDescription of language design.\\nJASA,\\n22:701‚Äì708.\\nJurgens, D., S. M. Mohammad, P. Turney, and K. Holyoak.\\n2012. SemEval-2012 task 2: Measuring degrees of rela-\\ntional similarity. *SEM 2012.\\nKatz, J. J. and J. A. Fodor. 1963. The structure of a semantic\\ntheory. Language, 39:170‚Äì210.\\nKiela, D. and S. Clark. 2014. A systematic study of semantic\\nvector space model parameters. EACL 2nd Workshop on\\nContinuous Vector Space Models and their Composition-\\nality (CVSC).\\nKim,\\nE.\\n2019.\\nOptimize\\ncomputational\\nefÔ¨Åciency\\nof skip-gram with negative sampling.\\nhttps://\\naegis4048.github.io/optimize_computational_\\nefficiency_of_skip-gram_with_negative_\\nsampling.\\nLake, B. M. and G. L. Murphy. 2021.\\nWord meaning in\\nminds and machines. Psychological Review. In press.\\nLandauer, T. K. and S. T. Dumais. 1997. A solution to Plato‚Äôs\\nproblem: The Latent Semantic Analysis theory of acqui-\\nsition, induction, and representation of knowledge. Psy-\\nchological Review, 104:211‚Äì240.\\nLandauer, T. K., D. Laham, B. Rehder, and M. E. Schreiner.\\n1997. How well can passage meaning be derived with-\\nout using word order? A comparison of Latent Semantic\\nAnalysis and humans. COGSCI.\\nLapesa, G. and S. Evert. 2014. A large scale evaluation of\\ndistributional semantic models: Parameters, interactions\\nand model selection. TACL, 2:531‚Äì545.\\nLee, D. D. and H. S. Seung. 1999. Learning the parts of\\nobjects by non-negative matrix factorization.\\nNature,\\n401(6755):788‚Äì791.\\nLevy, O. and Y. Goldberg. 2014a. Dependency-based word\\nembeddings. ACL.\\nLevy, O. and Y. Goldberg. 2014b. Linguistic regularities in\\nsparse and explicit word representations. CoNLL.\\nLevy, O. and Y. Goldberg. 2014c. Neural word embedding\\nas implicit matrix factorization. NeurIPS.\\nLevy, O., Y. Goldberg, and I. Dagan. 2015. Improving dis-\\ntributional similarity with lessons learned from word em-\\nbeddings. TACL, 3:211‚Äì225.\\nLin, Y., J.-B. Michel, E. Lieberman Aiden, J. Orwant,\\nW. Brockman, and S. Petrov. 2012. Syntactic annotations\\nfor the Google Books NGram corpus. ACL.\\nLinzen, T. 2016. Issues in evaluating semantic spaces us-\\ning word analogies. 1st Workshop on Evaluating Vector-\\nSpace Representations for NLP.\\nManning, C. D., P. Raghavan, and H. Sch¬®utze. 2008. Intro-\\nduction to Information Retrieval. Cambridge.\\nMikolov, T., K. Chen, G. S. Corrado, and J. Dean. 2013a. Ef-\\nÔ¨Åcient estimation of word representations in vector space.\\nICLR 2013.\\nMikolov, T., S. Kombrink, L. Burget, J. H. ÀáCernock`y, and\\nS. Khudanpur. 2011. Extensions of recurrent neural net-\\nwork language model. ICASSP.\\nMikolov, T., I. Sutskever, K. Chen, G. S. Corrado, and\\nJ. Dean. 2013b. Distributed representations of words and\\nphrases and their compositionality. NeurIPS.\\nMikolov, T., W.-t. Yih, and G. Zweig. 2013c.\\nLinguis-\\ntic regularities in continuous space word representations.\\nNAACL HLT.\\nNosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002a.\\nHarvesting implicit group attitudes and beliefs from a\\ndemonstration web site. Group Dynamics: Theory, Re-\\nsearch, and Practice, 6(1):101.\\nNosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002b.\\nMath=male, me=female, therefore mathÃ∏= me. Journal of\\npersonality and social psychology, 83(1):44.\\nOsgood, C. E., G. J. Suci, and P. H. Tannenbaum. 1957. The\\nMeasurement of Meaning. University of Illinois Press.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 26}, page_content='Exercises\\n27\\nPennington, J., R. Socher, and C. D. Manning. 2014. GloVe:\\nGlobal vectors for word representation. EMNLP.\\nPeterson, J. C., D. Chen, and T. L. GrifÔ¨Åths. 2020. Parallelo-\\ngrams revisited: Exploring the limitations of vector space\\nmodels for simple analogies. Cognition, 205.\\nPilehvar, M. T. and J. Camacho-Collados. 2019. WiC: the\\nword-in-context dataset for evaluating context-sensitive\\nmeaning representations. NAACL HLT.\\nRehder, B., M. E. Schreiner, M. B. W. Wolfe, D. Laham,\\nT. K. Landauer, and W. Kintsch. 1998.\\nUsing Latent\\nSemantic Analysis to assess knowledge: Some technical\\nconsiderations. Discourse Processes, 25(2-3):337‚Äì354.\\nRohde, D. L. T., L. M. Gonnerman, and D. C. Plaut. 2006.\\nAn improved model of semantic similarity based on lexi-\\ncal co-occurrence. CACM, 8:627‚Äì633.\\nRumelhart, D. E. and A. A. Abrahamson. 1973. A model for\\nanalogical reasoning. Cognitive Psychology, 5(1):1‚Äì28.\\nSalton, G. 1971. The SMART Retrieval System: Experiments\\nin Automatic Document Processing. Prentice Hall.\\nSchluter, N. 2018. The word analogy testing caveat. NAACL\\nHLT.\\nSchone, P. and D. Jurafsky. 2000. Knowlege-free induction\\nof morphology using latent semantic analysis. CoNLL.\\nSchone, P. and D. Jurafsky. 2001a. Is knowledge-free in-\\nduction of multiword unit dictionary headwords a solved\\nproblem? EMNLP.\\nSchone, P. and D. Jurafsky. 2001b. Knowledge-free induc-\\ntion of inÔ¨Çectional morphologies. NAACL.\\nSch¬®utze, H. 1992. Dimensions of meaning. Proceedings of\\nSupercomputing ‚Äô92. IEEE Press.\\nSch¬®utze, H. 1997. Ambiguity Resolution in Language Learn-\\ning ‚Äì Computational and Cognitive Models. CSLI, Stan-\\nford, CA.\\nSch¬®utze, H., D. A. Hull, and J. Pedersen. 1995. A compar-\\nison of classiÔ¨Åers and document representations for the\\nrouting problem. SIGIR-95.\\nSch¬®utze, H. and J. Pedersen. 1993. A vector model for syn-\\ntagmatic and paradigmatic relatedness. 9th Annual Con-\\nference of the UW Centre for the New OED and Text Re-\\nsearch.\\nSparck Jones, K. 1972. A statistical interpretation of term\\nspeciÔ¨Åcity and its application in retrieval. Journal of Doc-\\numentation, 28(1):11‚Äì21.\\nSparck Jones, K. 1986. Synonymy and Semantic ClassiÔ¨Åca-\\ntion. Edinburgh University Press, Edinburgh. Republica-\\ntion of 1964 PhD Thesis.\\nSwitzer, P. 1965.\\nVector images in document retrieval.\\nStatistical Association Methods For Mechanized Docu-\\nmentation. Symposium Proceedings. Washington, D.C.,\\nUSA, March 17, 1964. https://nvlpubs.nist.gov/\\nnistpubs/Legacy/MP/nbsmiscellaneouspub269.\\npdf.\\nTian, Y., V. Kulkarni, B. Perozzi, and S. Skiena. 2016. On\\nthe convergent properties of word embedding methods.\\nArXiv preprint arXiv:1605.03956.\\nTurian, J., L. Ratinov, and Y. Bengio. 2010. Word represen-\\ntations: a simple and general method for semi-supervised\\nlearning. ACL.\\nTurney, P. D. and M. L. Littman. 2005. Corpus-based learn-\\ning of analogies and semantic relations. Machine Learn-\\ning, 60(1-3):251‚Äì278.\\nvan der Maaten, L. and G. E. Hinton. 2008. Visualizing high-\\ndimensional data using t-SNE. JMLR, 9:2579‚Äì2605.\\nWierzbicka, A. 1992. Semantics, Culture, and Cognition:\\nUniversity Human Concepts in Culture-SpeciÔ¨Åc ConÔ¨Ågu-\\nrations. Oxford University Press.\\nWierzbicka, A. 1996. Semantics: Primes and Universals.\\nOxford University Press.\\nWittgenstein, L. 1953. Philosophical Investigations. (Trans-\\nlated by Anscombe, G.E.M.). Blackwell.\\nZhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-\\nW. Chang. 2017.\\nMen also like shopping: Reducing\\ngender bias ampliÔ¨Åcation using corpus-level constraints.\\nEMNLP.\\nZhao, J., Y. Zhou, Z. Li, W. Wang, and K.-W. Chang. 2018.\\nLearning gender-neutral word embeddings. EMNLP.')]\n"
     ]
    }
   ],
   "source": [
    "pdf = process_all_pdf('./data')\n",
    "print(pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8ffaa26",
   "metadata": {},
   "source": [
    "#Chunking Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d670d4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "def split_documents(documents , chunk_size=1000 , chunk_overlap=200):\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size,\n",
    "        chunk_overlap=chunk_overlap,\n",
    "        length_function=len,\n",
    "        separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs = text_splitter.split_documents(documents)\n",
    "    print(f\" split {len(documents)} documents into {len(split_docs)} chunks \")\n",
    "    print(f\" example chunk : {split_docs}\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    return split_docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "83e14c23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " split 30 documents into 116 chunks \n",
      " example chunk : [Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 0}, page_content='Darshan Hiremath \\n8904691801 | darshanah2002@gmail.com \\n \\nProfile \\nAI & Machine Learning enthusiast with hands-on experience in Statistical Models, Transformer \\nModels, and Large Language Models (LLMs). Passionate about model explainability, fine-tuning \\ntechniques, and AI-powered applications. Skilled in integrating LIME, SHAP, and LLMs (GPT-\\n4, Gemini AI) to enhance interpretability. Experienced in efficient fine-tuning (LoRA, PEFT) and \\noptimizing large models for real-world use. \\n \\nTechnical Skills \\nProgramming: Python \\n‚Ä¢ \\nExplainable AI: SHAP, LIME, Grad-CAM, Integrated Gradients \\n‚Ä¢ \\nLLM : Llama 3.1  \\n‚Ä¢ \\nDeep Learning: CNNs, Transformers, LLMs   \\n‚Ä¢ \\nNLP Models: GPT-2, DistilBERT   \\n‚Ä¢ \\nLLM Fine-Tuning: LoRA, PEFT, Quantization (4-bit, 8-bit)   \\n‚Ä¢ \\nFrameworks: PyTorch, TensorFlow , Hugging Face   \\n‚Ä¢ \\nTools: Gemini AI, GPT-4   \\n‚Ä¢ \\nDomains: XAI, NLP, Deep Learning , Model Interpretability \\n \\nWork Experience \\nAI & Machine Learning Engineer'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 0}, page_content='‚Ä¢ \\nFrameworks: PyTorch, TensorFlow , Hugging Face   \\n‚Ä¢ \\nTools: Gemini AI, GPT-4   \\n‚Ä¢ \\nDomains: XAI, NLP, Deep Learning , Model Interpretability \\n \\nWork Experience \\nAI & Machine Learning Engineer   \\nL&T Technology Services | July 2024 ‚Äì Present   \\n \\nExplainable AI ‚Äì Statistical Models (Honda Use Case) \\n\\uf0b7 \\nApplied LIME and SHAP to explain predictions of a statistical sensor-based quality \\nmodel (Gx, Gy, Gz). \\n\\uf0b7 \\nDelivered instance-level and global feature attributions for ‚ÄúGood / No-Good‚Äù \\nclassifications. \\n\\uf0b7 \\nIntegrated GPT-4 and Gemini AI to automatically convert XAI outputs into \\nbusiness-friendly explanations for non-technical stakeholders. \\n\\uf0b7 \\nPresented explainability results through visual reports and demo videos to cross-\\nfunctional teams. \\n \\nExplainability in Transformer Models \\n\\uf0b7 Investigated feasibility of applying SHAP to transformer architectures. \\n\\uf0b7 Fine-tuned GPT-2 and DistilBERT on Amazon Reviews for sentiment \\nclassification.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 0}, page_content='Explainability in Transformer Models \\n\\uf0b7 Investigated feasibility of applying SHAP to transformer architectures. \\n\\uf0b7 Fine-tuned GPT-2 and DistilBERT on Amazon Reviews for sentiment \\nclassification. \\n\\uf0b7 Identified and resolved incorrect attribution issues by improving fine-tuning strategy. \\n\\uf0b7 Successfully generated token-level and feature-level explanations for transformer \\npredictions. \\n \\nExploration of LLMs & Efficient Fine-Tuning \\n\\uf0b7 Explored explainability extensions for Large Language Models (LLMs). \\n\\uf0b7 Experimented with 4-bit and 8-bit quantized model loading for memory-efficient \\ninference. \\n\\uf0b7 Implemented PEFT techniques, including LoRA, to fine-tune LLMs with reduced \\ncompute cost. \\n\\uf0b7 Evaluated trade-offs between performance, memory usage, and interpretability.'), Document(metadata={'producer': 'www.ilovepdf.com', 'creator': 'Microsoft¬Æ Word 2016', 'creationdate': '2025-12-23T17:27:33+00:00', 'source': 'Darshan_resume.pdf', 'file_path': 'data\\\\Darshan_resume.pdf', 'total_pages': 3, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creationDate': \"D:20251223172733+00'00'\", 'page': 1}, page_content='Hackathon  \\n\\uf0b7 \\nParticipated in L&T internal hackathon focused on applied AI solutions. \\n\\uf0b7 \\nImplemented Grad-CAM on ResNet for eye disease classification, highlighting \\nclass-discriminative regions. \\n\\uf0b7 \\nDemonstrated how CNN models learn visual patterns and validated predictions using \\nsaliency maps. \\nEDUCATION \\nBapuji Institute Of Engineering And Technology                                                    2020 ‚Äì 2024 \\nComputer Science & Engineering                                                                              \\n7.8/10 CGPA  \\nVishwaachetana Vidyaniketana Pu College                                                              2018 - 2020 \\n 73 percent  \\nOM National PU College                                                                                          2018 \\n71 percent'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 0}, page_content='Speech and Language Processing.\\nDaniel Jurafsky & James H. Martin.\\nCopyright ¬© 2025.\\nAll\\nrights reserved.\\nDraft of August 24, 2025.\\nCHAPTER\\n5\\nEmbeddings\\nËçÉËÄÖÊâÄ‰ª•Âú®È±ºÔºåÂæóÈ±ºËÄåÂøòËçÉNets are for Ô¨Åsh;\\nOnce you get the Ô¨Åsh, you can forget the net.\\nË®ÄËÄÖÊâÄ‰ª•Âú®ÊÑèÔºåÂæóÊÑèËÄåÂøòË®ÄWords are for meaning;\\nOnce you get the meaning, you can forget the words\\nÂ∫ÑÂ≠ê(Zhuangzi), Chapter 26\\nThe asphalt that Los Angeles is famous for occurs mainly on its freeways. But\\nin the middle of the city is another patch of asphalt, the La Brea tar pits, and this\\nasphalt preserves millions of fossil bones from the last of the Ice Ages of the Pleis-\\ntocene Epoch. One of these fossils is the Smilodon, or saber-toothed tiger, instantly\\nrecognizable by its long canines. Five million years ago or so, a completely different\\nsaber-tooth tiger called Thylacosmilus lived\\nin Argentina and other parts of South Amer-\\nica. Thylacosmilus was a marsupial whereas\\nSmilodon was a placental mammal, but Thy-\\nlacosmilus had the same long upper canines'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 0}, page_content='in Argentina and other parts of South Amer-\\nica. Thylacosmilus was a marsupial whereas\\nSmilodon was a placental mammal, but Thy-\\nlacosmilus had the same long upper canines\\nand, like Smilodon, had a protective bone\\nÔ¨Çange on the lower jaw.\\nThe similarity of\\nthese two mammals is one of many examples\\nof parallel or convergent evolution, in which particular contexts or environments\\nlead to the evolution of very similar structures in different species (Gould, 1980).\\nThe role of context is also important in the similarity of a less biological kind\\nof organism: the word. Words that occur in similar contexts tend to have similar\\nmeanings. This link between similarity in how words are distributed and similarity\\nin what they mean is called the distributional hypothesis. The hypothesis was\\ndistributional\\nhypothesis\\nÔ¨Årst formulated in the 1950s by linguists like Joos (1950), Harris (1954), and Firth\\n(1957), who noticed that words which are synonyms (like oculist and eye-doctor)'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 0}, page_content='distributional\\nhypothesis\\nÔ¨Årst formulated in the 1950s by linguists like Joos (1950), Harris (1954), and Firth\\n(1957), who noticed that words which are synonyms (like oculist and eye-doctor)\\ntended to occur in the same environment (e.g., near words like eye or examined)\\nwith the amount of meaning difference between two words ‚Äúcorresponding roughly\\nto the amount of difference in their environments‚Äù (Harris, 1954, p. 157).\\nIn this chapter we introduce embeddings, vector representations of the meaning\\nembeddings\\nof words that are learned directly from word distributions in texts. Embeddings lie\\nat the heart of large language models and other modern applications. The static em-\\nbeddings we introduce here underlie the more powerful dynamic or contextualized\\nembeddings like BERT that we will see in Chapter 10 and Chapter 8.\\nThe linguistic Ô¨Åeld that studies embeddings and their meanings is called vector\\nsemantics. Embeddings are also the Ô¨Årst example in this book of representation\\nvector'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 0}, page_content='The linguistic Ô¨Åeld that studies embeddings and their meanings is called vector\\nsemantics. Embeddings are also the Ô¨Årst example in this book of representation\\nvector\\nsemantics\\nlearning, automatically learning useful representations of the input text. Finding\\nrepresentation\\nlearning\\nsuch self-supervised ways to learn representations of language, instead of creat-\\ning representations by hand via feature engineering, is an important principle of\\nmodern NLP (Bengio et al., 2013).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 1}, page_content='2\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n5.1\\nLexical Semantics\\nLet‚Äôs begin by introducing some basic principles of word meaning. How should\\nwe represent the meaning of a word? In the n-gram models of Chapter 3, and in\\nclassical NLP applications, our only representation of a word is as a string of letters,\\nor an index in a vocabulary list. This representation is not that different from a\\ntradition in philosophy, perhaps you‚Äôve seen it in introductory logic classes, in which\\nthe meaning of words is represented by just spelling the word with small capital\\nletters; representing the meaning of ‚Äúdog‚Äù as DOG, and ‚Äúcat‚Äù as CAT, or by using an\\napostrophe (DOG‚Äô).\\nRepresenting the meaning of a word by capitalizing it is a pretty unsatisfactory\\nmodel. You might have seen a version of a joke due originally to semanticist Barbara\\nPartee (Carlson, 1977):\\nQ: What‚Äôs the meaning of life?\\nA: LIFE‚Äô\\nSurely we can do better than this! After all, we‚Äôll want a model of word meaning'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 1}, page_content='Partee (Carlson, 1977):\\nQ: What‚Äôs the meaning of life?\\nA: LIFE‚Äô\\nSurely we can do better than this! After all, we‚Äôll want a model of word meaning\\nto do all sorts of things for us. It should tell us that some words have similar mean-\\nings (cat is similar to dog), others are antonyms (cold is the opposite of hot), some\\nhave positive connotations (happy) while others have negative connotations (sad). It\\nshould represent the fact that the meanings of buy, sell, and pay offer differing per-\\nspectives on the same underlying purchasing event. (If I buy something from you,\\nyou‚Äôve probably sold it to me, and I likely paid you.) More generally, a model of\\nword meaning should allow us to draw inferences to address meaning-related tasks\\nlike question-answering or dialogue.\\nIn this section we summarize some of these desiderata, drawing on results in the\\nlinguistic study of word meaning, which is called lexical semantics; we‚Äôll return to\\nlexical\\nsemantics'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 1}, page_content='In this section we summarize some of these desiderata, drawing on results in the\\nlinguistic study of word meaning, which is called lexical semantics; we‚Äôll return to\\nlexical\\nsemantics\\nand expand on this list in Appendix G and Chapter 21.\\nLemmas and Senses\\nLet‚Äôs start by looking at how one word (we‚Äôll choose mouse)\\nmight be deÔ¨Åned in a dictionary (simpliÔ¨Åed from the online dictionary WordNet):\\nmouse (N)\\n1.\\nany of numerous small rodents...\\n2.\\na hand-operated device that controls a cursor...\\nHere the form mouse is the lemma, also called the citation form. The form\\nlemma\\ncitation form\\nmouse would also be the lemma for the word mice; dictionaries don‚Äôt have separate\\ndeÔ¨Ånitions for inÔ¨Çected forms like mice. Similarly sing is the lemma for sing, sang,\\nsung. In many languages the inÔ¨Ånitive form is used as the lemma for the verb, so\\nSpanish dormir ‚Äúto sleep‚Äù is the lemma for duermes ‚Äúyou sleep‚Äù. The speciÔ¨Åc forms\\nsung or carpets or sing or duermes are called wordforms.\\nwordform'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 1}, page_content='Spanish dormir ‚Äúto sleep‚Äù is the lemma for duermes ‚Äúyou sleep‚Äù. The speciÔ¨Åc forms\\nsung or carpets or sing or duermes are called wordforms.\\nwordform\\nAs the example above shows, each lemma can have multiple meanings; the\\nlemma mouse can refer to the rodent or the cursor control device. We call each\\nof these aspects of the meaning of mouse a word sense. The fact that lemmas can\\nbe polysemous (have multiple senses) can make interpretation difÔ¨Åcult (is some-\\none who searches for ‚Äúmouse info‚Äù looking for a pet or a widget?). Chapter 10\\nand Appendix G will discuss the problem of polysemy, and introduce word sense\\ndisambiguation, the task of determining which sense of a word is being used in a\\nparticular context.\\nSynonymy\\nOne important component of word meaning is the relationship be-\\ntween word senses. For example when one word has a sense whose meaning is'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 2}, page_content='5.1\\n‚Ä¢\\nLEXICAL SEMANTICS\\n3\\nidentical to a sense of another word, or nearly identical, we say the two senses of\\nthose two words are synonyms. Synonyms include such pairs as\\nsynonym\\ncouch/sofa vomit/throw up Ô¨Ålbert/hazelnut car/automobile\\nA more formal deÔ¨Ånition of synonymy (between words rather than senses) is that\\ntwo words are synonymous if they are substitutable for one another in any sentence\\nwithout changing the truth conditions of the sentence, the situations in which the\\nsentence would be true.\\nWhile substitutions between some pairs of words like car / automobile or wa-\\nter / H2O are truth preserving, the words are still not identical in meaning. Indeed,\\nprobably no two words are absolutely identical in meaning. One of the fundamental\\ntenets of semantics, called the principle of contrast (Girard 1718, Br¬¥eal 1897, Clark\\nprinciple of\\ncontrast\\n1987), states that a difference in linguistic form is always associated with some dif-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 2}, page_content='tenets of semantics, called the principle of contrast (Girard 1718, Br¬¥eal 1897, Clark\\nprinciple of\\ncontrast\\n1987), states that a difference in linguistic form is always associated with some dif-\\nference in meaning. For example, the word H2O is used in scientiÔ¨Åc contexts and\\nwould be inappropriate in a hiking guide‚Äîwater would be more appropriate‚Äî and\\nthis genre difference is part of the meaning of the word. In practice, the word syn-\\nonym is therefore used to describe a relationship of approximate or rough synonymy.\\nWord Similarity\\nWhile words don‚Äôt have many synonyms, most words do have\\nlots of similar words. Cat is not a synonym of dog, but cats and dogs are certainly\\nsimilar words. In moving from synonymy to similarity, it will be useful to shift from\\ntalking about relations between word senses (like synonymy) to relations between\\nwords (like similarity). Dealing with words avoids having to commit to a particular'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 2}, page_content='talking about relations between word senses (like synonymy) to relations between\\nwords (like similarity). Dealing with words avoids having to commit to a particular\\nrepresentation of word senses, which will turn out to simplify our task.\\nThe notion of word similarity is very useful in larger semantic tasks. Knowing\\nsimilarity\\nhow similar two words are can help in computing how similar the meaning of two\\nphrases or sentences are, a very important component of tasks like question answer-\\ning, paraphrasing, and summarization. One way of getting values for word similarity\\nis to ask humans to judge how similar one word is to another. A number of datasets\\nhave resulted from such experiments. For example the SimLex-999 dataset (Hill\\net al., 2015) gives values on a scale from 0 to 10, like the examples below, which\\nrange from near-synonyms (vanish, disappear) to pairs that scarcely seem to have\\nanything in common (hole, agreement):\\nvanish\\ndisappear\\n9.8\\nbelief\\nimpression 5.95\\nmuscle bone\\n3.65'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 2}, page_content='range from near-synonyms (vanish, disappear) to pairs that scarcely seem to have\\nanything in common (hole, agreement):\\nvanish\\ndisappear\\n9.8\\nbelief\\nimpression 5.95\\nmuscle bone\\n3.65\\nmodest Ô¨Çexible\\n0.98\\nhole\\nagreement\\n0.3\\nWord Relatedness\\nThe meaning of two words can be related in ways other than\\nsimilarity. One such class of connections is called word relatedness (Budanitsky\\nrelatedness\\nand Hirst, 2006), also traditionally called word association in psychology.\\nassociation\\nConsider the meanings of the words coffee and cup. Coffee is not similar to cup;\\nthey share practically no features (coffee is a plant or a beverage, while a cup is a\\nmanufactured object with a particular shape). But coffee and cup are clearly related;\\nthey are associated by co-participating in an everyday event (the event of drinking\\ncoffee out of a cup). Similarly scalpel and surgeon are not similar but are related\\neventively (a surgeon tends to make use of a scalpel).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 2}, page_content='coffee out of a cup). Similarly scalpel and surgeon are not similar but are related\\neventively (a surgeon tends to make use of a scalpel).\\nOne common kind of relatedness between words is if they belong to the same\\nsemantic Ô¨Åeld. A semantic Ô¨Åeld is a set of words which cover a particular semantic\\nsemantic Ô¨Åeld\\ndomain and bear structured relations with each other. For example, words might be'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 3}, page_content='4\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nrelated by being in the semantic Ô¨Åeld of hospitals (surgeon, scalpel, nurse, anes-\\nthetic, hospital), restaurants (waiter, menu, plate, food, chef), or houses (door, roof,\\nkitchen, family, bed). Semantic Ô¨Åelds are also related to topic models, like Latent\\ntopic models\\nDirichlet Allocation, LDA, which apply unsupervised learning on large sets of texts\\nto induce sets of associated words from text. Semantic Ô¨Åelds and topic models are\\nvery useful tools for discovering topical structure in documents.\\nIn Appendix G we‚Äôll introduce more relations between senses like hypernymy\\nor IS-A, antonymy (opposites) and meronymy (part-whole relations).\\nConnotation\\nFinally, words have affective meanings or connotations. The word\\nconnotations\\nconnotation has different meanings in different Ô¨Åelds, but here we use it to mean the\\naspects of a word‚Äôs meaning that are related to a writer or reader‚Äôs emotions, senti-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 3}, page_content='connotations\\nconnotation has different meanings in different Ô¨Åelds, but here we use it to mean the\\naspects of a word‚Äôs meaning that are related to a writer or reader‚Äôs emotions, senti-\\nment, opinions, or evaluations. For example some words have positive connotations\\n(wonderful) while others have negative connotations (dreary). Even words whose\\nmeanings are similar in other ways can vary in connotation; consider the difference\\nin connotations between fake, knockoff, forgery, on the one hand, and copy, replica,\\nreproduction on the other, or innocent (positive connotation) and naive (negative\\nconnotation). Some words describe positive evaluation (great, love) and others neg-\\native evaluation (terrible, hate). Positive or negative evaluation language is called\\nsentiment, as we saw in Appendix K, and word sentiment plays a role in impor-\\nsentiment\\ntant tasks like sentiment analysis, stance detection, and applications of NLP to the\\nlanguage of politics and consumer reviews.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 3}, page_content='sentiment\\ntant tasks like sentiment analysis, stance detection, and applications of NLP to the\\nlanguage of politics and consumer reviews.\\nEarly work on affective meaning (Osgood et al., 1957) found that words varied\\nalong three important dimensions of affective meaning:\\nvalence: the pleasantness of the stimulus\\narousal: the intensity of emotion provoked by the stimulus\\ndominance: the degree of control exerted by the stimulus\\nThus words like happy or satisÔ¨Åed are high on valence, while unhappy or an-\\nnoyed are low on valence. Excited is high on arousal, while calm is low on arousal.\\nControlling is high on dominance, while awed or inÔ¨Çuenced are low on dominance.\\nEach word is thus represented by three numbers, corresponding to its value on each\\nof the three dimensions:\\nValence Arousal Dominance\\ncourageous 8.0\\n5.5\\n7.4\\nmusic\\n7.7\\n5.6\\n6.5\\nheartbreak\\n2.5\\n5.7\\n3.6\\ncub\\n6.7\\n4.0\\n4.2\\nOsgood et al. (1957) noticed that in using these 3 numbers to represent the'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 3}, page_content='Valence Arousal Dominance\\ncourageous 8.0\\n5.5\\n7.4\\nmusic\\n7.7\\n5.6\\n6.5\\nheartbreak\\n2.5\\n5.7\\n3.6\\ncub\\n6.7\\n4.0\\n4.2\\nOsgood et al. (1957) noticed that in using these 3 numbers to represent the\\nmeaning of a word, the model was representing each word as a point in a three-\\ndimensional space, a vector whose three dimensions corresponded to the word‚Äôs\\nrating on the three scales. This revolutionary idea that word meaning could be rep-\\nresented as a point in space (e.g., that part of the meaning of heartbreak can be\\nrepresented as the point [2.5,5.7,3.6]) was the Ô¨Årst expression of the vector seman-\\ntics models that we introduce next.\\n5.2\\nVector Semantics: The Intuition\\nVector semantics is the standard way to represent word meaning in NLP, helping\\nvector\\nsemantics'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 4}, page_content='5.2\\n‚Ä¢\\nVECTOR SEMANTICS: THE INTUITION\\n5\\nus model many of the aspects of word meaning we saw in the previous section. The\\nroots of the model lie in the 1950s when two big ideas converged: Osgood‚Äôs 1957\\nidea mentioned above to use a point in three-dimensional space to represent the\\nconnotation of a word, and the proposal by linguists like Joos (1950), Harris (1954),\\nand Firth (1957) to deÔ¨Åne the meaning of a word by its distribution in language\\nuse, meaning its neighboring words or grammatical environments. Their idea was\\nthat two words that occur in very similar distributions (whose neighboring words are\\nsimilar) have similar meanings.\\nFor example, suppose you didn‚Äôt know the meaning of the word ongchoi (a re-\\ncent borrowing from Cantonese) but you see it in the following contexts:\\n(5.1) Ongchoi is delicious sauteed with garlic.\\n(5.2) Ongchoi is superb over rice.\\n(5.3) ...ongchoi leaves with salty sauces...\\nAnd suppose that you had seen many of these context words in other contexts:'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 4}, page_content='(5.2) Ongchoi is superb over rice.\\n(5.3) ...ongchoi leaves with salty sauces...\\nAnd suppose that you had seen many of these context words in other contexts:\\n(5.4) ...spinach sauteed with garlic over rice...\\n(5.5) ...chard stems and leaves are delicious...\\n(5.6) ...collard greens and other salty leafy greens\\nThe fact that ongchoi occurs with words like rice and garlic and delicious and\\nsalty, as do words like spinach, chard, and collard greens might suggest that ongchoi\\nis a leafy green similar to these other leafy greens.1 We can implement the same\\nintuition computationally by just counting words in the context of ongchoi.\\nFigure 5.1\\nA two-dimensional (t-SNE) visualization of 200-dimensional word2vec em-\\nbeddings for some words close to the word sweet, showing that words with similar mean-\\nings are nearby in space. Visualization created using the TensorBoard Embedding Projector\\nhttps://projector.tensorflow.org/.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 4}, page_content='ings are nearby in space. Visualization created using the TensorBoard Embedding Projector\\nhttps://projector.tensorflow.org/.\\nThe idea of vector semantics is to represent a word as a point in a multidimen-\\nsional semantic space that is derived (in different ways we‚Äôll see) from the distri-\\nbutions of word neighbors. Vectors for representing words are called embeddings.\\nembeddings\\nThe word ‚Äúembedding‚Äù derives historically from its mathematical sense as a map-\\nping from one space or structure to another, although the meaning has shifted; see\\nthe end of the chapter.\\nFig. 5.1 shows a visualization of embeddings learned by the word2vec algorithm,\\nshowing the location of selected words (neighbors of ‚Äúsweet‚Äù) projected down from\\n1\\nIt‚Äôs in fact Ipomoea aquatica, a relative of morning glory sometimes called water spinach in English.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 5}, page_content='6\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n200-dimensional space into a 2-dimensional space. Note that the nearest neighbors\\nof sweet are semantically related words like honey, candy, juice, chocolate. This idea\\nthat similar words are near each other in high-dimensional space is an important\\nthat offers enormous power to language models and other NLP applications. For\\nexample the sentiment classiÔ¨Åers of Chapter 4 depend on the same words appearing\\nin the training and test sets. But by representing words as embeddings, a classiÔ¨Åer\\ncan assign sentiment as long as it sees some words with similar meanings. And as\\nwe‚Äôll see, vector semantic models like the ones showed in Fig. 5.1 can be learned\\nautomatically from text without supervision.\\nIn this chapter we‚Äôll begin with a simple pedagogical model of embeddings in\\nwhich the meaning of a word is deÔ¨Åned by a vector with the counts of nearby words.\\nWe introduce this model as a helpful way to understand the concept of vectors and'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 5}, page_content='which the meaning of a word is deÔ¨Åned by a vector with the counts of nearby words.\\nWe introduce this model as a helpful way to understand the concept of vectors and\\nwhat it means for a vector to be a representation of word meaning, but more sophis-\\nticated variants like the tf-idf model we will introduce in Chapter 11 are important\\nmethods you should understand. We will see that this method results in very long\\nvectors that are sparse, i.e. mostly zeros (since most words simply never occur in the\\ncontext of others). We‚Äôll then introduce the word2vec model family for constructing\\nshort, dense vectors that have even more useful semantic properties.\\nWe‚Äôll also introduce the cosine, the standard way to use embeddings to com-\\npute semantic similarity, between two words, two sentences, or two documents, an\\nimportant tool in practical applications.\\n5.3\\nSimple count-based embeddings\\n‚ÄúThe most important attributes of a vector in 3-space are {Location, Location, Location}‚Äù'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 5}, page_content='important tool in practical applications.\\n5.3\\nSimple count-based embeddings\\n‚ÄúThe most important attributes of a vector in 3-space are {Location, Location, Location}‚Äù\\nRandall Munroe, the hover from https://xkcd.com/2358/\\nLet‚Äôs now introduce the Ô¨Årst way to compute word vector embeddings. This sim-\\nplest vector model of meaning is based on the co-occurrence matrix, a way of rep-\\nresenting how often words co-occur. We‚Äôll deÔ¨Åne a particular kind of co-occurrence\\nmatrix, the word-context matrix, in which each row in the matrix represents a word\\nword-context\\nmatrix\\nin the vocabulary and each column represents how often each other word in the vo-\\ncabulary appears nearby. This matrix is thus of dimensionality |V| √ó |V| and each\\ncell records the number of times the row (target) word and the column (context)\\nword co-occur nearby in some training corpus.\\nWhat do we mean by ‚Äònearby‚Äô? We could implement various methods, but let‚Äôs'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 5}, page_content='word co-occur nearby in some training corpus.\\nWhat do we mean by ‚Äònearby‚Äô? We could implement various methods, but let‚Äôs\\nstart with a very simple one: a context window around the word, let‚Äôs say of 4 words\\nto the left and 4 words to the right. If we do that, each cell will represents the\\nnumber of times (in some training corpus) the column word occurs in such a ¬±4\\nword window around the row word.\\nLet‚Äôs see how this works for 4 words: cherry, strawberry, digital, and informa-\\ntion. For each word we took a single instance from a corpus, and we show the ¬±4\\nword window from that instance:\\nis traditionally followed by cherry\\npie, a traditional dessert\\noften mixed, such as strawberry\\nrhubarb pie. Apple pie\\ncomputer peripherals and personal digital\\nassistants. These devices usually\\na computer. This includes information available on the internet\\nIf we then take every occurrence of each word in a large corpus and count the'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 5}, page_content='assistants. These devices usually\\na computer. This includes information available on the internet\\nIf we then take every occurrence of each word in a large corpus and count the\\ncontext words around it, we get a word-context co-occurrence matrix. The full word-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 6}, page_content='5.3\\n‚Ä¢\\nSIMPLE COUNT-BASED EMBEDDINGS\\n7\\ncontext co-occurrence matrix is very large, because for each word in the vocabulary\\n(since |V|) we have to count how often it occurs with every other word in the vo-\\ncabulary, hence dimensionality |V|√ó|V|. Let‚Äôs therefore instead sketch the process\\non a smaller scale. Imagine that we are going to look at only the 4 words, and only\\nconsider the following 3 context words: a, computer, and pie. Furthermore let‚Äôs\\nassume we only count occurrences in the mini-corpus above.\\nSo before looking at Fig. 5.2, compute by hand the counts for these 3 context\\nwords for the four words cherry, strawberry, digital, and information.\\na\\ncomputer\\npie\\ncherry\\n1\\n0\\n1\\nstrawberry\\n0\\n0\\n2\\ndigital\\n0\\n1\\n0\\ninformation\\n1\\n1\\n0\\nFigure 5.2\\nCo-occurrence vectors for four words with counts from the 4 windows above,\\nshowing just 3 of the potential context word dimensions. The vector for cherry is outlined in'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 6}, page_content='0\\ninformation\\n1\\n1\\n0\\nFigure 5.2\\nCo-occurrence vectors for four words with counts from the 4 windows above,\\nshowing just 3 of the potential context word dimensions. The vector for cherry is outlined in\\nred. Note that a real vector would have vastly more dimensions and thus be even sparser.\\nHopefully your count matches what is shown in Fig. 5.2, so that each cell repre-\\nsents the number of times a particular word (deÔ¨Åned by the row) occurs in a partic-\\nular context (deÔ¨Åned by the word column).\\nEach row, then, is a vector representing a word. To review some basic linear\\nalgebra, a vector is, at heart, just a list or array of numbers. So cherry is represented\\nvector\\nas the list [1,0,1] (the Ô¨Årst row vector in Fig. 5.2) and information is represented as\\nthe list [1,1,0] (the fourth row vector).\\nA vector space is a collection of vectors, and is characterized by its dimension.\\nvector space\\ndimension\\nVectors in a 3-dimensional vector space have an element for each dimension of the'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 6}, page_content='A vector space is a collection of vectors, and is characterized by its dimension.\\nvector space\\ndimension\\nVectors in a 3-dimensional vector space have an element for each dimension of the\\nspace. We will loosely refer to a vector in a 3-dimensional space as a 3-dimensional\\nvector, with one element along each dimension. In the example in Fig. 5.2, we‚Äôve\\nchosen to make the document vectors of dimension 3, just so they Ô¨Åt on the page; in\\nreal term-document matrices, the document vectors would have dimensionality |V|,\\nthe vocabulary size.\\nThe ordering of the numbers in a vector space indicates the different dimensions\\non which documents vary. The third dimension for all these vectors corresponds\\nto the number of times pie occurs in the context. The second dimension for all of\\nthem corresponds to the number of times the word computer occurs. Notice that\\nthe vectors for information and digital have the same value (1) for this ‚Äúcomputer‚Äù\\ndimension.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 6}, page_content='them corresponds to the number of times the word computer occurs. Notice that\\nthe vectors for information and digital have the same value (1) for this ‚Äúcomputer‚Äù\\ndimension.\\nIn reality, we don‚Äôt compute word vectors on a single context window. Instead,\\nwe compute them over an entire corpus. Let‚Äôs see what some real counts look like.\\nLet‚Äôs look at some vectors computed in this way. Fig. 5.3 shows a subset of the\\nword-word co-occurrence matrix for these four words, where, again because it‚Äôs\\nimpossible to visualize all |V| possible context words on the page of this textbook,\\nwe show a subset of 6 of the dimensions, with counts computed from the Wikipedia\\ncorpus (Davies, 2015).\\nNote in Fig. 5.3 that the two words cherry and strawberry are more similar to\\neach other (both pie and sugar tend to occur in their window) than they are to other\\nwords like digital; conversely, digital and information are more similar to each other\\nthan, say, to strawberry.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 6}, page_content='each other (both pie and sugar tend to occur in their window) than they are to other\\nwords like digital; conversely, digital and information are more similar to each other\\nthan, say, to strawberry.\\nWe can think of the vector for a document as a point in |V|-dimensional space;\\nthus the documents in Fig. 5.3 are points in 3-dimensional space. Fig. 5.4 shows a\\nspatial visualization.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 7}, page_content='8\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\naardvark\\n...\\ncomputer\\ndata\\nresult\\npie\\nsugar\\n...\\ncherry\\n0\\n...\\n2\\n8\\n9\\n442\\n25\\n...\\nstrawberry\\n0\\n...\\n0\\n0\\n1\\n60\\n19\\n...\\ndigital\\n0\\n...\\n1670\\n1683\\n85\\n5\\n4\\n...\\ninformation\\n0\\n...\\n3325\\n3982\\n378\\n5\\n13\\n...\\nFigure 5.3\\nCo-occurrence vectors for four words in the Wikipedia corpus, showing six of\\nthe dimensions (hand-picked for pedagogical purposes). The vector for digital is outlined in\\nred. Note that a real vector would have vastly more dimensions and thus be much sparser, i.e.\\nwould have zero values in most dimensions.\\n1000 2000 3000 4000\\n1000\\n2000\\ndigital\\n [1683,1670]\\ncomputer\\n data\\ninformation\\n [3982,3325] \\n3000\\n4000\\nFigure 5.4\\nA spatial visualization of word vectors for digital and information, showing just\\ntwo of the dimensions, corresponding to the words data and computer.\\nNote that |V|, the dimensionality of the vector, is generally the size of the vo-\\ncabulary, often between 10,000 and 50,000 words (using the most frequent words'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 7}, page_content='Note that |V|, the dimensionality of the vector, is generally the size of the vo-\\ncabulary, often between 10,000 and 50,000 words (using the most frequent words\\nin the training corpus; keeping words after about the most frequent 50,000 or so is\\ngenerally not helpful). Since most of these numbers are zero these are sparse vector\\nrepresentations; there are efÔ¨Åcient algorithms for storing and computing with sparse\\nmatrices.\\nIt‚Äôs also possible to applying various kinds of weighting functions to the counts\\nin these cells. The most popular such weighting is tf-idf, which we‚Äôll introduce in\\nChapter 11, but there have historically been a wide variety of other weightings.\\nNow that we have some intuitions, let‚Äôs move on to examine the details of com-\\nputing word similarity.\\n5.4\\nCosine for measuring similarity\\nTo measure similarity between two target words v and w, we need a metric that\\ntakes two vectors (of the same dimensionality, either both with words as dimensions,'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 7}, page_content='5.4\\nCosine for measuring similarity\\nTo measure similarity between two target words v and w, we need a metric that\\ntakes two vectors (of the same dimensionality, either both with words as dimensions,\\nhence of length |V|, or both with documents as dimensions, of length |D|) and gives\\na measure of their similarity. By far the most common similarity metric is the cosine\\nof the angle between the vectors.\\nThe cosine‚Äîlike most measures for vector similarity used in NLP‚Äîis based on\\nthe dot product operator from linear algebra, also called the inner product:\\ndot product\\ninner product\\ndot product(v,w) = v ¬∑w =\\nN\\nX\\ni=1\\nviwi = v1w1 +v2w2 +...+vNwN\\n(5.7)\\nThe dot product acts as a similarity metric because it will tend to be high just when\\nthe two vectors have large values in the same dimensions. Alternatively, vectors that'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 8}, page_content='5.4\\n‚Ä¢\\nCOSINE FOR MEASURING SIMILARITY\\n9\\nhave zeros in different dimensions‚Äîorthogonal vectors‚Äîwill have a dot product of\\n0, representing their strong dissimilarity.\\nThis raw dot product, however, has a problem as a similarity metric: it favors\\nlong vectors. The vector length is deÔ¨Åned as\\nvector length\\n|v| =\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nv2\\ni\\n(5.8)\\nThe dot product is higher if a vector is longer, with higher values in each dimension.\\nMore frequent words have longer vectors, since they tend to co-occur with more\\nwords and have higher co-occurrence values with each of them. The raw dot product\\nthus will be higher for frequent words. But this is a problem; we‚Äôd like a similarity\\nmetric that tells us how similar two words are regardless of their frequency.\\nWe modify the dot product to normalize for the vector length by dividing the\\ndot product by the lengths of each of the two vectors. This normalized dot product\\nturns out to be the same as the cosine of the angle between the two vectors, following'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 8}, page_content='dot product by the lengths of each of the two vectors. This normalized dot product\\nturns out to be the same as the cosine of the angle between the two vectors, following\\nfrom the deÔ¨Ånition of the dot product between two vectors a and b:\\na¬∑b = |a||b|cosŒ∏\\na¬∑b\\n|a||b| = cosŒ∏\\n(5.9)\\nThe cosine similarity metric between two vectors v and w thus can be computed as:\\ncosine\\ncosine(v,w) = v ¬∑w\\n|v||w| =\\nN\\nX\\ni=1\\nviwi\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nv2\\ni\\nv\\nu\\nu\\nt\\nN\\nX\\ni=1\\nw2\\ni\\n(5.10)\\nFor some applications we pre-normalize each vector, by dividing it by its length,\\ncreating a unit vector of length 1. Thus we could compute a unit vector from a by\\nunit vector\\ndividing it by |a|. For unit vectors, the dot product is the same as the cosine.\\nThe cosine value ranges from 1 for vectors pointing in the same direction, through\\n0 for orthogonal vectors, to -1 for vectors pointing in opposite directions. But since\\nraw frequency values are non-negative, the cosine for these vectors ranges from 0‚Äì1.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 8}, page_content='0 for orthogonal vectors, to -1 for vectors pointing in opposite directions. But since\\nraw frequency values are non-negative, the cosine for these vectors ranges from 0‚Äì1.\\nLet‚Äôs see how the cosine computes which of the words cherry or digital is closer\\nin meaning to information, just using raw counts from the following shortened table:\\npie\\ndata computer\\ncherry\\n442\\n8\\n2\\ndigital\\n5\\n1683\\n1670\\ninformation\\n5\\n3982\\n3325\\ncos(cherry,information) =\\n442‚àó5+8‚àó3982+2‚àó3325\\n‚àö\\n4422 +82 +22‚àö\\n52 +39822 +33252 = .018\\ncos(digital,information) =\\n5‚àó5+1683‚àó3982+1670‚àó3325\\n‚àö\\n52 +16832 +16702‚àö\\n52 +39822 +33252 = .996\\nThe model decides that information is way closer to digital than it is to cherry, a\\nresult that seems sensible. Fig. 5.5 shows a visualization.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 9}, page_content='10\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n500\\n1000\\n1500\\n2000\\n2500\\n3000\\n500\\ndigital\\ncherry\\ninformation\\nDimension 1: ‚Äòpie‚Äô\\nDimension 2: ‚Äòcomputer‚Äô\\nFigure 5.5\\nA (rough) graphical demonstration of cosine similarity, showing vectors for\\nthree words (cherry, digital, and information) in the two dimensional space deÔ¨Åned by counts\\nof the words computer and pie nearby. The Ô¨Ågure doesn‚Äôt show the cosine, but it highlights the\\nangles; note that the angle between digital and information is smaller than the angle between\\ncherry and information. When two vectors are more similar, the cosine is larger but the angle\\nis smaller; the cosine has its maximum (1) when the angle between two vectors is smallest\\n(0‚ó¶); the cosine of all other angles is less than 1.\\ncan be used to compute word similarity, for tasks like Ô¨Ånding word paraphrases,\\ntracking changes in word meaning, or automatically discovering meanings of words\\nin different corpora. For example, we can Ô¨Ånd the 10 most similar words to any'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 9}, page_content='tracking changes in word meaning, or automatically discovering meanings of words\\nin different corpora. For example, we can Ô¨Ånd the 10 most similar words to any\\ntarget word w by computing the cosines between w and each of the |V| ‚àí1 other\\nwords, sorting, and looking at the top 10.\\n5.5\\nWord2vec\\nIn the previous sections we saw how to represent a word as a sparse, long vector with\\ndimensions corresponding to words in the vocabulary. We now introduce a more\\npowerful word representation: embeddings, short dense vectors. Unlike the vectors\\nwe‚Äôve seen so far, embeddings are short, with number of dimensions d ranging from\\n50-1000, rather than the much larger vocabulary size |V|.These d dimensions don‚Äôt\\nhave a clear interpretation. And the vectors are dense: instead of vector entries\\nbeing sparse, mostly-zero counts or functions of counts, the values will be real-\\nvalued numbers that can be negative.\\nIt turns out that dense vectors work better in every NLP task than sparse vectors.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 9}, page_content='valued numbers that can be negative.\\nIt turns out that dense vectors work better in every NLP task than sparse vectors.\\nWhile we don‚Äôt completely understand all the reasons for this, we have some intu-\\nitions. Representing words as 300-dimensional dense vectors requires our classiÔ¨Åers\\nto learn far fewer weights than if we represented words as 50,000-dimensional vec-\\ntors, and the smaller parameter space possibly helps with generalization and avoid-\\ning overÔ¨Åtting. Dense vectors may also do a better job of capturing synonymy.\\nFor example, in a sparse vector representation, dimensions for synonyms like car\\nand automobile dimension are distinct and unrelated; sparse vectors may thus fail\\nto capture the similarity between a word with car as a neighbor and a word with\\nautomobile as a neighbor.\\nIn this section we introduce one method for computing embeddings: skip-gram\\nskip-gram\\nwith negative sampling, sometimes called SGNS. The skip-gram algorithm is one\\nSGNS'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 9}, page_content='automobile as a neighbor.\\nIn this section we introduce one method for computing embeddings: skip-gram\\nskip-gram\\nwith negative sampling, sometimes called SGNS. The skip-gram algorithm is one\\nSGNS\\nof two algorithms in a software package called word2vec, and so sometimes the\\nword2vec\\nalgorithm is loosely referred to as word2vec (Mikolov et al. 2013a, Mikolov et al.\\n2013b). The word2vec methods are fast, efÔ¨Åcient to train, and easily available on-\\nline with code and pretrained embeddings. Word2vec embeddings are static em-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 10}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n11\\nbeddings, meaning that the method learns one Ô¨Åxed embedding for each word in the\\nstatic\\nembeddings\\nvocabulary. In Chapter 10 we‚Äôll introduce methods for learning dynamic contextual\\nembeddings like the popular family of BERT representations, in which the vector\\nfor each word is different in different contexts.\\nThe intuition of word2vec is that instead of counting how often each word w oc-\\ncurs near, say, apricot, we‚Äôll instead train a classiÔ¨Åer on a binary prediction task: ‚ÄúIs\\nword w likely to show up near apricot?‚Äù We don‚Äôt actually care about this prediction\\ntask; instead we‚Äôll take the learned classiÔ¨Åer weights as the word embeddings.\\nThe revolutionary intuition here is that we can just use running text as implicitly\\nsupervised training data for such a classiÔ¨Åer; a word c that occurs near the target\\nword apricot acts as gold ‚Äòcorrect answer‚Äô to the question ‚ÄúIs word c likely to show\\nup near apricot?‚Äù This method, often called self-supervision, avoids the need for'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 10}, page_content='word apricot acts as gold ‚Äòcorrect answer‚Äô to the question ‚ÄúIs word c likely to show\\nup near apricot?‚Äù This method, often called self-supervision, avoids the need for\\nself-supervision\\nany sort of hand-labeled supervision signal. This idea was Ô¨Årst proposed in the task\\nof neural language modeling, when Bengio et al. (2003) and Collobert et al. (2011)\\nshowed that a neural language model (a neural network that learned to predict the\\nnext word from prior words) could just use the next word in running text as its\\nsupervision signal, and could be used to learn an embedding representation for each\\nword as part of doing this prediction task.\\nWe‚Äôll see how to do neural networks in the next chapter, but word2vec is a\\nmuch simpler model than the neural network language model, in two ways. First,\\nword2vec simpliÔ¨Åes the task (making it binary classiÔ¨Åcation instead of word pre-\\ndiction). Second, word2vec simpliÔ¨Åes the architecture (training a logistic regression'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 10}, page_content='word2vec simpliÔ¨Åes the task (making it binary classiÔ¨Åcation instead of word pre-\\ndiction). Second, word2vec simpliÔ¨Åes the architecture (training a logistic regression\\nclassiÔ¨Åer instead of a multi-layer neural network with hidden layers that demand\\nmore sophisticated training algorithms). The intuition of skip-gram is:\\n1. Treat the target word and a neighboring context word as positive examples.\\n2. Randomly sample other words in the lexicon to get negative samples.\\n3. Use logistic regression to train a classiÔ¨Åer to distinguish those two cases.\\n4. Use the learned weights as the embeddings.\\n5.5.1\\nThe classiÔ¨Åer\\nLet‚Äôs start by thinking about the classiÔ¨Åcation task, and then turn to how to train.\\nImagine a sentence like the following, with a target word apricot, and assume we‚Äôre\\nusing a window of ¬±2 context words:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nOur goal is to train a classiÔ¨Åer such that, given a tuple (w,c) of a target word'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 10}, page_content='using a window of ¬±2 context words:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nOur goal is to train a classiÔ¨Åer such that, given a tuple (w,c) of a target word\\nw paired with a candidate context word c (for example (apricot, jam), or perhaps\\n(apricot, aardvark)) it will return the probability that c is a real context word (true\\nfor jam, false for aardvark):\\nP(+|w,c)\\n(5.11)\\nThe probability that word c is not a real context word for w is just 1 minus\\nEq. 5.11:\\nP(‚àí|w,c) = 1‚àíP(+|w,c)\\n(5.12)\\nHow does the classiÔ¨Åer compute the probability P? The intuition of the skip-\\ngram model is to base this probability on embedding similarity: a word is likely to'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 11}, page_content='12\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\noccur near the target if its embedding vector is similar to the target embedding. To\\ncompute similarity between these dense embeddings, we rely on the intuition that\\ntwo vectors are similar if they have a high dot product (after all, cosine is just a\\nnormalized dot product). In other words:\\nSimilarity(w,c) ‚âàc¬∑w\\n(5.13)\\nThe dot product c ¬∑ w is not a probability, it‚Äôs just a number ranging from ‚àí‚àûto ‚àû\\n(since the elements in word2vec embeddings can be negative, the dot product can be\\nnegative). To turn the dot product into a probability, we‚Äôll use the logistic or sigmoid\\nfunction œÉ(x), the fundamental core of logistic regression:\\nœÉ(x) =\\n1\\n1+exp(‚àíx)\\n(5.14)\\nWe model the probability that word c is a real context word for target word w as:\\nP(+|w,c) = œÉ(c¬∑w) =\\n1\\n1+exp(‚àíc¬∑w)\\n(5.15)\\nThe sigmoid function returns a number between 0 and 1, but to make it a probability\\nwe‚Äôll also need the total probability of the two possible events (c is a context word,'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 11}, page_content='1\\n1+exp(‚àíc¬∑w)\\n(5.15)\\nThe sigmoid function returns a number between 0 and 1, but to make it a probability\\nwe‚Äôll also need the total probability of the two possible events (c is a context word,\\nand c isn‚Äôt a context word) to sum to 1. We thus estimate the probability that word c\\nis not a real context word for w as:\\nP(‚àí|w,c) = 1‚àíP(+|w,c)\\n= œÉ(‚àíc¬∑w) =\\n1\\n1+exp(c¬∑w)\\n(5.16)\\nEquation 5.15 gives us the probability for one word, but there are many context\\nwords in the window. Skip-gram makes the simplifying assumption that all context\\nwords are independent, allowing us to just multiply their probabilities:\\nP(+|w,c1:L) =\\nL\\nY\\ni=1\\nœÉ(ci ¬∑w)\\n(5.17)\\nlogP(+|w,c1:L) =\\nL\\nX\\ni=1\\nlogœÉ(ci ¬∑w)\\n(5.18)\\nIn summary, skip-gram trains a probabilistic classiÔ¨Åer that, given a test target word\\nw and its context window of L words c1:L, assigns a probability based on how similar\\nthis context window is to the target word. The probability is based on applying the'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 11}, page_content='w and its context window of L words c1:L, assigns a probability based on how similar\\nthis context window is to the target word. The probability is based on applying the\\nlogistic (sigmoid) function to the dot product of the embeddings of the target word\\nwith each context word. To compute this probability, we just need embeddings for\\neach target word and context word in the vocabulary.\\nFig. 5.6 shows the intuition of the parameters we‚Äôll need. Skip-gram actually\\nstores two embeddings for each word, one for the word as a target, and one for the\\nword considered as context. Thus the parameters we need to learn are two matrices\\nW and C, each containing an embedding for every one of the |V| words in the\\nvocabulary V.2 Let‚Äôs now turn to learning these embeddings (which is the real goal\\nof training this classiÔ¨Åer in the Ô¨Årst place).\\n2\\nIn principle the target matrix and the context matrix could use different vocabularies, but we‚Äôll simplify\\nby assuming one shared vocabulary V.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 12}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n13\\n1\\nW\\nC\\naardvark\\nzebra\\nzebra\\naardvark\\napricot\\napricot\\n|V|\\n|V|+1\\n2|V|\\nùúΩ =\\ntarget words\\ncontext & noise\\nwords\\n‚Ä¶\\n‚Ä¶\\n1..d\\n‚Ä¶\\n‚Ä¶\\nFigure 5.6\\nThe embeddings learned by the skipgram model. The algorithm stores two em-\\nbeddings for each word, the target embedding (sometimes called the input embedding) and\\nthe context embedding (sometimes called the output embedding). The parameter Œ∏ that the al-\\ngorithm learns is thus a matrix of 2|V| vectors, each of dimension d, formed by concatenating\\ntwo matrices, the target embeddings W and the context+noise embeddings C.\\n5.5.2\\nLearning skip-gram embeddings\\nThe learning algorithm for skip-gram embeddings takes as input a corpus of text,\\nand a chosen vocabulary size N. It begins by assigning a random embedding vector\\nfor each of the N vocabulary words, and then proceeds to iteratively shift the em-\\nbedding of each word w to be more like the embeddings of words that occur nearby'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 12}, page_content='for each of the N vocabulary words, and then proceeds to iteratively shift the em-\\nbedding of each word w to be more like the embeddings of words that occur nearby\\nin texts, and less like the embeddings of words that don‚Äôt occur nearby. Let‚Äôs start\\nby considering a single piece of training data:\\n... lemon,\\na [tablespoon of apricot jam,\\na] pinch ...\\nc1\\nc2\\nw\\nc3\\nc4\\nThis example has a target word w (apricot), and 4 context words in the L = ¬±2\\nwindow, resulting in 4 positive training instances (on the left below):\\npositive examples +\\nw\\ncpos\\napricot tablespoon\\napricot of\\napricot jam\\napricot a\\nnegative examples -\\nw\\ncneg\\nw\\ncneg\\napricot aardvark apricot seven\\napricot my\\napricot forever\\napricot where\\napricot dear\\napricot coaxial\\napricot if\\nFor training a binary classiÔ¨Åer we also need negative examples. In fact skip-\\ngram with negative sampling (SGNS) uses more negative examples than positive\\nexamples (with the ratio between them set by a parameter k). So for each of these'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 12}, page_content='gram with negative sampling (SGNS) uses more negative examples than positive\\nexamples (with the ratio between them set by a parameter k). So for each of these\\n(w,cpos) training instances we‚Äôll create k negative samples, each consisting of the\\ntarget w plus a ‚Äònoise word‚Äô cneg. A noise word is a random word from the lexicon,\\nconstrained not to be the target word w. The table right above shows the setting\\nwhere k = 2, so we‚Äôll have 2 negative examples in the negative training set ‚àífor\\neach positive example w,cpos.\\nThe noise words are chosen according to their weighted unigram probability\\npŒ±(w), where Œ± is a weight. If we were sampling according to unweighted proba-\\nbility P(w), it would mean that with unigram probability P(‚Äúthe‚Äù) we would choose\\nthe word the as a noise word, with unigram probability P(‚Äúaardvark‚Äù) we would\\nchoose aardvark, and so on. But in practice it is common to set Œ± = 0.75, i.e. use'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 13}, page_content='14\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nthe weighting P3\\n4 (w):\\nPŒ±(w) =\\ncount(w)Œ±\\nP\\nw‚Ä≤ count(w‚Ä≤)Œ±\\n(5.19)\\nSetting Œ± = .75 gives better performance because it gives rare noise words slightly\\nhigher probability: for rare words, PŒ±(w) > P(w). To illustrate this intuition, it\\nmight help to work out the probabilities for an example with Œ± = .75 and two events,\\nP(a) = 0.99 and P(b) = 0.01:\\nPŒ±(a) =\\n.99.75\\n.99.75 +.01.75 = 0.97\\nPŒ±(b) =\\n.01.75\\n.99.75 +.01.75 = 0.03\\n(5.20)\\nThus using Œ± = .75 increases the probability of the rare event b from 0.01 to 0.03.\\nGiven the set of positive and negative training instances, and an initial set of\\nembeddings, the goal of the learning algorithm is to adjust those embeddings to\\n‚Ä¢ Maximize the similarity of the target word, context word pairs (w,cpos) drawn\\nfrom the positive examples\\n‚Ä¢ Minimize the similarity of the (w,cneg) pairs from the negative examples.\\nIf we consider one word/context pair (w,cpos) with its k noise words cneg1...cnegk,'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 13}, page_content='from the positive examples\\n‚Ä¢ Minimize the similarity of the (w,cneg) pairs from the negative examples.\\nIf we consider one word/context pair (w,cpos) with its k noise words cneg1...cnegk,\\nwe can express these two goals as the following loss function L to be minimized\\n(hence the ‚àí); here the Ô¨Årst term expresses that we want the classiÔ¨Åer to assign the\\nreal context word cpos a high probability of being a neighbor, and the second term\\nexpresses that we want to assign each of the noise words cnegi a high probability of\\nbeing a non-neighbor, all multiplied because we assume independence:\\nL = ‚àílog\\n\"\\nP(+|w,cpos)\\nkY\\ni=1\\nP(‚àí|w,cnegi)\\n#\\n= ‚àí\\n\"\\nlogP(+|w,cpos)+\\nk\\nX\\ni=1\\nlogP(‚àí|w,cnegi)\\n#\\n= ‚àí\\n\"\\nlogP(+|w,cpos)+\\nk\\nX\\ni=1\\nlog\\n\\x001‚àíP(+|w,cnegi)\\n\\x01\\n#\\n= ‚àí\\n\"\\nlogœÉ(cpos ¬∑w)+\\nk\\nX\\ni=1\\nlogœÉ(‚àícnegi ¬∑w)\\n#\\n(5.21)\\nThat is, we want to maximize the dot product of the word with the actual context\\nwords, and minimize the dot products of the word with the k negative sampled non-\\nneighbor words.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 13}, page_content='#\\n(5.21)\\nThat is, we want to maximize the dot product of the word with the actual context\\nwords, and minimize the dot products of the word with the k negative sampled non-\\nneighbor words.\\nWe minimize this loss function using stochastic gradient descent. Fig. 5.7 shows\\nthe intuition of one step of learning.\\nTo get the gradient, we need to take the derivative of Eq. 5.21 with respect to\\nthe different embeddings. It turns out the derivatives are the following (we leave the'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 14}, page_content='5.5\\n‚Ä¢\\nWORD2VEC\\n15\\nW\\nC\\nmove apricot and jam closer,\\nincreasing cpos z w\\naardvark\\nmove apricot and matrix apart\\ndecreasing cneg1 z w\\n‚Äú‚Ä¶apricot jam‚Ä¶‚Äù\\nw\\nzebra\\nzebra\\naardvark\\njam\\napricot\\ncpos\\nmatrix\\nTolstoy\\nmove apricot and Tolstoy apart\\ndecreasing cneg2 z w\\n!\\ncneg1\\ncneg2\\nk=2\\nFigure 5.7\\nIntuition of one step of gradient descent. The skip-gram model tries to shift em-\\nbeddings so the target embeddings (here for apricot) are closer to (have a higher dot product\\nwith) context embeddings for nearby words (here jam) and further from (lower dot product\\nwith) context embeddings for noise words that don‚Äôt occur nearby (here Tolstoy and matrix).\\nproof as an exercise at the end of the chapter):\\n‚àÇL\\n‚àÇcpos\\n= [œÉ(cpos ¬∑w)‚àí1]w\\n(5.22)\\n‚àÇL\\n‚àÇcneg\\n= [œÉ(cneg ¬∑w)]w\\n(5.23)\\n‚àÇL\\n‚àÇw = [œÉ(cpos ¬∑w)‚àí1]cpos +\\nk\\nX\\ni=1\\n[œÉ(cnegi ¬∑w)]cnegi\\n(5.24)\\nThe update equations going from time step t to t + 1 in stochastic gradient descent\\nare thus:\\nct+1\\npos\\n= ct\\npos ‚àíŒ∑[œÉ(ct\\npos ¬∑wt)‚àí1]wt\\n(5.25)\\nct+1\\nneg = ct\\nneg ‚àíŒ∑[œÉ(ct\\nneg ¬∑wt)]wt'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 14}, page_content='(5.24)\\nThe update equations going from time step t to t + 1 in stochastic gradient descent\\nare thus:\\nct+1\\npos\\n= ct\\npos ‚àíŒ∑[œÉ(ct\\npos ¬∑wt)‚àí1]wt\\n(5.25)\\nct+1\\nneg = ct\\nneg ‚àíŒ∑[œÉ(ct\\nneg ¬∑wt)]wt\\n(5.26)\\nwt+1 = wt ‚àíŒ∑\\n\"\\n[œÉ(ct\\npos ¬∑wt)‚àí1]ct\\npos +\\nk\\nX\\ni=1\\n[œÉ(ct\\nnegi ¬∑wt)]ct\\nnegi\\n#\\n(5.27)\\nJust as in logistic regression, then, the learning algorithm starts with randomly ini-\\ntialized W and C matrices, and then walks through the training corpus using gradient\\ndescent to move W and C so as to minimize the loss in Eq. 5.21 by making the up-\\ndates in (Eq. 5.25)-(Eq. 5.27).\\nRecall that the skip-gram model learns two separate embeddings for each word i:\\nthe target embedding wi and the context embedding ci, stored in two matrices, the\\ntarget\\nembedding\\ncontext\\nembedding\\ntarget matrix W and the context matrix C. It‚Äôs common to just add them together,\\nrepresenting word i with the vector wi +ci. Alternatively we can throw away the C\\nmatrix and just represent each word i by the vector wi.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 14}, page_content='representing word i with the vector wi +ci. Alternatively we can throw away the C\\nmatrix and just represent each word i by the vector wi.\\nAs with the simple count-based methods like tf-idf, the context window size L\\naffects the performance of skip-gram embeddings, and experiments often tune the\\nparameter L on a devset.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 15}, page_content='16\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n5.5.3\\nOther kinds of static embeddings\\nThere are many kinds of static embeddings. An extension of word2vec, fasttext\\nfasttext\\n(Bojanowski et al., 2017), addresses a problem with word2vec as we have presented\\nit so far: it has no good way to deal with unknown words‚Äîwords that appear in\\na test corpus but were unseen in the training corpus. A related problem is word\\nsparsity, such as in languages with rich morphology, where some of the many forms\\nfor each noun and verb may only occur rarely. Fasttext deals with these problems\\nby using subword models, representing each word as itself plus a bag of constituent\\nn-grams, with special boundary symbols < and > added to each word. For example,\\nwith n = 3 the word where would be represented by the sequence <where> plus the\\ncharacter n-grams:\\n<wh, whe, her, ere, re>\\nThen a skipgram embedding is learned for each constituent n-gram, and the word'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 15}, page_content='character n-grams:\\n<wh, whe, her, ere, re>\\nThen a skipgram embedding is learned for each constituent n-gram, and the word\\nwhere is represented by the sum of all of the embeddings of its constituent n-grams.\\nUnknown words can then be presented only by the sum of the constituent n-grams.\\nA fasttext open-source library, including pretrained embeddings for 157 languages,\\nis available at https://fasttext.cc.\\nAnother very widely used static embedding model is GloVe (Pennington et al.,\\n2014), short for Global Vectors, because the model is based on capturing global\\ncorpus statistics. GloVe is based on ratios of probabilities from the word-word co-\\noccurrence matrix.\\nIt turns out that dense embeddings like word2vec actually have an elegant math-\\nematical relationship with count-based embeddings, in which word2vec can be seen\\nas implicitly optimizing a function of a count matrix with a particular (PPMI) weight-\\ning (Levy and Goldberg, 2014c).\\n5.6\\nVisualizing Embeddings'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 15}, page_content='as implicitly optimizing a function of a count matrix with a particular (PPMI) weight-\\ning (Levy and Goldberg, 2014c).\\n5.6\\nVisualizing Embeddings\\n‚ÄúI see well in many dimensions as long as the dimensions are around two.‚Äù\\nThe late economist Martin Shubik\\nVisualizing embeddings is an important goal in helping understand, apply, and\\nimprove these models of word meaning. But how can we visualize a (for example)\\n100-dimensional vector?\\nWRIST\\nANKLE\\nSHOULDER\\nARM\\nLEG\\nHAND\\nFOOT\\nHEAD\\nNOSE\\nFINGER\\nTOE\\nFACE\\nEAR\\nEYE\\nTOOTH\\nDOG\\nCAT\\nPUPPY\\nKITTEN\\nCOW\\nMOUSE\\nTURTLE\\nOYSTER\\nLION\\nBULL\\nCHICAGO\\nATLANTA\\nMONTREAL\\nNASHVILLE\\nTOKYO\\nCHINA\\nRUSSIA\\nAFRICA\\nASIA\\nEUROPE\\nAMERICA\\nBRAZIL\\nMOSCOW\\nFRANCE\\nHAWAII\\nThe simplest way to visualize the meaning of a word\\nw embedded in a space is to list the most similar words to\\nw by sorting the vectors for all words in the vocabulary by\\ntheir cosine with the vector for w. For example the 7 closest\\nwords to frog using a particular embeddings computed with'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 15}, page_content='w by sorting the vectors for all words in the vocabulary by\\ntheir cosine with the vector for w. For example the 7 closest\\nwords to frog using a particular embeddings computed with\\nthe GloVe algorithm are: frogs, toad, litoria, leptodactyli-\\ndae, rana, lizard, and eleutherodactylus (Pennington et al.,\\n2014).\\nYet another visualization method is to use a clustering\\nalgorithm to show a hierarchical representation of which\\nwords are similar to others in the embedding space. The\\nuncaptioned Ô¨Ågure on the left uses hierarchical clustering\\nof some embedding vectors for nouns as a visualization\\nmethod (Rohde et al., 2006).'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 16}, page_content='5.7\\n‚Ä¢\\nSEMANTIC PROPERTIES OF EMBEDDINGS\\n17\\nProbably the most common visualization method, how-\\never, is to project the 100 dimensions of a word down into 2\\ndimensions. Fig. 5.1 showed one such visualization, as does\\nFig. 5.9, using a projection method called t-SNE (van der\\nMaaten and Hinton, 2008).\\n5.7\\nSemantic properties of embeddings\\nIn this section we brieÔ¨Çy summarize some of the semantic properties of embeddings\\nthat have been studied.\\nDifferent types of similarity or association:\\nOne parameter of vector semantic\\nmodels that is relevant to both sparse PPMI vectors and dense word2vec vectors is\\nthe size of the context window used to collect counts. This is generally between 1\\nand 10 words on each side of the target word (for a total context of 2-20 words).\\nThe choice depends on the goals of the representation. Shorter context windows\\ntend to lead to representations that are a bit more syntactic, since the information is'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 16}, page_content='The choice depends on the goals of the representation. Shorter context windows\\ntend to lead to representations that are a bit more syntactic, since the information is\\ncoming from immediately nearby words. When the vectors are computed from short\\ncontext windows, the most similar words to a target word w tend to be semantically\\nsimilar words with the same parts of speech. When vectors are computed from long\\ncontext windows, the highest cosine words to a target word w tend to be words that\\nare topically related but not similar.\\nFor example Levy and Goldberg (2014a) showed that using skip-gram with a\\nwindow of ¬±2, the most similar words to the word Hogwarts (from the Harry Potter\\nseries) were names of other Ô¨Åctional schools: Sunnydale (from Buffy the Vampire\\nSlayer) or Evernight (from a vampire series). With a window of ¬±5, the most similar\\nwords to Hogwarts were other words topically related to the Harry Potter series:\\nDumbledore, Malfoy, and half-blood.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 16}, page_content='words to Hogwarts were other words topically related to the Harry Potter series:\\nDumbledore, Malfoy, and half-blood.\\nIt‚Äôs also often useful to distinguish two kinds of similarity or association between\\nwords (Sch¬®utze and Pedersen, 1993). Two words have Ô¨Årst-order co-occurrence\\nÔ¨Årst-order\\nco-occurrence\\n(sometimes called syntagmatic association) if they are typically nearby each other.\\nThus wrote is a Ô¨Årst-order associate of book or poem. Two words have second-order\\nco-occurrence (sometimes called paradigmatic association) if they have similar\\nsecond-order\\nco-occurrence\\nneighbors. Thus wrote is a second-order associate of words like said or remarked.\\nAnalogy/Relational Similarity:\\nAnother semantic property of embeddings is their\\nability to capture relational meanings. In an important early vector space model of\\ncognition, Rumelhart and Abrahamson (1973) proposed the parallelogram model\\nparallelogram\\nmodel'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 16}, page_content='ability to capture relational meanings. In an important early vector space model of\\ncognition, Rumelhart and Abrahamson (1973) proposed the parallelogram model\\nparallelogram\\nmodel\\nfor solving simple analogy problems of the form a is to b as a* is to what?. In such\\nproblems, a system is given a problem like apple:tree::grape:?, i.e., apple is to tree\\nas grape is to\\n, and must Ô¨Åll in the word vine. In the parallelogram model, il-\\nlustrated in Fig. 5.8, the vector from the word apple to the word tree (= #   ¬ª\\ntree‚àí#       ¬ª\\napple)\\nis added to the vector for grape (#        ¬ª\\ngrape); the nearest word to that point is returned.\\nIn early work with sparse embeddings, scholars showed that sparse vector mod-\\nels of meaning could solve such analogy problems (Turney and Littman, 2005),\\nbut the parallelogram method received more modern attention because of its suc-\\ncess with word2vec or GloVe vectors (Mikolov et al. 2013c, Levy and Goldberg'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 16}, page_content='but the parallelogram method received more modern attention because of its suc-\\ncess with word2vec or GloVe vectors (Mikolov et al. 2013c, Levy and Goldberg\\n2014b, Pennington et al. 2014). For example, the result of the expression #     ¬ª\\nking ‚àí\\n#     ¬ª\\nman + #            ¬ª\\nwoman is a vector close to #         ¬ª\\nqueen. Similarly, #      ¬ª\\nParis ‚àí#           ¬ª\\nFrance + #     ¬ª\\nItaly results\\nin a vector that is close to #         ¬ª\\nRome. The embedding model thus seems to be extract-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 17}, page_content='18\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\ntree\\napple\\ngrape\\nvine\\nFigure 5.8\\nThe parallelogram model for analogy problems (Rumelhart and Abrahamson,\\n1973): the location of #     ¬ª\\nvine can be found by subtracting #       ¬ª\\napple from #   ¬ª\\ntree and adding #       ¬ª\\ngrape.\\ning representations of relations like MALE-FEMALE, or CAPITAL-CITY-OF, or even\\nCOMPARATIVE/SUPERLATIVE, as shown in Fig. 5.9 from GloVe.\\n(a)\\n(b)\\nFigure 5.9\\nRelational properties of the GloVe vector space, shown by projecting vectors onto two dimensions.\\n(a) #     ¬ª\\nking‚àí#     ¬ª\\nman+ #            ¬ª\\nwoman is close to #        ¬ª\\nqueen. (b) offsets seem to capture comparative and superlative morphology\\n(Pennington et al., 2014).\\nFor a a : b :: a‚àó: b‚àóproblem, meaning the algorithm is given vectors a, b, and\\na‚àóand must Ô¨Ånd b‚àó, the parallelogram method is thus:\\nÀÜb‚àó= argmin\\nx\\ndistance(x,b‚àía+a‚àó)\\n(5.28)\\nwith some distance function, such as Euclidean distance.\\nThere are some caveats. For example, the closest value returned by the paral-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 17}, page_content='ÀÜb‚àó= argmin\\nx\\ndistance(x,b‚àía+a‚àó)\\n(5.28)\\nwith some distance function, such as Euclidean distance.\\nThere are some caveats. For example, the closest value returned by the paral-\\nlelogram algorithm in word2vec or GloVe embedding spaces is usually not in fact\\nb* but one of the 3 input words or their morphological variants (i.e., cherry:red ::\\npotato:x returns potato or potatoes instead of brown), so these must be explicitly\\nexcluded. Furthermore while embedding spaces perform well if the task involves\\nfrequent words, small distances, and certain relations (like relating countries with\\ntheir capitals or verbs/nouns with their inÔ¨Çected forms), the parallelogram method\\nwith embeddings doesn‚Äôt work as well for other relations (Linzen 2016, Gladkova\\net al. 2016, Schluter 2018, Ethayarajh et al. 2019a), and indeed Peterson et al. (2020)\\nargue that the parallelogram method is in general too simple to model the human\\ncognitive process of forming analogies of this kind.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 18}, page_content='5.8\\n‚Ä¢\\nBIAS AND EMBEDDINGS\\n19\\n5.7.1\\nEmbeddings and Historical Semantics\\nEmbeddings can also be a useful tool for studying how meaning changes over time,\\nby computing multiple embedding spaces, each from texts written in a particular\\ntime period. For example Fig. 5.10 shows a visualization of changes in meaning in\\nEnglish words over the last two centuries, computed by building separate embedding\\nspaces for each decade from historical corpora like Google n-grams (Lin et al., 2012)\\nand the Corpus of Historical American English (Davies, 2012).\\nFigure 5.10\\nA t-SNE visualization of the semantic change of 3 words in English using\\nword2vec vectors. The modern sense of each word, and the grey context words, are com-\\nputed from the most recent (modern) time-point embedding space. Earlier points are com-\\nputed from earlier historical embedding spaces. The visualizations show the changes in the\\nword gay from meanings related to ‚Äúcheerful‚Äù or ‚Äúfrolicsome‚Äù to referring to homosexuality,'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 18}, page_content='puted from earlier historical embedding spaces. The visualizations show the changes in the\\nword gay from meanings related to ‚Äúcheerful‚Äù or ‚Äúfrolicsome‚Äù to referring to homosexuality,\\nthe development of the modern ‚Äútransmission‚Äù sense of broadcast from its original sense of\\nsowing seeds, and the pejoration of the word awful as it shifted from meaning ‚Äúfull of awe‚Äù\\nto meaning ‚Äúterrible or appalling‚Äù (Hamilton et al., 2016).\\n5.8\\nBias and Embeddings\\nIn addition to their ability to learn word meaning from text, embeddings, alas,\\nalso reproduce the implicit biases and stereotypes that were latent in the text. As\\nthe prior section just showed, embeddings can roughly model relational similar-\\nity: ‚Äòqueen‚Äô as the closest word to ‚Äòking‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô implies the analogy\\nman:woman::king:queen. But these same embedding analogies also exhibit gender\\nstereotypes. For example Bolukbasi et al. (2016) Ô¨Ånd that the closest occupation'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 18}, page_content='man:woman::king:queen. But these same embedding analogies also exhibit gender\\nstereotypes. For example Bolukbasi et al. (2016) Ô¨Ånd that the closest occupation\\nto ‚Äòcomputer programmer‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô in word2vec embeddings trained on\\nnews text is ‚Äòhomemaker‚Äô, and that the embeddings similarly suggest the analogy\\n‚Äòfather‚Äô is to ‚Äòdoctor‚Äô as ‚Äòmother‚Äô is to ‚Äònurse‚Äô. This could result in what Crawford\\n(2017) and Blodgett et al. (2020) call an allocational harm, when a system allo-\\nallocational\\nharm\\ncates resources (jobs or credit) unfairly to different groups. For example algorithms\\nthat use embeddings as part of a search for hiring potential programmers or doctors\\nmight thus incorrectly downweight documents with women‚Äôs names.\\nIt turns out that embeddings don‚Äôt just reÔ¨Çect the statistics of their input, but also\\namplify bias; gendered terms become more gendered in embedding space than they\\nbias\\nampliÔ¨Åcation'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 18}, page_content='It turns out that embeddings don‚Äôt just reÔ¨Çect the statistics of their input, but also\\namplify bias; gendered terms become more gendered in embedding space than they\\nbias\\nampliÔ¨Åcation\\nwere in the input text statistics (Zhao et al. 2017, Ethayarajh et al. 2019b, Jia et al.\\n2020), and biases are more exaggerated than in actual labor employment statistics\\n(Garg et al., 2018).\\nEmbeddings also encode the implicit associations that are a property of human\\nreasoning. The Implicit Association Test (Greenwald et al., 1998) measures peo-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 19}, page_content='20\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nple‚Äôs associations between concepts (like ‚ÄòÔ¨Çowers‚Äô or ‚Äòinsects‚Äô) and attributes (like\\n‚Äòpleasantness‚Äô and ‚Äòunpleasantness‚Äô) by measuring differences in the latency with\\nwhich they label words in the various categories.3 Using such methods, people\\nin the United States have been shown to associate African-American names with\\nunpleasant words (more than European-American names), male names more with\\nmathematics and female names with the arts, and old people‚Äôs names with unpleas-\\nant words (Greenwald et al. 1998, Nosek et al. 2002a, Nosek et al. 2002b). Caliskan\\net al. (2017) replicated all these Ô¨Åndings of implicit associations using GloVe vectors\\nand cosine similarity instead of human latencies. For example African-American\\nnames like ‚ÄòLeroy‚Äô and ‚ÄòShaniqua‚Äô had a higher GloVe cosine with unpleasant words\\nwhile European-American names (‚ÄòBrad‚Äô, ‚ÄòGreg‚Äô, ‚ÄòCourtney‚Äô) had a higher cosine\\nwith pleasant words. These problems with embeddings are an example of a repre-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 19}, page_content='while European-American names (‚ÄòBrad‚Äô, ‚ÄòGreg‚Äô, ‚ÄòCourtney‚Äô) had a higher cosine\\nwith pleasant words. These problems with embeddings are an example of a repre-\\nsentational harm (Crawford 2017, Blodgett et al. 2020), which is a harm caused by\\nrepresentational\\nharm\\na system demeaning or even ignoring some social groups. Any embedding-aware al-\\ngorithm that made use of word sentiment could thus exacerbate bias against African\\nAmericans.\\nRecent research focuses on ways to try to remove these kinds of biases, for\\nexample by developing a transformation of the embedding space that removes gen-\\nder stereotypes but preserves deÔ¨Ånitional gender (Bolukbasi et al. 2016, Zhao et al.\\n2017) or changing the training procedure (Zhao et al., 2018). However, although\\nthese sorts of debiasing may reduce bias in embeddings, they do not eliminate it\\ndebiasing\\n(Gonen and Goldberg, 2019), and this remains an open problem.\\nHistorical embeddings are also being used to measure biases in the past. Garg'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 19}, page_content='debiasing\\n(Gonen and Goldberg, 2019), and this remains an open problem.\\nHistorical embeddings are also being used to measure biases in the past. Garg\\net al. (2018) used embeddings from historical texts to measure the association be-\\ntween embeddings for occupations and embeddings for names of various ethnici-\\nties or genders (for example the relative cosine similarity of women‚Äôs names versus\\nmen‚Äôs to occupation words like ‚Äòlibrarian‚Äô or ‚Äòcarpenter‚Äô) across the 20th century.\\nThey found that the cosines correlate with the empirical historical percentages of\\nwomen or ethnic groups in those occupations. Historical embeddings also repli-\\ncated old surveys of ethnic stereotypes; the tendency of experimental participants in\\n1933 to associate adjectives like ‚Äòindustrious‚Äô or ‚Äòsuperstitious‚Äô with, e.g., Chinese\\nethnicity, correlates with the cosine between Chinese last names and those adjectives\\nusing embeddings trained on 1930s text. They also were able to document historical'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 19}, page_content='ethnicity, correlates with the cosine between Chinese last names and those adjectives\\nusing embeddings trained on 1930s text. They also were able to document historical\\ngender biases, such as the fact that embeddings for adjectives related to competence\\n(‚Äòsmart‚Äô, ‚Äòwise‚Äô, ‚Äòthoughtful‚Äô, ‚Äòresourceful‚Äô) had a higher cosine with male than fe-\\nmale words, and showed that this bias has been slowly decreasing since 1960. We\\nreturn in later chapters to this question about the role of bias in natural language\\nprocessing.\\n5.9\\nEvaluating Vector Models\\nThe most important evaluation metric for vector models is extrinsic evaluation on\\ntasks, i.e., using vectors in an NLP task and seeing whether this improves perfor-\\nmance over some other model.\\n3\\nRoughly speaking, if humans associate ‚ÄòÔ¨Çowers‚Äô with ‚Äòpleasantness‚Äô and ‚Äòinsects‚Äô with ‚Äòunpleasant-\\nness‚Äô, when they are instructed to push a green button for ‚ÄòÔ¨Çowers‚Äô (daisy, iris, lilac) and ‚Äòpleasant words‚Äô'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 19}, page_content='ness‚Äô, when they are instructed to push a green button for ‚ÄòÔ¨Çowers‚Äô (daisy, iris, lilac) and ‚Äòpleasant words‚Äô\\n(love, laughter, pleasure) and a red button for ‚Äòinsects‚Äô (Ô¨Çea, spider, mosquito) and ‚Äòunpleasant words‚Äô\\n(abuse, hatred, ugly) they are faster than in an incongruous condition where they push a red button for\\n‚ÄòÔ¨Çowers‚Äô and ‚Äòunpleasant words‚Äô and a green button for ‚Äòinsects‚Äô and ‚Äòpleasant words‚Äô.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 20}, page_content='5.10\\n‚Ä¢\\nSUMMARY\\n21\\nNonetheless it is useful to have intrinsic evaluations. The most common metric\\nis to test their performance on similarity, computing the correlation between an\\nalgorithm‚Äôs word similarity scores and word similarity ratings assigned by humans.\\nWordSim-353 (Finkelstein et al., 2002) is a commonly used set of ratings from 0\\nto 10 for 353 noun pairs; for example (plane, car) had an average score of 5.77.\\nSimLex-999 (Hill et al., 2015) is a more complex dataset that quantiÔ¨Åes similarity\\n(cup, mug) rather than relatedness (cup, coffee), and includes concrete and abstract\\nadjective, noun and verb pairs. The TOEFL dataset is a set of 80 questions, each\\nconsisting of a target word with 4 additional word choices; the task is to choose\\nwhich is the correct synonym, as in the example: Levied is closest in meaning to:\\nimposed, believed, requested, correlated (Landauer and Dumais, 1997). All of these\\ndatasets present words without context.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 20}, page_content='imposed, believed, requested, correlated (Landauer and Dumais, 1997). All of these\\ndatasets present words without context.\\nSlightly more realistic are intrinsic similarity tasks that include context. The\\nStanford Contextual Word Similarity (SCWS) dataset (Huang et al., 2012) and the\\nWord-in-Context (WiC) dataset (Pilehvar and Camacho-Collados, 2019) offer richer\\nevaluation scenarios. SCWS gives human judgments on 2,003 pairs of words in\\ntheir sentential context, while WiC gives target words in two sentential contexts that\\nare either in the same or different senses; see Appendix G. The semantic textual\\nsimilarity task (Agirre et al. 2012, Agirre et al. 2015) evaluates the performance of\\nsentence-level similarity algorithms, consisting of a set of pairs of sentences, each\\npair with human-labeled similarity scores.\\nAnother task used for evaluation is the analogy task, discussed on page 17, where\\nthe system has to solve problems of the form a is to b as a* is to b*, given a, b, and a*'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 20}, page_content='Another task used for evaluation is the analogy task, discussed on page 17, where\\nthe system has to solve problems of the form a is to b as a* is to b*, given a, b, and a*\\nand having to Ô¨Ånd b* (Turney and Littman, 2005). A number of sets of tuples have\\nbeen created for this task (Mikolov et al. 2013a, Mikolov et al. 2013c, Gladkova\\net al. 2016), covering morphology (city:cities::child:children), lexicographic rela-\\ntions (leg:table::spout:teapot) and encyclopedia relations (Beijing:China::Dublin:Ireland),\\nsome drawing from the SemEval-2012 Task 2 dataset of 79 different relations (Jur-\\ngens et al., 2012).\\nAll embedding algorithms suffer from inherent variability. For example because\\nof randomness in the initialization and the random negative sampling, algorithms\\nlike word2vec may produce different results even from the same dataset, and in-\\ndividual documents in a collection may strongly impact the resulting embeddings'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 20}, page_content='like word2vec may produce different results even from the same dataset, and in-\\ndividual documents in a collection may strongly impact the resulting embeddings\\n(Tian et al. 2016, Hellrich and Hahn 2016, Antoniak and Mimno 2018). When em-\\nbeddings are used to study word associations in particular corpora, therefore, it is\\nbest practice to train multiple embeddings with bootstrap sampling over documents\\nand average the results (Antoniak and Mimno, 2018).\\n5.10\\nSummary\\n‚Ä¢ In vector semantics, a word is modeled as a vector‚Äîa point in high-dimensional\\nspace, also called an embedding. In this chapter we focus on static embed-\\ndings, where each word is mapped to a Ô¨Åxed embedding.\\n‚Ä¢ Vector semantic models fall into two classes: sparse and dense. In sparse\\nmodels each dimension corresponds to a word in the vocabulary V and cells\\nare functions of co-occurrence counts. The word-context or term-term ma-\\ntrix has a row for each (target) word in the vocabulary and a column for each'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 20}, page_content='are functions of co-occurrence counts. The word-context or term-term ma-\\ntrix has a row for each (target) word in the vocabulary and a column for each\\ncontext term in the vocabulary.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 21}, page_content='22\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\n‚Ä¢ Dense vector models typically have dimensionality 50‚Äì1000. Word2vec al-\\ngorithms like skip-gram are a popular way to compute dense embeddings.\\nSkip-gram trains a logistic regression classiÔ¨Åer to compute the probability that\\ntwo words are ‚Äòlikely to occur nearby in text‚Äô. This probability is computed\\nfrom the dot product between the embeddings for the two words.\\n‚Ä¢ Skip-gram uses stochastic gradient descent to train the classiÔ¨Åer, by learning\\nembeddings that have a high dot product with embeddings of words that occur\\nnearby and a low dot product with noise words.\\n‚Ä¢ Other important embedding algorithms include GloVe, a method based on\\nratios of word co-occurrence probabilities.\\n‚Ä¢ Whether using sparse or dense vectors, word and document similarities are\\ncomputed by some function of the dot product between vectors. The cosine\\nof two vectors‚Äîa normalized dot product‚Äîis the most popular such metric.\\nHistorical Notes'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 21}, page_content='computed by some function of the dot product between vectors. The cosine\\nof two vectors‚Äîa normalized dot product‚Äîis the most popular such metric.\\nHistorical Notes\\nThe idea of vector semantics arose out of research in the 1950s in three distinct\\nÔ¨Åelds: linguistics, psychology, and computer science, each of which contributed a\\nfundamental aspect of the model.\\nThe idea that meaning is related to the distribution of words in context was\\nwidespread in linguistic theory of the 1950s, among distributionalists like Zellig\\nHarris, Martin Joos, and J. R. Firth, and semioticians like Thomas Sebeok. As Joos\\n(1950) put it,\\nthe linguist‚Äôs ‚Äúmeaning‚Äù of a morpheme. . . is by deÔ¨Ånition the set of conditional\\nprobabilities of its occurrence in context with all other morphemes.\\nThe idea that the meaning of a word might be modeled as a point in a multi-\\ndimensional semantic space came from psychologists like Charles E. Osgood, who'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 21}, page_content='The idea that the meaning of a word might be modeled as a point in a multi-\\ndimensional semantic space came from psychologists like Charles E. Osgood, who\\nhad been studying how people responded to the meaning of words by assigning val-\\nues along scales like happy/sad or hard/soft. Osgood et al. (1957) proposed that the\\nmeaning of a word in general could be modeled as a point in a multidimensional\\nEuclidean space, and that the similarity of meaning between two words could be\\nmodeled as the distance between these points in the space.\\nA Ô¨Ånal intellectual source in the 1950s and early 1960s was the Ô¨Åeld then called\\nmechanical indexing, now known as information retrieval. In what became known\\nmechanical\\nindexing\\nas the vector space model for information retrieval (Salton 1971, Sparck Jones\\n1986), researchers demonstrated new ways to deÔ¨Åne the meaning of words in terms\\nof vectors (Switzer, 1965), and reÔ¨Åned methods for word similarity based on mea-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 21}, page_content='1986), researchers demonstrated new ways to deÔ¨Åne the meaning of words in terms\\nof vectors (Switzer, 1965), and reÔ¨Åned methods for word similarity based on mea-\\nsures of statistical association between words like mutual information (Giuliano,\\n1965) and idf (Sparck Jones, 1972), and showed that the meaning of documents\\ncould be represented in the same vector spaces used for words. Around the same\\ntime, (Cordier, 1965) showed that factor analysis of word association probabilities\\ncould be used to form dense vector representations of words.\\nSome of the philosophical underpinning of the distributional way of thinking\\ncame from the late writings of the philosopher Wittgenstein, who was skeptical of\\nthe possibility of building a completely formal theory of meaning deÔ¨Ånitions for\\neach word. Wittgenstein suggested instead that ‚Äúthe meaning of a word is its use in\\nthe language‚Äù (Wittgenstein, 1953, PI 43). That is, instead of using some logical lan-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 21}, page_content='each word. Wittgenstein suggested instead that ‚Äúthe meaning of a word is its use in\\nthe language‚Äù (Wittgenstein, 1953, PI 43). That is, instead of using some logical lan-\\nguage to deÔ¨Åne each word, or drawing on denotations or truth values, Wittgenstein‚Äôs'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 22}, page_content='HISTORICAL NOTES\\n23\\nidea is that we should deÔ¨Åne a word by how it is used by people in speaking and un-\\nderstanding in their day-to-day interactions, thus preÔ¨Åguring the movement toward\\nembodied and experiential models in linguistics and NLP (Glenberg and Robertson\\n2000, Lake and Murphy 2021, Bisk et al. 2020, Bender and Koller 2020).\\nMore distantly related is the idea of deÔ¨Åning words by a vector of discrete fea-\\ntures, which has roots at least as far back as Descartes and Leibniz (Wierzbicka 1992,\\nWierzbicka 1996). By the middle of the 20th century, beginning with the work of\\nHjelmslev (Hjelmslev, 1969) (originally 1943) and Ô¨Çeshed out in early models of\\ngenerative grammar (Katz and Fodor, 1963), the idea arose of representing mean-\\ning with semantic features, symbols that represent some sort of primitive meaning.\\nsemantic\\nfeature\\nFor example words like hen, rooster, or chick, have something in common (they all'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 22}, page_content='ing with semantic features, symbols that represent some sort of primitive meaning.\\nsemantic\\nfeature\\nFor example words like hen, rooster, or chick, have something in common (they all\\ndescribe chickens) and something different (their age and sex), representable as:\\nhen\\n+female, +chicken, +adult\\nrooster -female, +chicken, +adult\\nchick\\n+chicken, -adult\\nThe dimensions used by vector models of meaning to deÔ¨Åne words, however, are\\nonly abstractly related to this idea of a small Ô¨Åxed number of hand-built dimensions.\\nNonetheless, there has been some attempt to show that certain dimensions of em-\\nbedding models do contribute some speciÔ¨Åc compositional aspect of meaning like\\nthese early semantic features.\\nThe use of dense vectors to model word meaning, and indeed the term embed-\\nding, grew out of the latent semantic indexing (LSI) model (Deerwester et al.,\\n1988) recast as LSA (latent semantic analysis) (Deerwester et al., 1990). In LSA'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 22}, page_content='ding, grew out of the latent semantic indexing (LSI) model (Deerwester et al.,\\n1988) recast as LSA (latent semantic analysis) (Deerwester et al., 1990). In LSA\\nsingular value decomposition‚ÄîSVD‚Äî is applied to a term-document matrix (each\\nSVD\\ncell weighted by log frequency and normalized by entropy), and then the Ô¨Årst 300\\ndimensions are used as the LSA embedding. Singular Value Decomposition (SVD)\\nis a method for Ô¨Ånding the most important dimensions of a data set, those dimen-\\nsions along which the data varies the most. LSA was then quickly widely applied:\\nas a cognitive model (Landauer and Dumais, 1997), and for tasks like spell checking\\n(Jones and Martin, 1997), language modeling (Bellegarda 1997, Coccaro and Ju-\\nrafsky 1998, Bellegarda 2000), morphology induction (Schone and Jurafsky 2000,\\nSchone and Jurafsky 2001b), multiword expressions (MWEs) (Schone and Jurafsky,\\n2001a), and essay grading (Rehder et al., 1998). Related models were simultane-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 22}, page_content='Schone and Jurafsky 2001b), multiword expressions (MWEs) (Schone and Jurafsky,\\n2001a), and essay grading (Rehder et al., 1998). Related models were simultane-\\nously developed and applied to word sense disambiguation by Sch¬®utze (1992). LSA\\nalso led to the earliest use of embeddings to represent words in a probabilistic clas-\\nsiÔ¨Åer, in the logistic regression document router of Sch¬®utze et al. (1995). The idea of\\nSVD on the term-term matrix (rather than the term-document matrix) as a model of\\nmeaning for NLP was proposed soon after LSA by Sch¬®utze (1992). Sch¬®utze applied\\nthe low-rank (97-dimensional) embeddings produced by SVD to the task of word\\nsense disambiguation, analyzed the resulting semantic space, and also suggested\\npossible techniques like dropping high-order dimensions. See Sch¬®utze (1997).\\nA number of alternative matrix models followed on from the early SVD work,\\nincluding Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 1999), Latent'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 22}, page_content='A number of alternative matrix models followed on from the early SVD work,\\nincluding Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 1999), Latent\\nDirichlet Allocation (LDA) (Blei et al., 2003), and Non-negative Matrix Factoriza-\\ntion (NMF) (Lee and Seung, 1999).\\nThe LSA community seems to have Ô¨Årst used the word ‚Äúembedding‚Äù in Landauer\\net al. (1997), in a variant of its mathematical meaning as a mapping from one space\\nor mathematical structure to another. In LSA, the word embedding seems to have\\ndescribed the mapping from the space of sparse count vectors to the latent space of\\nSVD dense vectors. Although the word thus originally meant the mapping from one'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 23}, page_content='24\\nCHAPTER 5\\n‚Ä¢\\nEMBEDDINGS\\nspace to another, it has metonymically shifted to mean the resulting dense vector in\\nthe latent space, and it is in this sense that we currently use the word.\\nBy the next decade, Bengio et al. (2003) and Bengio et al. (2006) showed that\\nneural language models could also be used to develop embeddings as part of the task\\nof word prediction. Collobert and Weston (2007), Collobert and Weston (2008), and\\nCollobert et al. (2011) then demonstrated that embeddings could be used to represent\\nword meanings for a number of NLP tasks. Turian et al. (2010) compared the value\\nof different kinds of embeddings for different NLP tasks. Mikolov et al. (2011)\\nshowed that recurrent neural nets could be used as language models. The idea of\\nsimplifying the hidden layer of these neural net language models to create the skip-\\ngram (and also CBOW) algorithms was proposed by Mikolov et al. (2013a). The\\nnegative sampling training algorithm was proposed in Mikolov et al. (2013b). There'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 23}, page_content='gram (and also CBOW) algorithms was proposed by Mikolov et al. (2013a). The\\nnegative sampling training algorithm was proposed in Mikolov et al. (2013b). There\\nare numerous surveys of static embeddings and their parameterizations (Bullinaria\\nand Levy 2007, Bullinaria and Levy 2012, Lapesa and Evert 2014, Kiela and Clark\\n2014, Levy et al. 2015).\\nSee Manning et al. (2008) and Chapter 11 for a deeper understanding of the role\\nof vectors in information retrieval, including how to compare queries with docu-\\nments, more details on tf-idf, and issues of scaling to very large datasets. See Kim\\n(2019) for a clear and comprehensive tutorial on word2vec. Cruse (2004) is a useful\\nintroductory linguistic text on lexical semantics.\\nExercises'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='Exercises\\n25\\nAgirre, E., C. Banea, C. Cardie, D. Cer, M. Diab,\\nA. Gonzalez-Agirre, W. Guo, I. Lopez-Gazpio, M. Mar-\\nitxalar, R. Mihalcea, G. Rigau, L. Uria, and J. Wiebe.\\n2015. SemEval-2015 task 2: Semantic textual similarity,\\nEnglish, Spanish and pilot on interpretability. SemEval-\\n15.\\nAgirre, E., M. Diab, D. Cer, and A. Gonzalez-Agirre. 2012.\\nSemEval-2012 task 6: A pilot on semantic textual simi-\\nlarity. SemEval-12.\\nAntoniak, M. and D. Mimno. 2018. Evaluating the stability\\nof embedding-based word similarities. TACL, 6:107‚Äì119.\\nBellegarda, J. R. 1997. A latent semantic analysis framework\\nfor large-span language modeling. EUROSPEECH.\\nBellegarda, J. R. 2000. Exploiting latent semantic informa-\\ntion in statistical language modeling. Proceedings of the\\nIEEE, 89(8):1279‚Äì1296.\\nBender, E. M. and A. Koller. 2020. Climbing towards NLU:\\nOn meaning, form, and understanding in the age of data.\\nACL.\\nBengio, Y., A. Courville, and P. Vincent. 2013. Represen-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='IEEE, 89(8):1279‚Äì1296.\\nBender, E. M. and A. Koller. 2020. Climbing towards NLU:\\nOn meaning, form, and understanding in the age of data.\\nACL.\\nBengio, Y., A. Courville, and P. Vincent. 2013. Represen-\\ntation learning: A review and new perspectives. IEEE\\nTransactions on Pattern Analysis and Machine Intelli-\\ngence, 35(8):1798‚Äì1828.\\nBengio, Y., R. Ducharme, P. Vincent, and C. Jauvin. 2003.\\nA neural probabilistic language model. JMLR, 3:1137‚Äì\\n1155.\\nBengio, Y., H. Schwenk, J.-S. Sen¬¥ecal, F. Morin, and J.-L.\\nGauvain. 2006. Neural probabilistic language models. In\\nInnovations in Machine Learning, 137‚Äì186. Springer.\\nBisk, Y., A. Holtzman, J. Thomason, J. Andreas, Y. Bengio,\\nJ. Chai, M. Lapata, A. Lazaridou, J. May, A. Nisnevich,\\nN. Pinto, and J. Turian. 2020. Experience grounds lan-\\nguage. EMNLP.\\nBlei, D. M., A. Y. Ng, and M. I. Jordan. 2003. Latent Dirich-\\nlet allocation. JMLR, 3(5):993‚Äì1022.\\nBlodgett, S. L., S. Barocas, H. Daum¬¥e III, and H. Wallach.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='guage. EMNLP.\\nBlei, D. M., A. Y. Ng, and M. I. Jordan. 2003. Latent Dirich-\\nlet allocation. JMLR, 3(5):993‚Äì1022.\\nBlodgett, S. L., S. Barocas, H. Daum¬¥e III, and H. Wallach.\\n2020. Language (technology) is power: A critical survey\\nof ‚Äúbias‚Äù in NLP. ACL.\\nBojanowski, P., E. Grave, A. Joulin, and T. Mikolov. 2017.\\nEnriching word vectors with subword information. TACL,\\n5:135‚Äì146.\\nBolukbasi, T., K.-W. Chang, J. Zou, V. Saligrama, and A. T.\\nKalai. 2016. Man is to computer programmer as woman\\nis to homemaker? Debiasing word embeddings. NeurIPS.\\nBr¬¥eal, M. 1897. Essai de S¬¥emantique: Science des signiÔ¨Åca-\\ntions. Hachette.\\nBudanitsky, A. and G. Hirst. 2006.\\nEvaluating WordNet-\\nbased measures of lexical semantic relatedness. Compu-\\ntational Linguistics, 32(1):13‚Äì47.\\nBullinaria, J. A. and J. P. Levy. 2007. Extracting seman-\\ntic representations from word co-occurrence statistics:\\nA computational study.\\nBehavior research methods,\\n39(3):510‚Äì526.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='Bullinaria, J. A. and J. P. Levy. 2007. Extracting seman-\\ntic representations from word co-occurrence statistics:\\nA computational study.\\nBehavior research methods,\\n39(3):510‚Äì526.\\nBullinaria, J. A. and J. P. Levy. 2012. Extracting semantic\\nrepresentations from word co-occurrence statistics: stop-\\nlists, stemming, and SVD. Behavior research methods,\\n44(3):890‚Äì907.\\nCaliskan, A., J. J. Bryson, and A. Narayanan. 2017. Seman-\\ntics derived automatically from language corpora contain\\nhuman-like biases. Science, 356(6334):183‚Äì186.\\nCarlson, G. N. 1977. Reference to kinds in English. Ph.D.\\nthesis, University of Massachusetts, Amherst. Forward.\\nClark, E. 1987. The principle of contrast: A constraint on\\nlanguage acquisition. In B. MacWhinney, ed., Mecha-\\nnisms of language acquisition, 1‚Äì33. LEA.\\nCoccaro, N. and D. Jurafsky. 1998. Towards better integra-\\ntion of semantic predictors in statistical language model-\\ning. ICSLP.\\nCollobert, R. and J. Weston. 2007. Fast semantic extraction'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='Coccaro, N. and D. Jurafsky. 1998. Towards better integra-\\ntion of semantic predictors in statistical language model-\\ning. ICSLP.\\nCollobert, R. and J. Weston. 2007. Fast semantic extraction\\nusing a novel neural network architecture. ACL.\\nCollobert, R. and J. Weston. 2008. A uniÔ¨Åed architecture for\\nnatural language processing: Deep neural networks with\\nmultitask learning. ICML.\\nCollobert,\\nR.,\\nJ.\\nWeston,\\nL.\\nBottou,\\nM.\\nKarlen,\\nK. Kavukcuoglu, and P. Kuksa. 2011. Natural language\\nprocessing (almost) from scratch. JMLR, 12:2493‚Äì2537.\\nCordier, B. 1965. Factor-analysis of correspondences. COL-\\nING 1965.\\nCrawford, K. 2017.\\nThe trouble with bias.\\nKeynote at\\nNeurIPS.\\nCruse, D. A. 2004. Meaning in Language: an Introduction\\nto Semantics and Pragmatics. Oxford University Press.\\nSecond edition.\\nDavies, M. 2012.\\nExpanding horizons in historical lin-\\nguistics with the 400-million word Corpus of Historical\\nAmerican English. Corpora, 7(2):121‚Äì157.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='Second edition.\\nDavies, M. 2012.\\nExpanding horizons in historical lin-\\nguistics with the 400-million word Corpus of Historical\\nAmerican English. Corpora, 7(2):121‚Äì157.\\nDavies, M. 2015. The Wikipedia Corpus: 4.6 million arti-\\ncles, 1.9 billion words. Adapted from Wikipedia. https:\\n//www.english-corpora.org/wiki/.\\nDeerwester, S. C., S. T. Dumais, G. W. Furnas, R. A. Harsh-\\nman, T. K. Landauer, K. E. Lochbaum, and L. Streeter.\\n1988. Computer information retrieval using latent seman-\\ntic structure: US Patent 4,839,853.\\nDeerwester, S. C., S. T. Dumais, T. K. Landauer, G. W. Fur-\\nnas, and R. A. Harshman. 1990. Indexing by latent se-\\nmantics analysis. JASIS, 41(6):391‚Äì407.\\nEthayarajh, K., D. Duvenaud, and G. Hirst. 2019a. Towards\\nunderstanding linear word analogies. ACL.\\nEthayarajh, K., D. Duvenaud, and G. Hirst. 2019b. Under-\\nstanding undesirable word embedding associations. ACL.\\nFinkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin,\\nZ. Solan, G. Wolfman, and E. Ruppin. 2002.\\nPlacing'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 24}, page_content='standing undesirable word embedding associations. ACL.\\nFinkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin,\\nZ. Solan, G. Wolfman, and E. Ruppin. 2002.\\nPlacing\\nsearch in context: The concept revisited. ACM Trans-\\nactions on Information Systems, 20(1):116‚Äî-131.\\nFirth, J. R. 1957.\\nA synopsis of linguistic theory 1930‚Äì\\n1955. In Studies in Linguistic Analysis. Philological So-\\nciety. Reprinted in Palmer, F. (ed.) 1968. Selected Papers\\nof J. R. Firth. Longman, Harlow.\\nGarg, N., L. Schiebinger, D. Jurafsky, and J. Zou. 2018.\\nWord embeddings quantify 100 years of gender and eth-\\nnic stereotypes. Proceedings of the National Academy of\\nSciences, 115(16):E3635‚ÄìE3644.\\nGirard, G. 1718. La justesse de la langue franc¬∏oise: ou les\\ndiff¬¥erentes signiÔ¨Åcations des mots qui passent pour syn-\\nonimes. Laurent d‚ÄôHoury, Paris.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='26\\nChapter 5\\n‚Ä¢\\nEmbeddings\\nGiuliano,\\nV. E. 1965.\\nThe interpretation of word\\nassociations.\\nStatistical Association Methods For\\nMechanized\\nDocumentation.\\nSymposium\\nProceed-\\nings.\\nWashington,\\nD.C.,\\nUSA,\\nMarch\\n17,\\n1964.\\nhttps://nvlpubs.nist.gov/nistpubs/Legacy/\\nMP/nbsmiscellaneouspub269.pdf.\\nGladkova, A., A. Drozd, and S. Matsuoka. 2016. Analogy-\\nbased detection of morphological and semantic relations\\nwith word embeddings: what works and what doesn‚Äôt.\\nNAACL Student Research Workshop.\\nGlenberg, A. M. and D. A. Robertson. 2000. Symbol ground-\\ning and meaning: A comparison of high-dimensional and\\nembodied theories of meaning. Journal of memory and\\nlanguage, 43(3):379‚Äì401.\\nGonen, H. and Y. Goldberg. 2019. Lipstick on a pig: Debi-\\nasing methods cover up systematic gender biases in word\\nembeddings but do not remove them. NAACL HLT.\\nGould, S. J. 1980. The Panda‚Äôs Thumb. Penguin Group.\\nGreenwald, A. G., D. E. McGhee, and J. L. K. Schwartz.\\n1998. Measuring individual differences in implicit cogni-'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='Gould, S. J. 1980. The Panda‚Äôs Thumb. Penguin Group.\\nGreenwald, A. G., D. E. McGhee, and J. L. K. Schwartz.\\n1998. Measuring individual differences in implicit cogni-\\ntion: the implicit association test. Journal of personality\\nand social psychology, 74(6):1464‚Äì1480.\\nHamilton, W. L., J. Leskovec, and D. Jurafsky. 2016. Di-\\nachronic word embeddings reveal statistical laws of se-\\nmantic change. ACL.\\nHarris, Z. S. 1954. Distributional structure. Word, 10:146‚Äì\\n162.\\nHellrich,\\nJ. and U. Hahn. 2016.\\nBad company‚Äî\\nNeighborhoods in neural embedding spaces considered\\nharmful. COLING.\\nHill, F., R. Reichart, and A. Korhonen. 2015. Simlex-999:\\nEvaluating semantic models with (genuine) similarity es-\\ntimation. Computational Linguistics, 41(4):665‚Äì695.\\nHjelmslev, L. 1969. Prologomena to a Theory of Language.\\nUniversity of Wisconsin Press. Translated by Francis J.\\nWhitÔ¨Åeld; original Danish edition 1943.\\nHofmann, T. 1999. Probabilistic latent semantic indexing.\\nSIGIR-99.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='University of Wisconsin Press. Translated by Francis J.\\nWhitÔ¨Åeld; original Danish edition 1943.\\nHofmann, T. 1999. Probabilistic latent semantic indexing.\\nSIGIR-99.\\nHuang, E. H., R. Socher, C. D. Manning, and A. Y. Ng. 2012.\\nImproving word representations via global context and\\nmultiple word prototypes. ACL.\\nJia, S., T. Meng, J. Zhao, and K.-W. Chang. 2020. Mitigat-\\ning gender bias ampliÔ¨Åcation in distribution by posterior\\nregularization. ACL.\\nJones, M. P. and J. H. Martin. 1997. Contextual spelling cor-\\nrection using latent semantic analysis. ANLP.\\nJoos, M. 1950.\\nDescription of language design.\\nJASA,\\n22:701‚Äì708.\\nJurgens, D., S. M. Mohammad, P. Turney, and K. Holyoak.\\n2012. SemEval-2012 task 2: Measuring degrees of rela-\\ntional similarity. *SEM 2012.\\nKatz, J. J. and J. A. Fodor. 1963. The structure of a semantic\\ntheory. Language, 39:170‚Äì210.\\nKiela, D. and S. Clark. 2014. A systematic study of semantic\\nvector space model parameters. EACL 2nd Workshop on'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='theory. Language, 39:170‚Äì210.\\nKiela, D. and S. Clark. 2014. A systematic study of semantic\\nvector space model parameters. EACL 2nd Workshop on\\nContinuous Vector Space Models and their Composition-\\nality (CVSC).\\nKim,\\nE.\\n2019.\\nOptimize\\ncomputational\\nefÔ¨Åciency\\nof skip-gram with negative sampling.\\nhttps://\\naegis4048.github.io/optimize_computational_\\nefficiency_of_skip-gram_with_negative_\\nsampling.\\nLake, B. M. and G. L. Murphy. 2021.\\nWord meaning in\\nminds and machines. Psychological Review. In press.\\nLandauer, T. K. and S. T. Dumais. 1997. A solution to Plato‚Äôs\\nproblem: The Latent Semantic Analysis theory of acqui-\\nsition, induction, and representation of knowledge. Psy-\\nchological Review, 104:211‚Äì240.\\nLandauer, T. K., D. Laham, B. Rehder, and M. E. Schreiner.\\n1997. How well can passage meaning be derived with-\\nout using word order? A comparison of Latent Semantic\\nAnalysis and humans. COGSCI.\\nLapesa, G. and S. Evert. 2014. A large scale evaluation of'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='1997. How well can passage meaning be derived with-\\nout using word order? A comparison of Latent Semantic\\nAnalysis and humans. COGSCI.\\nLapesa, G. and S. Evert. 2014. A large scale evaluation of\\ndistributional semantic models: Parameters, interactions\\nand model selection. TACL, 2:531‚Äì545.\\nLee, D. D. and H. S. Seung. 1999. Learning the parts of\\nobjects by non-negative matrix factorization.\\nNature,\\n401(6755):788‚Äì791.\\nLevy, O. and Y. Goldberg. 2014a. Dependency-based word\\nembeddings. ACL.\\nLevy, O. and Y. Goldberg. 2014b. Linguistic regularities in\\nsparse and explicit word representations. CoNLL.\\nLevy, O. and Y. Goldberg. 2014c. Neural word embedding\\nas implicit matrix factorization. NeurIPS.\\nLevy, O., Y. Goldberg, and I. Dagan. 2015. Improving dis-\\ntributional similarity with lessons learned from word em-\\nbeddings. TACL, 3:211‚Äì225.\\nLin, Y., J.-B. Michel, E. Lieberman Aiden, J. Orwant,\\nW. Brockman, and S. Petrov. 2012. Syntactic annotations\\nfor the Google Books NGram corpus. ACL.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='beddings. TACL, 3:211‚Äì225.\\nLin, Y., J.-B. Michel, E. Lieberman Aiden, J. Orwant,\\nW. Brockman, and S. Petrov. 2012. Syntactic annotations\\nfor the Google Books NGram corpus. ACL.\\nLinzen, T. 2016. Issues in evaluating semantic spaces us-\\ning word analogies. 1st Workshop on Evaluating Vector-\\nSpace Representations for NLP.\\nManning, C. D., P. Raghavan, and H. Sch¬®utze. 2008. Intro-\\nduction to Information Retrieval. Cambridge.\\nMikolov, T., K. Chen, G. S. Corrado, and J. Dean. 2013a. Ef-\\nÔ¨Åcient estimation of word representations in vector space.\\nICLR 2013.\\nMikolov, T., S. Kombrink, L. Burget, J. H. ÀáCernock`y, and\\nS. Khudanpur. 2011. Extensions of recurrent neural net-\\nwork language model. ICASSP.\\nMikolov, T., I. Sutskever, K. Chen, G. S. Corrado, and\\nJ. Dean. 2013b. Distributed representations of words and\\nphrases and their compositionality. NeurIPS.\\nMikolov, T., W.-t. Yih, and G. Zweig. 2013c.\\nLinguis-\\ntic regularities in continuous space word representations.\\nNAACL HLT.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 25}, page_content='phrases and their compositionality. NeurIPS.\\nMikolov, T., W.-t. Yih, and G. Zweig. 2013c.\\nLinguis-\\ntic regularities in continuous space word representations.\\nNAACL HLT.\\nNosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002a.\\nHarvesting implicit group attitudes and beliefs from a\\ndemonstration web site. Group Dynamics: Theory, Re-\\nsearch, and Practice, 6(1):101.\\nNosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002b.\\nMath=male, me=female, therefore mathÃ∏= me. Journal of\\npersonality and social psychology, 83(1):44.\\nOsgood, C. E., G. J. Suci, and P. H. Tannenbaum. 1957. The\\nMeasurement of Meaning. University of Illinois Press.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 26}, page_content='Exercises\\n27\\nPennington, J., R. Socher, and C. D. Manning. 2014. GloVe:\\nGlobal vectors for word representation. EMNLP.\\nPeterson, J. C., D. Chen, and T. L. GrifÔ¨Åths. 2020. Parallelo-\\ngrams revisited: Exploring the limitations of vector space\\nmodels for simple analogies. Cognition, 205.\\nPilehvar, M. T. and J. Camacho-Collados. 2019. WiC: the\\nword-in-context dataset for evaluating context-sensitive\\nmeaning representations. NAACL HLT.\\nRehder, B., M. E. Schreiner, M. B. W. Wolfe, D. Laham,\\nT. K. Landauer, and W. Kintsch. 1998.\\nUsing Latent\\nSemantic Analysis to assess knowledge: Some technical\\nconsiderations. Discourse Processes, 25(2-3):337‚Äì354.\\nRohde, D. L. T., L. M. Gonnerman, and D. C. Plaut. 2006.\\nAn improved model of semantic similarity based on lexi-\\ncal co-occurrence. CACM, 8:627‚Äì633.\\nRumelhart, D. E. and A. A. Abrahamson. 1973. A model for\\nanalogical reasoning. Cognitive Psychology, 5(1):1‚Äì28.\\nSalton, G. 1971. The SMART Retrieval System: Experiments'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 26}, page_content='Rumelhart, D. E. and A. A. Abrahamson. 1973. A model for\\nanalogical reasoning. Cognitive Psychology, 5(1):1‚Äì28.\\nSalton, G. 1971. The SMART Retrieval System: Experiments\\nin Automatic Document Processing. Prentice Hall.\\nSchluter, N. 2018. The word analogy testing caveat. NAACL\\nHLT.\\nSchone, P. and D. Jurafsky. 2000. Knowlege-free induction\\nof morphology using latent semantic analysis. CoNLL.\\nSchone, P. and D. Jurafsky. 2001a. Is knowledge-free in-\\nduction of multiword unit dictionary headwords a solved\\nproblem? EMNLP.\\nSchone, P. and D. Jurafsky. 2001b. Knowledge-free induc-\\ntion of inÔ¨Çectional morphologies. NAACL.\\nSch¬®utze, H. 1992. Dimensions of meaning. Proceedings of\\nSupercomputing ‚Äô92. IEEE Press.\\nSch¬®utze, H. 1997. Ambiguity Resolution in Language Learn-\\ning ‚Äì Computational and Cognitive Models. CSLI, Stan-\\nford, CA.\\nSch¬®utze, H., D. A. Hull, and J. Pedersen. 1995. A compar-\\nison of classiÔ¨Åers and document representations for the\\nrouting problem. SIGIR-95.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 26}, page_content='ford, CA.\\nSch¬®utze, H., D. A. Hull, and J. Pedersen. 1995. A compar-\\nison of classiÔ¨Åers and document representations for the\\nrouting problem. SIGIR-95.\\nSch¬®utze, H. and J. Pedersen. 1993. A vector model for syn-\\ntagmatic and paradigmatic relatedness. 9th Annual Con-\\nference of the UW Centre for the New OED and Text Re-\\nsearch.\\nSparck Jones, K. 1972. A statistical interpretation of term\\nspeciÔ¨Åcity and its application in retrieval. Journal of Doc-\\numentation, 28(1):11‚Äì21.\\nSparck Jones, K. 1986. Synonymy and Semantic ClassiÔ¨Åca-\\ntion. Edinburgh University Press, Edinburgh. Republica-\\ntion of 1964 PhD Thesis.\\nSwitzer, P. 1965.\\nVector images in document retrieval.\\nStatistical Association Methods For Mechanized Docu-\\nmentation. Symposium Proceedings. Washington, D.C.,\\nUSA, March 17, 1964. https://nvlpubs.nist.gov/\\nnistpubs/Legacy/MP/nbsmiscellaneouspub269.\\npdf.\\nTian, Y., V. Kulkarni, B. Perozzi, and S. Skiena. 2016. On\\nthe convergent properties of word embedding methods.'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 26}, page_content='nistpubs/Legacy/MP/nbsmiscellaneouspub269.\\npdf.\\nTian, Y., V. Kulkarni, B. Perozzi, and S. Skiena. 2016. On\\nthe convergent properties of word embedding methods.\\nArXiv preprint arXiv:1605.03956.\\nTurian, J., L. Ratinov, and Y. Bengio. 2010. Word represen-\\ntations: a simple and general method for semi-supervised\\nlearning. ACL.\\nTurney, P. D. and M. L. Littman. 2005. Corpus-based learn-\\ning of analogies and semantic relations. Machine Learn-\\ning, 60(1-3):251‚Äì278.\\nvan der Maaten, L. and G. E. Hinton. 2008. Visualizing high-\\ndimensional data using t-SNE. JMLR, 9:2579‚Äì2605.\\nWierzbicka, A. 1992. Semantics, Culture, and Cognition:\\nUniversity Human Concepts in Culture-SpeciÔ¨Åc ConÔ¨Ågu-\\nrations. Oxford University Press.\\nWierzbicka, A. 1996. Semantics: Primes and Universals.\\nOxford University Press.\\nWittgenstein, L. 1953. Philosophical Investigations. (Trans-\\nlated by Anscombe, G.E.M.). Blackwell.\\nZhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-\\nW. Chang. 2017.\\nMen also like shopping: Reducing'), Document(metadata={'producer': 'pdfTeX-1.40.21', 'creator': 'LaTeX with hyperref', 'creationdate': '2025-08-24T11:50:50-07:00', 'source': 'embeddings.pdf', 'file_path': 'data\\\\embeddings.pdf', 'total_pages': 27, 'format': 'PDF 1.5', 'title': '', 'author': '', 'subject': '', 'keywords': '', 'moddate': '2025-08-24T11:50:50-07:00', 'trapped': '', 'modDate': \"D:20250824115050-07'00'\", 'creationDate': \"D:20250824115050-07'00'\", 'page': 26}, page_content='Wittgenstein, L. 1953. Philosophical Investigations. (Trans-\\nlated by Anscombe, G.E.M.). Blackwell.\\nZhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-\\nW. Chang. 2017.\\nMen also like shopping: Reducing\\ngender bias ampliÔ¨Åcation using corpus-level constraints.\\nEMNLP.\\nZhao, J., Y. Zhou, Z. Li, W. Wang, and K.-W. Chang. 2018.\\nLearning gender-neutral word embeddings. EMNLP.')]\n",
      "page_content and meta data  Darshan Hiremath \n",
      "8904691801 | darshanah2002@gmail.com \n",
      " \n",
      "Profile \n",
      "AI & Machine Learning enthusiast with hands-on experience in Statistical Models, Transformer \n",
      "Models, and Large Language Models (LLMs). Passionate about model explainability, fine-tuning \n",
      "techniques, and AI-powered applications. Skilled in integrating LIME, SHAP, and LLMs (GPT-\n",
      "4, Gemini AI) to enhance interpretability. Experienced in efficient fine-tuning (LoRA, PEFT) and \n",
      "optimizing large models for real-world use. \n",
      " \n",
      "Technical Skills \n",
      "Programming: Python \n",
      "‚Ä¢ \n",
      "Explainable AI: SHAP, LIME, Grad-CAM, Integrated Gradients \n",
      "‚Ä¢ \n",
      "LLM : Llama 3.1  \n",
      "‚Ä¢ \n",
      "Deep Learning: CNNs, Transformers, LLMs   \n",
      "‚Ä¢ \n",
      "NLP Models: GPT-2, DistilBERT   \n",
      "‚Ä¢ \n",
      "LLM Fine-Tuning: LoRA, PEFT, Quantization (4-bit, 8-bit)   \n",
      "‚Ä¢ \n",
      "Frameworks: PyTorch, TensorFlow , Hugging Face   \n",
      "‚Ä¢ \n",
      "Tools: Gemini AI, GPT-4   \n",
      "‚Ä¢ \n",
      "Domains: XAI, NLP, Deep Learning , Model Interpretability \n",
      " \n",
      "Work Experience \n",
      "AI & Machine Learning Engineer\n",
      "page_content and meta data  ‚Ä¢ \n",
      "Frameworks: PyTorch, TensorFlow , Hugging Face   \n",
      "‚Ä¢ \n",
      "Tools: Gemini AI, GPT-4   \n",
      "‚Ä¢ \n",
      "Domains: XAI, NLP, Deep Learning , Model Interpretability \n",
      " \n",
      "Work Experience \n",
      "AI & Machine Learning Engineer   \n",
      "L&T Technology Services | July 2024 ‚Äì Present   \n",
      " \n",
      "Explainable AI ‚Äì Statistical Models (Honda Use Case) \n",
      "ÔÇ∑ \n",
      "Applied LIME and SHAP to explain predictions of a statistical sensor-based quality \n",
      "model (Gx, Gy, Gz). \n",
      "ÔÇ∑ \n",
      "Delivered instance-level and global feature attributions for ‚ÄúGood / No-Good‚Äù \n",
      "classifications. \n",
      "ÔÇ∑ \n",
      "Integrated GPT-4 and Gemini AI to automatically convert XAI outputs into \n",
      "business-friendly explanations for non-technical stakeholders. \n",
      "ÔÇ∑ \n",
      "Presented explainability results through visual reports and demo videos to cross-\n",
      "functional teams. \n",
      " \n",
      "Explainability in Transformer Models \n",
      "ÔÇ∑ Investigated feasibility of applying SHAP to transformer architectures. \n",
      "ÔÇ∑ Fine-tuned GPT-2 and DistilBERT on Amazon Reviews for sentiment \n",
      "classification.\n",
      "page_content and meta data  Explainability in Transformer Models \n",
      "ÔÇ∑ Investigated feasibility of applying SHAP to transformer architectures. \n",
      "ÔÇ∑ Fine-tuned GPT-2 and DistilBERT on Amazon Reviews for sentiment \n",
      "classification. \n",
      "ÔÇ∑ Identified and resolved incorrect attribution issues by improving fine-tuning strategy. \n",
      "ÔÇ∑ Successfully generated token-level and feature-level explanations for transformer \n",
      "predictions. \n",
      " \n",
      "Exploration of LLMs & Efficient Fine-Tuning \n",
      "ÔÇ∑ Explored explainability extensions for Large Language Models (LLMs). \n",
      "ÔÇ∑ Experimented with 4-bit and 8-bit quantized model loading for memory-efficient \n",
      "inference. \n",
      "ÔÇ∑ Implemented PEFT techniques, including LoRA, to fine-tune LLMs with reduced \n",
      "compute cost. \n",
      "ÔÇ∑ Evaluated trade-offs between performance, memory usage, and interpretability.\n",
      "page_content and meta data  Hackathon  \n",
      "ÔÇ∑ \n",
      "Participated in L&T internal hackathon focused on applied AI solutions. \n",
      "ÔÇ∑ \n",
      "Implemented Grad-CAM on ResNet for eye disease classification, highlighting \n",
      "class-discriminative regions. \n",
      "ÔÇ∑ \n",
      "Demonstrated how CNN models learn visual patterns and validated predictions using \n",
      "saliency maps. \n",
      "EDUCATION \n",
      "Bapuji Institute Of Engineering And Technology                                                    2020 ‚Äì 2024 \n",
      "Computer Science & Engineering                                                                              \n",
      "7.8/10 CGPA  \n",
      "Vishwaachetana Vidyaniketana Pu College                                                              2018 - 2020 \n",
      " 73 percent  \n",
      "OM National PU College                                                                                          2018 \n",
      "71 percent\n",
      "page_content and meta data  Speech and Language Processing.\n",
      "Daniel Jurafsky & James H. Martin.\n",
      "Copyright ¬© 2025.\n",
      "All\n",
      "rights reserved.\n",
      "Draft of August 24, 2025.\n",
      "CHAPTER\n",
      "5\n",
      "Embeddings\n",
      "ËçÉËÄÖÊâÄ‰ª•Âú®È±ºÔºåÂæóÈ±ºËÄåÂøòËçÉNets are for Ô¨Åsh;\n",
      "Once you get the Ô¨Åsh, you can forget the net.\n",
      "Ë®ÄËÄÖÊâÄ‰ª•Âú®ÊÑèÔºåÂæóÊÑèËÄåÂøòË®ÄWords are for meaning;\n",
      "Once you get the meaning, you can forget the words\n",
      "Â∫ÑÂ≠ê(Zhuangzi), Chapter 26\n",
      "The asphalt that Los Angeles is famous for occurs mainly on its freeways. But\n",
      "in the middle of the city is another patch of asphalt, the La Brea tar pits, and this\n",
      "asphalt preserves millions of fossil bones from the last of the Ice Ages of the Pleis-\n",
      "tocene Epoch. One of these fossils is the Smilodon, or saber-toothed tiger, instantly\n",
      "recognizable by its long canines. Five million years ago or so, a completely different\n",
      "saber-tooth tiger called Thylacosmilus lived\n",
      "in Argentina and other parts of South Amer-\n",
      "ica. Thylacosmilus was a marsupial whereas\n",
      "Smilodon was a placental mammal, but Thy-\n",
      "lacosmilus had the same long upper canines\n",
      "page_content and meta data  in Argentina and other parts of South Amer-\n",
      "ica. Thylacosmilus was a marsupial whereas\n",
      "Smilodon was a placental mammal, but Thy-\n",
      "lacosmilus had the same long upper canines\n",
      "and, like Smilodon, had a protective bone\n",
      "Ô¨Çange on the lower jaw.\n",
      "The similarity of\n",
      "these two mammals is one of many examples\n",
      "of parallel or convergent evolution, in which particular contexts or environments\n",
      "lead to the evolution of very similar structures in different species (Gould, 1980).\n",
      "The role of context is also important in the similarity of a less biological kind\n",
      "of organism: the word. Words that occur in similar contexts tend to have similar\n",
      "meanings. This link between similarity in how words are distributed and similarity\n",
      "in what they mean is called the distributional hypothesis. The hypothesis was\n",
      "distributional\n",
      "hypothesis\n",
      "Ô¨Årst formulated in the 1950s by linguists like Joos (1950), Harris (1954), and Firth\n",
      "(1957), who noticed that words which are synonyms (like oculist and eye-doctor)\n",
      "page_content and meta data  distributional\n",
      "hypothesis\n",
      "Ô¨Årst formulated in the 1950s by linguists like Joos (1950), Harris (1954), and Firth\n",
      "(1957), who noticed that words which are synonyms (like oculist and eye-doctor)\n",
      "tended to occur in the same environment (e.g., near words like eye or examined)\n",
      "with the amount of meaning difference between two words ‚Äúcorresponding roughly\n",
      "to the amount of difference in their environments‚Äù (Harris, 1954, p. 157).\n",
      "In this chapter we introduce embeddings, vector representations of the meaning\n",
      "embeddings\n",
      "of words that are learned directly from word distributions in texts. Embeddings lie\n",
      "at the heart of large language models and other modern applications. The static em-\n",
      "beddings we introduce here underlie the more powerful dynamic or contextualized\n",
      "embeddings like BERT that we will see in Chapter 10 and Chapter 8.\n",
      "The linguistic Ô¨Åeld that studies embeddings and their meanings is called vector\n",
      "semantics. Embeddings are also the Ô¨Årst example in this book of representation\n",
      "vector\n",
      "page_content and meta data  The linguistic Ô¨Åeld that studies embeddings and their meanings is called vector\n",
      "semantics. Embeddings are also the Ô¨Årst example in this book of representation\n",
      "vector\n",
      "semantics\n",
      "learning, automatically learning useful representations of the input text. Finding\n",
      "representation\n",
      "learning\n",
      "such self-supervised ways to learn representations of language, instead of creat-\n",
      "ing representations by hand via feature engineering, is an important principle of\n",
      "modern NLP (Bengio et al., 2013).\n",
      "page_content and meta data  2\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "5.1\n",
      "Lexical Semantics\n",
      "Let‚Äôs begin by introducing some basic principles of word meaning. How should\n",
      "we represent the meaning of a word? In the n-gram models of Chapter 3, and in\n",
      "classical NLP applications, our only representation of a word is as a string of letters,\n",
      "or an index in a vocabulary list. This representation is not that different from a\n",
      "tradition in philosophy, perhaps you‚Äôve seen it in introductory logic classes, in which\n",
      "the meaning of words is represented by just spelling the word with small capital\n",
      "letters; representing the meaning of ‚Äúdog‚Äù as DOG, and ‚Äúcat‚Äù as CAT, or by using an\n",
      "apostrophe (DOG‚Äô).\n",
      "Representing the meaning of a word by capitalizing it is a pretty unsatisfactory\n",
      "model. You might have seen a version of a joke due originally to semanticist Barbara\n",
      "Partee (Carlson, 1977):\n",
      "Q: What‚Äôs the meaning of life?\n",
      "A: LIFE‚Äô\n",
      "Surely we can do better than this! After all, we‚Äôll want a model of word meaning\n",
      "page_content and meta data  Partee (Carlson, 1977):\n",
      "Q: What‚Äôs the meaning of life?\n",
      "A: LIFE‚Äô\n",
      "Surely we can do better than this! After all, we‚Äôll want a model of word meaning\n",
      "to do all sorts of things for us. It should tell us that some words have similar mean-\n",
      "ings (cat is similar to dog), others are antonyms (cold is the opposite of hot), some\n",
      "have positive connotations (happy) while others have negative connotations (sad). It\n",
      "should represent the fact that the meanings of buy, sell, and pay offer differing per-\n",
      "spectives on the same underlying purchasing event. (If I buy something from you,\n",
      "you‚Äôve probably sold it to me, and I likely paid you.) More generally, a model of\n",
      "word meaning should allow us to draw inferences to address meaning-related tasks\n",
      "like question-answering or dialogue.\n",
      "In this section we summarize some of these desiderata, drawing on results in the\n",
      "linguistic study of word meaning, which is called lexical semantics; we‚Äôll return to\n",
      "lexical\n",
      "semantics\n",
      "page_content and meta data  In this section we summarize some of these desiderata, drawing on results in the\n",
      "linguistic study of word meaning, which is called lexical semantics; we‚Äôll return to\n",
      "lexical\n",
      "semantics\n",
      "and expand on this list in Appendix G and Chapter 21.\n",
      "Lemmas and Senses\n",
      "Let‚Äôs start by looking at how one word (we‚Äôll choose mouse)\n",
      "might be deÔ¨Åned in a dictionary (simpliÔ¨Åed from the online dictionary WordNet):\n",
      "mouse (N)\n",
      "1.\n",
      "any of numerous small rodents...\n",
      "2.\n",
      "a hand-operated device that controls a cursor...\n",
      "Here the form mouse is the lemma, also called the citation form. The form\n",
      "lemma\n",
      "citation form\n",
      "mouse would also be the lemma for the word mice; dictionaries don‚Äôt have separate\n",
      "deÔ¨Ånitions for inÔ¨Çected forms like mice. Similarly sing is the lemma for sing, sang,\n",
      "sung. In many languages the inÔ¨Ånitive form is used as the lemma for the verb, so\n",
      "Spanish dormir ‚Äúto sleep‚Äù is the lemma for duermes ‚Äúyou sleep‚Äù. The speciÔ¨Åc forms\n",
      "sung or carpets or sing or duermes are called wordforms.\n",
      "wordform\n",
      "page_content and meta data  Spanish dormir ‚Äúto sleep‚Äù is the lemma for duermes ‚Äúyou sleep‚Äù. The speciÔ¨Åc forms\n",
      "sung or carpets or sing or duermes are called wordforms.\n",
      "wordform\n",
      "As the example above shows, each lemma can have multiple meanings; the\n",
      "lemma mouse can refer to the rodent or the cursor control device. We call each\n",
      "of these aspects of the meaning of mouse a word sense. The fact that lemmas can\n",
      "be polysemous (have multiple senses) can make interpretation difÔ¨Åcult (is some-\n",
      "one who searches for ‚Äúmouse info‚Äù looking for a pet or a widget?). Chapter 10\n",
      "and Appendix G will discuss the problem of polysemy, and introduce word sense\n",
      "disambiguation, the task of determining which sense of a word is being used in a\n",
      "particular context.\n",
      "Synonymy\n",
      "One important component of word meaning is the relationship be-\n",
      "tween word senses. For example when one word has a sense whose meaning is\n",
      "page_content and meta data  5.1\n",
      "‚Ä¢\n",
      "LEXICAL SEMANTICS\n",
      "3\n",
      "identical to a sense of another word, or nearly identical, we say the two senses of\n",
      "those two words are synonyms. Synonyms include such pairs as\n",
      "synonym\n",
      "couch/sofa vomit/throw up Ô¨Ålbert/hazelnut car/automobile\n",
      "A more formal deÔ¨Ånition of synonymy (between words rather than senses) is that\n",
      "two words are synonymous if they are substitutable for one another in any sentence\n",
      "without changing the truth conditions of the sentence, the situations in which the\n",
      "sentence would be true.\n",
      "While substitutions between some pairs of words like car / automobile or wa-\n",
      "ter / H2O are truth preserving, the words are still not identical in meaning. Indeed,\n",
      "probably no two words are absolutely identical in meaning. One of the fundamental\n",
      "tenets of semantics, called the principle of contrast (Girard 1718, Br¬¥eal 1897, Clark\n",
      "principle of\n",
      "contrast\n",
      "1987), states that a difference in linguistic form is always associated with some dif-\n",
      "page_content and meta data  tenets of semantics, called the principle of contrast (Girard 1718, Br¬¥eal 1897, Clark\n",
      "principle of\n",
      "contrast\n",
      "1987), states that a difference in linguistic form is always associated with some dif-\n",
      "ference in meaning. For example, the word H2O is used in scientiÔ¨Åc contexts and\n",
      "would be inappropriate in a hiking guide‚Äîwater would be more appropriate‚Äî and\n",
      "this genre difference is part of the meaning of the word. In practice, the word syn-\n",
      "onym is therefore used to describe a relationship of approximate or rough synonymy.\n",
      "Word Similarity\n",
      "While words don‚Äôt have many synonyms, most words do have\n",
      "lots of similar words. Cat is not a synonym of dog, but cats and dogs are certainly\n",
      "similar words. In moving from synonymy to similarity, it will be useful to shift from\n",
      "talking about relations between word senses (like synonymy) to relations between\n",
      "words (like similarity). Dealing with words avoids having to commit to a particular\n",
      "page_content and meta data  talking about relations between word senses (like synonymy) to relations between\n",
      "words (like similarity). Dealing with words avoids having to commit to a particular\n",
      "representation of word senses, which will turn out to simplify our task.\n",
      "The notion of word similarity is very useful in larger semantic tasks. Knowing\n",
      "similarity\n",
      "how similar two words are can help in computing how similar the meaning of two\n",
      "phrases or sentences are, a very important component of tasks like question answer-\n",
      "ing, paraphrasing, and summarization. One way of getting values for word similarity\n",
      "is to ask humans to judge how similar one word is to another. A number of datasets\n",
      "have resulted from such experiments. For example the SimLex-999 dataset (Hill\n",
      "et al., 2015) gives values on a scale from 0 to 10, like the examples below, which\n",
      "range from near-synonyms (vanish, disappear) to pairs that scarcely seem to have\n",
      "anything in common (hole, agreement):\n",
      "vanish\n",
      "disappear\n",
      "9.8\n",
      "belief\n",
      "impression 5.95\n",
      "muscle bone\n",
      "3.65\n",
      "page_content and meta data  range from near-synonyms (vanish, disappear) to pairs that scarcely seem to have\n",
      "anything in common (hole, agreement):\n",
      "vanish\n",
      "disappear\n",
      "9.8\n",
      "belief\n",
      "impression 5.95\n",
      "muscle bone\n",
      "3.65\n",
      "modest Ô¨Çexible\n",
      "0.98\n",
      "hole\n",
      "agreement\n",
      "0.3\n",
      "Word Relatedness\n",
      "The meaning of two words can be related in ways other than\n",
      "similarity. One such class of connections is called word relatedness (Budanitsky\n",
      "relatedness\n",
      "and Hirst, 2006), also traditionally called word association in psychology.\n",
      "association\n",
      "Consider the meanings of the words coffee and cup. Coffee is not similar to cup;\n",
      "they share practically no features (coffee is a plant or a beverage, while a cup is a\n",
      "manufactured object with a particular shape). But coffee and cup are clearly related;\n",
      "they are associated by co-participating in an everyday event (the event of drinking\n",
      "coffee out of a cup). Similarly scalpel and surgeon are not similar but are related\n",
      "eventively (a surgeon tends to make use of a scalpel).\n",
      "page_content and meta data  coffee out of a cup). Similarly scalpel and surgeon are not similar but are related\n",
      "eventively (a surgeon tends to make use of a scalpel).\n",
      "One common kind of relatedness between words is if they belong to the same\n",
      "semantic Ô¨Åeld. A semantic Ô¨Åeld is a set of words which cover a particular semantic\n",
      "semantic Ô¨Åeld\n",
      "domain and bear structured relations with each other. For example, words might be\n",
      "page_content and meta data  4\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "related by being in the semantic Ô¨Åeld of hospitals (surgeon, scalpel, nurse, anes-\n",
      "thetic, hospital), restaurants (waiter, menu, plate, food, chef), or houses (door, roof,\n",
      "kitchen, family, bed). Semantic Ô¨Åelds are also related to topic models, like Latent\n",
      "topic models\n",
      "Dirichlet Allocation, LDA, which apply unsupervised learning on large sets of texts\n",
      "to induce sets of associated words from text. Semantic Ô¨Åelds and topic models are\n",
      "very useful tools for discovering topical structure in documents.\n",
      "In Appendix G we‚Äôll introduce more relations between senses like hypernymy\n",
      "or IS-A, antonymy (opposites) and meronymy (part-whole relations).\n",
      "Connotation\n",
      "Finally, words have affective meanings or connotations. The word\n",
      "connotations\n",
      "connotation has different meanings in different Ô¨Åelds, but here we use it to mean the\n",
      "aspects of a word‚Äôs meaning that are related to a writer or reader‚Äôs emotions, senti-\n",
      "page_content and meta data  connotations\n",
      "connotation has different meanings in different Ô¨Åelds, but here we use it to mean the\n",
      "aspects of a word‚Äôs meaning that are related to a writer or reader‚Äôs emotions, senti-\n",
      "ment, opinions, or evaluations. For example some words have positive connotations\n",
      "(wonderful) while others have negative connotations (dreary). Even words whose\n",
      "meanings are similar in other ways can vary in connotation; consider the difference\n",
      "in connotations between fake, knockoff, forgery, on the one hand, and copy, replica,\n",
      "reproduction on the other, or innocent (positive connotation) and naive (negative\n",
      "connotation). Some words describe positive evaluation (great, love) and others neg-\n",
      "ative evaluation (terrible, hate). Positive or negative evaluation language is called\n",
      "sentiment, as we saw in Appendix K, and word sentiment plays a role in impor-\n",
      "sentiment\n",
      "tant tasks like sentiment analysis, stance detection, and applications of NLP to the\n",
      "language of politics and consumer reviews.\n",
      "page_content and meta data  sentiment\n",
      "tant tasks like sentiment analysis, stance detection, and applications of NLP to the\n",
      "language of politics and consumer reviews.\n",
      "Early work on affective meaning (Osgood et al., 1957) found that words varied\n",
      "along three important dimensions of affective meaning:\n",
      "valence: the pleasantness of the stimulus\n",
      "arousal: the intensity of emotion provoked by the stimulus\n",
      "dominance: the degree of control exerted by the stimulus\n",
      "Thus words like happy or satisÔ¨Åed are high on valence, while unhappy or an-\n",
      "noyed are low on valence. Excited is high on arousal, while calm is low on arousal.\n",
      "Controlling is high on dominance, while awed or inÔ¨Çuenced are low on dominance.\n",
      "Each word is thus represented by three numbers, corresponding to its value on each\n",
      "of the three dimensions:\n",
      "Valence Arousal Dominance\n",
      "courageous 8.0\n",
      "5.5\n",
      "7.4\n",
      "music\n",
      "7.7\n",
      "5.6\n",
      "6.5\n",
      "heartbreak\n",
      "2.5\n",
      "5.7\n",
      "3.6\n",
      "cub\n",
      "6.7\n",
      "4.0\n",
      "4.2\n",
      "Osgood et al. (1957) noticed that in using these 3 numbers to represent the\n",
      "page_content and meta data  Valence Arousal Dominance\n",
      "courageous 8.0\n",
      "5.5\n",
      "7.4\n",
      "music\n",
      "7.7\n",
      "5.6\n",
      "6.5\n",
      "heartbreak\n",
      "2.5\n",
      "5.7\n",
      "3.6\n",
      "cub\n",
      "6.7\n",
      "4.0\n",
      "4.2\n",
      "Osgood et al. (1957) noticed that in using these 3 numbers to represent the\n",
      "meaning of a word, the model was representing each word as a point in a three-\n",
      "dimensional space, a vector whose three dimensions corresponded to the word‚Äôs\n",
      "rating on the three scales. This revolutionary idea that word meaning could be rep-\n",
      "resented as a point in space (e.g., that part of the meaning of heartbreak can be\n",
      "represented as the point [2.5,5.7,3.6]) was the Ô¨Årst expression of the vector seman-\n",
      "tics models that we introduce next.\n",
      "5.2\n",
      "Vector Semantics: The Intuition\n",
      "Vector semantics is the standard way to represent word meaning in NLP, helping\n",
      "vector\n",
      "semantics\n",
      "page_content and meta data  5.2\n",
      "‚Ä¢\n",
      "VECTOR SEMANTICS: THE INTUITION\n",
      "5\n",
      "us model many of the aspects of word meaning we saw in the previous section. The\n",
      "roots of the model lie in the 1950s when two big ideas converged: Osgood‚Äôs 1957\n",
      "idea mentioned above to use a point in three-dimensional space to represent the\n",
      "connotation of a word, and the proposal by linguists like Joos (1950), Harris (1954),\n",
      "and Firth (1957) to deÔ¨Åne the meaning of a word by its distribution in language\n",
      "use, meaning its neighboring words or grammatical environments. Their idea was\n",
      "that two words that occur in very similar distributions (whose neighboring words are\n",
      "similar) have similar meanings.\n",
      "For example, suppose you didn‚Äôt know the meaning of the word ongchoi (a re-\n",
      "cent borrowing from Cantonese) but you see it in the following contexts:\n",
      "(5.1) Ongchoi is delicious sauteed with garlic.\n",
      "(5.2) Ongchoi is superb over rice.\n",
      "(5.3) ...ongchoi leaves with salty sauces...\n",
      "And suppose that you had seen many of these context words in other contexts:\n",
      "page_content and meta data  (5.2) Ongchoi is superb over rice.\n",
      "(5.3) ...ongchoi leaves with salty sauces...\n",
      "And suppose that you had seen many of these context words in other contexts:\n",
      "(5.4) ...spinach sauteed with garlic over rice...\n",
      "(5.5) ...chard stems and leaves are delicious...\n",
      "(5.6) ...collard greens and other salty leafy greens\n",
      "The fact that ongchoi occurs with words like rice and garlic and delicious and\n",
      "salty, as do words like spinach, chard, and collard greens might suggest that ongchoi\n",
      "is a leafy green similar to these other leafy greens.1 We can implement the same\n",
      "intuition computationally by just counting words in the context of ongchoi.\n",
      "Figure 5.1\n",
      "A two-dimensional (t-SNE) visualization of 200-dimensional word2vec em-\n",
      "beddings for some words close to the word sweet, showing that words with similar mean-\n",
      "ings are nearby in space. Visualization created using the TensorBoard Embedding Projector\n",
      "https://projector.tensorflow.org/.\n",
      "page_content and meta data  ings are nearby in space. Visualization created using the TensorBoard Embedding Projector\n",
      "https://projector.tensorflow.org/.\n",
      "The idea of vector semantics is to represent a word as a point in a multidimen-\n",
      "sional semantic space that is derived (in different ways we‚Äôll see) from the distri-\n",
      "butions of word neighbors. Vectors for representing words are called embeddings.\n",
      "embeddings\n",
      "The word ‚Äúembedding‚Äù derives historically from its mathematical sense as a map-\n",
      "ping from one space or structure to another, although the meaning has shifted; see\n",
      "the end of the chapter.\n",
      "Fig. 5.1 shows a visualization of embeddings learned by the word2vec algorithm,\n",
      "showing the location of selected words (neighbors of ‚Äúsweet‚Äù) projected down from\n",
      "1\n",
      "It‚Äôs in fact Ipomoea aquatica, a relative of morning glory sometimes called water spinach in English.\n",
      "page_content and meta data  6\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "200-dimensional space into a 2-dimensional space. Note that the nearest neighbors\n",
      "of sweet are semantically related words like honey, candy, juice, chocolate. This idea\n",
      "that similar words are near each other in high-dimensional space is an important\n",
      "that offers enormous power to language models and other NLP applications. For\n",
      "example the sentiment classiÔ¨Åers of Chapter 4 depend on the same words appearing\n",
      "in the training and test sets. But by representing words as embeddings, a classiÔ¨Åer\n",
      "can assign sentiment as long as it sees some words with similar meanings. And as\n",
      "we‚Äôll see, vector semantic models like the ones showed in Fig. 5.1 can be learned\n",
      "automatically from text without supervision.\n",
      "In this chapter we‚Äôll begin with a simple pedagogical model of embeddings in\n",
      "which the meaning of a word is deÔ¨Åned by a vector with the counts of nearby words.\n",
      "We introduce this model as a helpful way to understand the concept of vectors and\n",
      "page_content and meta data  which the meaning of a word is deÔ¨Åned by a vector with the counts of nearby words.\n",
      "We introduce this model as a helpful way to understand the concept of vectors and\n",
      "what it means for a vector to be a representation of word meaning, but more sophis-\n",
      "ticated variants like the tf-idf model we will introduce in Chapter 11 are important\n",
      "methods you should understand. We will see that this method results in very long\n",
      "vectors that are sparse, i.e. mostly zeros (since most words simply never occur in the\n",
      "context of others). We‚Äôll then introduce the word2vec model family for constructing\n",
      "short, dense vectors that have even more useful semantic properties.\n",
      "We‚Äôll also introduce the cosine, the standard way to use embeddings to com-\n",
      "pute semantic similarity, between two words, two sentences, or two documents, an\n",
      "important tool in practical applications.\n",
      "5.3\n",
      "Simple count-based embeddings\n",
      "‚ÄúThe most important attributes of a vector in 3-space are {Location, Location, Location}‚Äù\n",
      "page_content and meta data  important tool in practical applications.\n",
      "5.3\n",
      "Simple count-based embeddings\n",
      "‚ÄúThe most important attributes of a vector in 3-space are {Location, Location, Location}‚Äù\n",
      "Randall Munroe, the hover from https://xkcd.com/2358/\n",
      "Let‚Äôs now introduce the Ô¨Årst way to compute word vector embeddings. This sim-\n",
      "plest vector model of meaning is based on the co-occurrence matrix, a way of rep-\n",
      "resenting how often words co-occur. We‚Äôll deÔ¨Åne a particular kind of co-occurrence\n",
      "matrix, the word-context matrix, in which each row in the matrix represents a word\n",
      "word-context\n",
      "matrix\n",
      "in the vocabulary and each column represents how often each other word in the vo-\n",
      "cabulary appears nearby. This matrix is thus of dimensionality |V| √ó |V| and each\n",
      "cell records the number of times the row (target) word and the column (context)\n",
      "word co-occur nearby in some training corpus.\n",
      "What do we mean by ‚Äònearby‚Äô? We could implement various methods, but let‚Äôs\n",
      "page_content and meta data  word co-occur nearby in some training corpus.\n",
      "What do we mean by ‚Äònearby‚Äô? We could implement various methods, but let‚Äôs\n",
      "start with a very simple one: a context window around the word, let‚Äôs say of 4 words\n",
      "to the left and 4 words to the right. If we do that, each cell will represents the\n",
      "number of times (in some training corpus) the column word occurs in such a ¬±4\n",
      "word window around the row word.\n",
      "Let‚Äôs see how this works for 4 words: cherry, strawberry, digital, and informa-\n",
      "tion. For each word we took a single instance from a corpus, and we show the ¬±4\n",
      "word window from that instance:\n",
      "is traditionally followed by cherry\n",
      "pie, a traditional dessert\n",
      "often mixed, such as strawberry\n",
      "rhubarb pie. Apple pie\n",
      "computer peripherals and personal digital\n",
      "assistants. These devices usually\n",
      "a computer. This includes information available on the internet\n",
      "If we then take every occurrence of each word in a large corpus and count the\n",
      "page_content and meta data  assistants. These devices usually\n",
      "a computer. This includes information available on the internet\n",
      "If we then take every occurrence of each word in a large corpus and count the\n",
      "context words around it, we get a word-context co-occurrence matrix. The full word-\n",
      "page_content and meta data  5.3\n",
      "‚Ä¢\n",
      "SIMPLE COUNT-BASED EMBEDDINGS\n",
      "7\n",
      "context co-occurrence matrix is very large, because for each word in the vocabulary\n",
      "(since |V|) we have to count how often it occurs with every other word in the vo-\n",
      "cabulary, hence dimensionality |V|√ó|V|. Let‚Äôs therefore instead sketch the process\n",
      "on a smaller scale. Imagine that we are going to look at only the 4 words, and only\n",
      "consider the following 3 context words: a, computer, and pie. Furthermore let‚Äôs\n",
      "assume we only count occurrences in the mini-corpus above.\n",
      "So before looking at Fig. 5.2, compute by hand the counts for these 3 context\n",
      "words for the four words cherry, strawberry, digital, and information.\n",
      "a\n",
      "computer\n",
      "pie\n",
      "cherry\n",
      "1\n",
      "0\n",
      "1\n",
      "strawberry\n",
      "0\n",
      "0\n",
      "2\n",
      "digital\n",
      "0\n",
      "1\n",
      "0\n",
      "information\n",
      "1\n",
      "1\n",
      "0\n",
      "Figure 5.2\n",
      "Co-occurrence vectors for four words with counts from the 4 windows above,\n",
      "showing just 3 of the potential context word dimensions. The vector for cherry is outlined in\n",
      "page_content and meta data  0\n",
      "information\n",
      "1\n",
      "1\n",
      "0\n",
      "Figure 5.2\n",
      "Co-occurrence vectors for four words with counts from the 4 windows above,\n",
      "showing just 3 of the potential context word dimensions. The vector for cherry is outlined in\n",
      "red. Note that a real vector would have vastly more dimensions and thus be even sparser.\n",
      "Hopefully your count matches what is shown in Fig. 5.2, so that each cell repre-\n",
      "sents the number of times a particular word (deÔ¨Åned by the row) occurs in a partic-\n",
      "ular context (deÔ¨Åned by the word column).\n",
      "Each row, then, is a vector representing a word. To review some basic linear\n",
      "algebra, a vector is, at heart, just a list or array of numbers. So cherry is represented\n",
      "vector\n",
      "as the list [1,0,1] (the Ô¨Årst row vector in Fig. 5.2) and information is represented as\n",
      "the list [1,1,0] (the fourth row vector).\n",
      "A vector space is a collection of vectors, and is characterized by its dimension.\n",
      "vector space\n",
      "dimension\n",
      "Vectors in a 3-dimensional vector space have an element for each dimension of the\n",
      "page_content and meta data  A vector space is a collection of vectors, and is characterized by its dimension.\n",
      "vector space\n",
      "dimension\n",
      "Vectors in a 3-dimensional vector space have an element for each dimension of the\n",
      "space. We will loosely refer to a vector in a 3-dimensional space as a 3-dimensional\n",
      "vector, with one element along each dimension. In the example in Fig. 5.2, we‚Äôve\n",
      "chosen to make the document vectors of dimension 3, just so they Ô¨Åt on the page; in\n",
      "real term-document matrices, the document vectors would have dimensionality |V|,\n",
      "the vocabulary size.\n",
      "The ordering of the numbers in a vector space indicates the different dimensions\n",
      "on which documents vary. The third dimension for all these vectors corresponds\n",
      "to the number of times pie occurs in the context. The second dimension for all of\n",
      "them corresponds to the number of times the word computer occurs. Notice that\n",
      "the vectors for information and digital have the same value (1) for this ‚Äúcomputer‚Äù\n",
      "dimension.\n",
      "page_content and meta data  them corresponds to the number of times the word computer occurs. Notice that\n",
      "the vectors for information and digital have the same value (1) for this ‚Äúcomputer‚Äù\n",
      "dimension.\n",
      "In reality, we don‚Äôt compute word vectors on a single context window. Instead,\n",
      "we compute them over an entire corpus. Let‚Äôs see what some real counts look like.\n",
      "Let‚Äôs look at some vectors computed in this way. Fig. 5.3 shows a subset of the\n",
      "word-word co-occurrence matrix for these four words, where, again because it‚Äôs\n",
      "impossible to visualize all |V| possible context words on the page of this textbook,\n",
      "we show a subset of 6 of the dimensions, with counts computed from the Wikipedia\n",
      "corpus (Davies, 2015).\n",
      "Note in Fig. 5.3 that the two words cherry and strawberry are more similar to\n",
      "each other (both pie and sugar tend to occur in their window) than they are to other\n",
      "words like digital; conversely, digital and information are more similar to each other\n",
      "than, say, to strawberry.\n",
      "page_content and meta data  each other (both pie and sugar tend to occur in their window) than they are to other\n",
      "words like digital; conversely, digital and information are more similar to each other\n",
      "than, say, to strawberry.\n",
      "We can think of the vector for a document as a point in |V|-dimensional space;\n",
      "thus the documents in Fig. 5.3 are points in 3-dimensional space. Fig. 5.4 shows a\n",
      "spatial visualization.\n",
      "page_content and meta data  8\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "aardvark\n",
      "...\n",
      "computer\n",
      "data\n",
      "result\n",
      "pie\n",
      "sugar\n",
      "...\n",
      "cherry\n",
      "0\n",
      "...\n",
      "2\n",
      "8\n",
      "9\n",
      "442\n",
      "25\n",
      "...\n",
      "strawberry\n",
      "0\n",
      "...\n",
      "0\n",
      "0\n",
      "1\n",
      "60\n",
      "19\n",
      "...\n",
      "digital\n",
      "0\n",
      "...\n",
      "1670\n",
      "1683\n",
      "85\n",
      "5\n",
      "4\n",
      "...\n",
      "information\n",
      "0\n",
      "...\n",
      "3325\n",
      "3982\n",
      "378\n",
      "5\n",
      "13\n",
      "...\n",
      "Figure 5.3\n",
      "Co-occurrence vectors for four words in the Wikipedia corpus, showing six of\n",
      "the dimensions (hand-picked for pedagogical purposes). The vector for digital is outlined in\n",
      "red. Note that a real vector would have vastly more dimensions and thus be much sparser, i.e.\n",
      "would have zero values in most dimensions.\n",
      "1000 2000 3000 4000\n",
      "1000\n",
      "2000\n",
      "digital\n",
      " [1683,1670]\n",
      "computer\n",
      " data\n",
      "information\n",
      " [3982,3325] \n",
      "3000\n",
      "4000\n",
      "Figure 5.4\n",
      "A spatial visualization of word vectors for digital and information, showing just\n",
      "two of the dimensions, corresponding to the words data and computer.\n",
      "Note that |V|, the dimensionality of the vector, is generally the size of the vo-\n",
      "cabulary, often between 10,000 and 50,000 words (using the most frequent words\n",
      "page_content and meta data  Note that |V|, the dimensionality of the vector, is generally the size of the vo-\n",
      "cabulary, often between 10,000 and 50,000 words (using the most frequent words\n",
      "in the training corpus; keeping words after about the most frequent 50,000 or so is\n",
      "generally not helpful). Since most of these numbers are zero these are sparse vector\n",
      "representations; there are efÔ¨Åcient algorithms for storing and computing with sparse\n",
      "matrices.\n",
      "It‚Äôs also possible to applying various kinds of weighting functions to the counts\n",
      "in these cells. The most popular such weighting is tf-idf, which we‚Äôll introduce in\n",
      "Chapter 11, but there have historically been a wide variety of other weightings.\n",
      "Now that we have some intuitions, let‚Äôs move on to examine the details of com-\n",
      "puting word similarity.\n",
      "5.4\n",
      "Cosine for measuring similarity\n",
      "To measure similarity between two target words v and w, we need a metric that\n",
      "takes two vectors (of the same dimensionality, either both with words as dimensions,\n",
      "page_content and meta data  5.4\n",
      "Cosine for measuring similarity\n",
      "To measure similarity between two target words v and w, we need a metric that\n",
      "takes two vectors (of the same dimensionality, either both with words as dimensions,\n",
      "hence of length |V|, or both with documents as dimensions, of length |D|) and gives\n",
      "a measure of their similarity. By far the most common similarity metric is the cosine\n",
      "of the angle between the vectors.\n",
      "The cosine‚Äîlike most measures for vector similarity used in NLP‚Äîis based on\n",
      "the dot product operator from linear algebra, also called the inner product:\n",
      "dot product\n",
      "inner product\n",
      "dot product(v,w) = v ¬∑w =\n",
      "N\n",
      "X\n",
      "i=1\n",
      "viwi = v1w1 +v2w2 +...+vNwN\n",
      "(5.7)\n",
      "The dot product acts as a similarity metric because it will tend to be high just when\n",
      "the two vectors have large values in the same dimensions. Alternatively, vectors that\n",
      "page_content and meta data  5.4\n",
      "‚Ä¢\n",
      "COSINE FOR MEASURING SIMILARITY\n",
      "9\n",
      "have zeros in different dimensions‚Äîorthogonal vectors‚Äîwill have a dot product of\n",
      "0, representing their strong dissimilarity.\n",
      "This raw dot product, however, has a problem as a similarity metric: it favors\n",
      "long vectors. The vector length is deÔ¨Åned as\n",
      "vector length\n",
      "|v| =\n",
      "v\n",
      "u\n",
      "u\n",
      "t\n",
      "N\n",
      "X\n",
      "i=1\n",
      "v2\n",
      "i\n",
      "(5.8)\n",
      "The dot product is higher if a vector is longer, with higher values in each dimension.\n",
      "More frequent words have longer vectors, since they tend to co-occur with more\n",
      "words and have higher co-occurrence values with each of them. The raw dot product\n",
      "thus will be higher for frequent words. But this is a problem; we‚Äôd like a similarity\n",
      "metric that tells us how similar two words are regardless of their frequency.\n",
      "We modify the dot product to normalize for the vector length by dividing the\n",
      "dot product by the lengths of each of the two vectors. This normalized dot product\n",
      "turns out to be the same as the cosine of the angle between the two vectors, following\n",
      "page_content and meta data  dot product by the lengths of each of the two vectors. This normalized dot product\n",
      "turns out to be the same as the cosine of the angle between the two vectors, following\n",
      "from the deÔ¨Ånition of the dot product between two vectors a and b:\n",
      "a¬∑b = |a||b|cosŒ∏\n",
      "a¬∑b\n",
      "|a||b| = cosŒ∏\n",
      "(5.9)\n",
      "The cosine similarity metric between two vectors v and w thus can be computed as:\n",
      "cosine\n",
      "cosine(v,w) = v ¬∑w\n",
      "|v||w| =\n",
      "N\n",
      "X\n",
      "i=1\n",
      "viwi\n",
      "v\n",
      "u\n",
      "u\n",
      "t\n",
      "N\n",
      "X\n",
      "i=1\n",
      "v2\n",
      "i\n",
      "v\n",
      "u\n",
      "u\n",
      "t\n",
      "N\n",
      "X\n",
      "i=1\n",
      "w2\n",
      "i\n",
      "(5.10)\n",
      "For some applications we pre-normalize each vector, by dividing it by its length,\n",
      "creating a unit vector of length 1. Thus we could compute a unit vector from a by\n",
      "unit vector\n",
      "dividing it by |a|. For unit vectors, the dot product is the same as the cosine.\n",
      "The cosine value ranges from 1 for vectors pointing in the same direction, through\n",
      "0 for orthogonal vectors, to -1 for vectors pointing in opposite directions. But since\n",
      "raw frequency values are non-negative, the cosine for these vectors ranges from 0‚Äì1.\n",
      "page_content and meta data  0 for orthogonal vectors, to -1 for vectors pointing in opposite directions. But since\n",
      "raw frequency values are non-negative, the cosine for these vectors ranges from 0‚Äì1.\n",
      "Let‚Äôs see how the cosine computes which of the words cherry or digital is closer\n",
      "in meaning to information, just using raw counts from the following shortened table:\n",
      "pie\n",
      "data computer\n",
      "cherry\n",
      "442\n",
      "8\n",
      "2\n",
      "digital\n",
      "5\n",
      "1683\n",
      "1670\n",
      "information\n",
      "5\n",
      "3982\n",
      "3325\n",
      "cos(cherry,information) =\n",
      "442‚àó5+8‚àó3982+2‚àó3325\n",
      "‚àö\n",
      "4422 +82 +22‚àö\n",
      "52 +39822 +33252 = .018\n",
      "cos(digital,information) =\n",
      "5‚àó5+1683‚àó3982+1670‚àó3325\n",
      "‚àö\n",
      "52 +16832 +16702‚àö\n",
      "52 +39822 +33252 = .996\n",
      "The model decides that information is way closer to digital than it is to cherry, a\n",
      "result that seems sensible. Fig. 5.5 shows a visualization.\n",
      "page_content and meta data  10\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "500\n",
      "digital\n",
      "cherry\n",
      "information\n",
      "Dimension 1: ‚Äòpie‚Äô\n",
      "Dimension 2: ‚Äòcomputer‚Äô\n",
      "Figure 5.5\n",
      "A (rough) graphical demonstration of cosine similarity, showing vectors for\n",
      "three words (cherry, digital, and information) in the two dimensional space deÔ¨Åned by counts\n",
      "of the words computer and pie nearby. The Ô¨Ågure doesn‚Äôt show the cosine, but it highlights the\n",
      "angles; note that the angle between digital and information is smaller than the angle between\n",
      "cherry and information. When two vectors are more similar, the cosine is larger but the angle\n",
      "is smaller; the cosine has its maximum (1) when the angle between two vectors is smallest\n",
      "(0‚ó¶); the cosine of all other angles is less than 1.\n",
      "can be used to compute word similarity, for tasks like Ô¨Ånding word paraphrases,\n",
      "tracking changes in word meaning, or automatically discovering meanings of words\n",
      "in different corpora. For example, we can Ô¨Ånd the 10 most similar words to any\n",
      "page_content and meta data  tracking changes in word meaning, or automatically discovering meanings of words\n",
      "in different corpora. For example, we can Ô¨Ånd the 10 most similar words to any\n",
      "target word w by computing the cosines between w and each of the |V| ‚àí1 other\n",
      "words, sorting, and looking at the top 10.\n",
      "5.5\n",
      "Word2vec\n",
      "In the previous sections we saw how to represent a word as a sparse, long vector with\n",
      "dimensions corresponding to words in the vocabulary. We now introduce a more\n",
      "powerful word representation: embeddings, short dense vectors. Unlike the vectors\n",
      "we‚Äôve seen so far, embeddings are short, with number of dimensions d ranging from\n",
      "50-1000, rather than the much larger vocabulary size |V|.These d dimensions don‚Äôt\n",
      "have a clear interpretation. And the vectors are dense: instead of vector entries\n",
      "being sparse, mostly-zero counts or functions of counts, the values will be real-\n",
      "valued numbers that can be negative.\n",
      "It turns out that dense vectors work better in every NLP task than sparse vectors.\n",
      "page_content and meta data  valued numbers that can be negative.\n",
      "It turns out that dense vectors work better in every NLP task than sparse vectors.\n",
      "While we don‚Äôt completely understand all the reasons for this, we have some intu-\n",
      "itions. Representing words as 300-dimensional dense vectors requires our classiÔ¨Åers\n",
      "to learn far fewer weights than if we represented words as 50,000-dimensional vec-\n",
      "tors, and the smaller parameter space possibly helps with generalization and avoid-\n",
      "ing overÔ¨Åtting. Dense vectors may also do a better job of capturing synonymy.\n",
      "For example, in a sparse vector representation, dimensions for synonyms like car\n",
      "and automobile dimension are distinct and unrelated; sparse vectors may thus fail\n",
      "to capture the similarity between a word with car as a neighbor and a word with\n",
      "automobile as a neighbor.\n",
      "In this section we introduce one method for computing embeddings: skip-gram\n",
      "skip-gram\n",
      "with negative sampling, sometimes called SGNS. The skip-gram algorithm is one\n",
      "SGNS\n",
      "page_content and meta data  automobile as a neighbor.\n",
      "In this section we introduce one method for computing embeddings: skip-gram\n",
      "skip-gram\n",
      "with negative sampling, sometimes called SGNS. The skip-gram algorithm is one\n",
      "SGNS\n",
      "of two algorithms in a software package called word2vec, and so sometimes the\n",
      "word2vec\n",
      "algorithm is loosely referred to as word2vec (Mikolov et al. 2013a, Mikolov et al.\n",
      "2013b). The word2vec methods are fast, efÔ¨Åcient to train, and easily available on-\n",
      "line with code and pretrained embeddings. Word2vec embeddings are static em-\n",
      "page_content and meta data  5.5\n",
      "‚Ä¢\n",
      "WORD2VEC\n",
      "11\n",
      "beddings, meaning that the method learns one Ô¨Åxed embedding for each word in the\n",
      "static\n",
      "embeddings\n",
      "vocabulary. In Chapter 10 we‚Äôll introduce methods for learning dynamic contextual\n",
      "embeddings like the popular family of BERT representations, in which the vector\n",
      "for each word is different in different contexts.\n",
      "The intuition of word2vec is that instead of counting how often each word w oc-\n",
      "curs near, say, apricot, we‚Äôll instead train a classiÔ¨Åer on a binary prediction task: ‚ÄúIs\n",
      "word w likely to show up near apricot?‚Äù We don‚Äôt actually care about this prediction\n",
      "task; instead we‚Äôll take the learned classiÔ¨Åer weights as the word embeddings.\n",
      "The revolutionary intuition here is that we can just use running text as implicitly\n",
      "supervised training data for such a classiÔ¨Åer; a word c that occurs near the target\n",
      "word apricot acts as gold ‚Äòcorrect answer‚Äô to the question ‚ÄúIs word c likely to show\n",
      "up near apricot?‚Äù This method, often called self-supervision, avoids the need for\n",
      "page_content and meta data  word apricot acts as gold ‚Äòcorrect answer‚Äô to the question ‚ÄúIs word c likely to show\n",
      "up near apricot?‚Äù This method, often called self-supervision, avoids the need for\n",
      "self-supervision\n",
      "any sort of hand-labeled supervision signal. This idea was Ô¨Årst proposed in the task\n",
      "of neural language modeling, when Bengio et al. (2003) and Collobert et al. (2011)\n",
      "showed that a neural language model (a neural network that learned to predict the\n",
      "next word from prior words) could just use the next word in running text as its\n",
      "supervision signal, and could be used to learn an embedding representation for each\n",
      "word as part of doing this prediction task.\n",
      "We‚Äôll see how to do neural networks in the next chapter, but word2vec is a\n",
      "much simpler model than the neural network language model, in two ways. First,\n",
      "word2vec simpliÔ¨Åes the task (making it binary classiÔ¨Åcation instead of word pre-\n",
      "diction). Second, word2vec simpliÔ¨Åes the architecture (training a logistic regression\n",
      "page_content and meta data  word2vec simpliÔ¨Åes the task (making it binary classiÔ¨Åcation instead of word pre-\n",
      "diction). Second, word2vec simpliÔ¨Åes the architecture (training a logistic regression\n",
      "classiÔ¨Åer instead of a multi-layer neural network with hidden layers that demand\n",
      "more sophisticated training algorithms). The intuition of skip-gram is:\n",
      "1. Treat the target word and a neighboring context word as positive examples.\n",
      "2. Randomly sample other words in the lexicon to get negative samples.\n",
      "3. Use logistic regression to train a classiÔ¨Åer to distinguish those two cases.\n",
      "4. Use the learned weights as the embeddings.\n",
      "5.5.1\n",
      "The classiÔ¨Åer\n",
      "Let‚Äôs start by thinking about the classiÔ¨Åcation task, and then turn to how to train.\n",
      "Imagine a sentence like the following, with a target word apricot, and assume we‚Äôre\n",
      "using a window of ¬±2 context words:\n",
      "... lemon,\n",
      "a [tablespoon of apricot jam,\n",
      "a] pinch ...\n",
      "c1\n",
      "c2\n",
      "w\n",
      "c3\n",
      "c4\n",
      "Our goal is to train a classiÔ¨Åer such that, given a tuple (w,c) of a target word\n",
      "page_content and meta data  using a window of ¬±2 context words:\n",
      "... lemon,\n",
      "a [tablespoon of apricot jam,\n",
      "a] pinch ...\n",
      "c1\n",
      "c2\n",
      "w\n",
      "c3\n",
      "c4\n",
      "Our goal is to train a classiÔ¨Åer such that, given a tuple (w,c) of a target word\n",
      "w paired with a candidate context word c (for example (apricot, jam), or perhaps\n",
      "(apricot, aardvark)) it will return the probability that c is a real context word (true\n",
      "for jam, false for aardvark):\n",
      "P(+|w,c)\n",
      "(5.11)\n",
      "The probability that word c is not a real context word for w is just 1 minus\n",
      "Eq. 5.11:\n",
      "P(‚àí|w,c) = 1‚àíP(+|w,c)\n",
      "(5.12)\n",
      "How does the classiÔ¨Åer compute the probability P? The intuition of the skip-\n",
      "gram model is to base this probability on embedding similarity: a word is likely to\n",
      "page_content and meta data  12\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "occur near the target if its embedding vector is similar to the target embedding. To\n",
      "compute similarity between these dense embeddings, we rely on the intuition that\n",
      "two vectors are similar if they have a high dot product (after all, cosine is just a\n",
      "normalized dot product). In other words:\n",
      "Similarity(w,c) ‚âàc¬∑w\n",
      "(5.13)\n",
      "The dot product c ¬∑ w is not a probability, it‚Äôs just a number ranging from ‚àí‚àûto ‚àû\n",
      "(since the elements in word2vec embeddings can be negative, the dot product can be\n",
      "negative). To turn the dot product into a probability, we‚Äôll use the logistic or sigmoid\n",
      "function œÉ(x), the fundamental core of logistic regression:\n",
      "œÉ(x) =\n",
      "1\n",
      "1+exp(‚àíx)\n",
      "(5.14)\n",
      "We model the probability that word c is a real context word for target word w as:\n",
      "P(+|w,c) = œÉ(c¬∑w) =\n",
      "1\n",
      "1+exp(‚àíc¬∑w)\n",
      "(5.15)\n",
      "The sigmoid function returns a number between 0 and 1, but to make it a probability\n",
      "we‚Äôll also need the total probability of the two possible events (c is a context word,\n",
      "page_content and meta data  1\n",
      "1+exp(‚àíc¬∑w)\n",
      "(5.15)\n",
      "The sigmoid function returns a number between 0 and 1, but to make it a probability\n",
      "we‚Äôll also need the total probability of the two possible events (c is a context word,\n",
      "and c isn‚Äôt a context word) to sum to 1. We thus estimate the probability that word c\n",
      "is not a real context word for w as:\n",
      "P(‚àí|w,c) = 1‚àíP(+|w,c)\n",
      "= œÉ(‚àíc¬∑w) =\n",
      "1\n",
      "1+exp(c¬∑w)\n",
      "(5.16)\n",
      "Equation 5.15 gives us the probability for one word, but there are many context\n",
      "words in the window. Skip-gram makes the simplifying assumption that all context\n",
      "words are independent, allowing us to just multiply their probabilities:\n",
      "P(+|w,c1:L) =\n",
      "L\n",
      "Y\n",
      "i=1\n",
      "œÉ(ci ¬∑w)\n",
      "(5.17)\n",
      "logP(+|w,c1:L) =\n",
      "L\n",
      "X\n",
      "i=1\n",
      "logœÉ(ci ¬∑w)\n",
      "(5.18)\n",
      "In summary, skip-gram trains a probabilistic classiÔ¨Åer that, given a test target word\n",
      "w and its context window of L words c1:L, assigns a probability based on how similar\n",
      "this context window is to the target word. The probability is based on applying the\n",
      "page_content and meta data  w and its context window of L words c1:L, assigns a probability based on how similar\n",
      "this context window is to the target word. The probability is based on applying the\n",
      "logistic (sigmoid) function to the dot product of the embeddings of the target word\n",
      "with each context word. To compute this probability, we just need embeddings for\n",
      "each target word and context word in the vocabulary.\n",
      "Fig. 5.6 shows the intuition of the parameters we‚Äôll need. Skip-gram actually\n",
      "stores two embeddings for each word, one for the word as a target, and one for the\n",
      "word considered as context. Thus the parameters we need to learn are two matrices\n",
      "W and C, each containing an embedding for every one of the |V| words in the\n",
      "vocabulary V.2 Let‚Äôs now turn to learning these embeddings (which is the real goal\n",
      "of training this classiÔ¨Åer in the Ô¨Årst place).\n",
      "2\n",
      "In principle the target matrix and the context matrix could use different vocabularies, but we‚Äôll simplify\n",
      "by assuming one shared vocabulary V.\n",
      "page_content and meta data  5.5\n",
      "‚Ä¢\n",
      "WORD2VEC\n",
      "13\n",
      "1\n",
      "W\n",
      "C\n",
      "aardvark\n",
      "zebra\n",
      "zebra\n",
      "aardvark\n",
      "apricot\n",
      "apricot\n",
      "|V|\n",
      "|V|+1\n",
      "2|V|\n",
      "ùúΩ =\n",
      "target words\n",
      "context & noise\n",
      "words\n",
      "‚Ä¶\n",
      "‚Ä¶\n",
      "1..d\n",
      "‚Ä¶\n",
      "‚Ä¶\n",
      "Figure 5.6\n",
      "The embeddings learned by the skipgram model. The algorithm stores two em-\n",
      "beddings for each word, the target embedding (sometimes called the input embedding) and\n",
      "the context embedding (sometimes called the output embedding). The parameter Œ∏ that the al-\n",
      "gorithm learns is thus a matrix of 2|V| vectors, each of dimension d, formed by concatenating\n",
      "two matrices, the target embeddings W and the context+noise embeddings C.\n",
      "5.5.2\n",
      "Learning skip-gram embeddings\n",
      "The learning algorithm for skip-gram embeddings takes as input a corpus of text,\n",
      "and a chosen vocabulary size N. It begins by assigning a random embedding vector\n",
      "for each of the N vocabulary words, and then proceeds to iteratively shift the em-\n",
      "bedding of each word w to be more like the embeddings of words that occur nearby\n",
      "page_content and meta data  for each of the N vocabulary words, and then proceeds to iteratively shift the em-\n",
      "bedding of each word w to be more like the embeddings of words that occur nearby\n",
      "in texts, and less like the embeddings of words that don‚Äôt occur nearby. Let‚Äôs start\n",
      "by considering a single piece of training data:\n",
      "... lemon,\n",
      "a [tablespoon of apricot jam,\n",
      "a] pinch ...\n",
      "c1\n",
      "c2\n",
      "w\n",
      "c3\n",
      "c4\n",
      "This example has a target word w (apricot), and 4 context words in the L = ¬±2\n",
      "window, resulting in 4 positive training instances (on the left below):\n",
      "positive examples +\n",
      "w\n",
      "cpos\n",
      "apricot tablespoon\n",
      "apricot of\n",
      "apricot jam\n",
      "apricot a\n",
      "negative examples -\n",
      "w\n",
      "cneg\n",
      "w\n",
      "cneg\n",
      "apricot aardvark apricot seven\n",
      "apricot my\n",
      "apricot forever\n",
      "apricot where\n",
      "apricot dear\n",
      "apricot coaxial\n",
      "apricot if\n",
      "For training a binary classiÔ¨Åer we also need negative examples. In fact skip-\n",
      "gram with negative sampling (SGNS) uses more negative examples than positive\n",
      "examples (with the ratio between them set by a parameter k). So for each of these\n",
      "page_content and meta data  gram with negative sampling (SGNS) uses more negative examples than positive\n",
      "examples (with the ratio between them set by a parameter k). So for each of these\n",
      "(w,cpos) training instances we‚Äôll create k negative samples, each consisting of the\n",
      "target w plus a ‚Äònoise word‚Äô cneg. A noise word is a random word from the lexicon,\n",
      "constrained not to be the target word w. The table right above shows the setting\n",
      "where k = 2, so we‚Äôll have 2 negative examples in the negative training set ‚àífor\n",
      "each positive example w,cpos.\n",
      "The noise words are chosen according to their weighted unigram probability\n",
      "pŒ±(w), where Œ± is a weight. If we were sampling according to unweighted proba-\n",
      "bility P(w), it would mean that with unigram probability P(‚Äúthe‚Äù) we would choose\n",
      "the word the as a noise word, with unigram probability P(‚Äúaardvark‚Äù) we would\n",
      "choose aardvark, and so on. But in practice it is common to set Œ± = 0.75, i.e. use\n",
      "page_content and meta data  14\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "the weighting P3\n",
      "4 (w):\n",
      "PŒ±(w) =\n",
      "count(w)Œ±\n",
      "P\n",
      "w‚Ä≤ count(w‚Ä≤)Œ±\n",
      "(5.19)\n",
      "Setting Œ± = .75 gives better performance because it gives rare noise words slightly\n",
      "higher probability: for rare words, PŒ±(w) > P(w). To illustrate this intuition, it\n",
      "might help to work out the probabilities for an example with Œ± = .75 and two events,\n",
      "P(a) = 0.99 and P(b) = 0.01:\n",
      "PŒ±(a) =\n",
      ".99.75\n",
      ".99.75 +.01.75 = 0.97\n",
      "PŒ±(b) =\n",
      ".01.75\n",
      ".99.75 +.01.75 = 0.03\n",
      "(5.20)\n",
      "Thus using Œ± = .75 increases the probability of the rare event b from 0.01 to 0.03.\n",
      "Given the set of positive and negative training instances, and an initial set of\n",
      "embeddings, the goal of the learning algorithm is to adjust those embeddings to\n",
      "‚Ä¢ Maximize the similarity of the target word, context word pairs (w,cpos) drawn\n",
      "from the positive examples\n",
      "‚Ä¢ Minimize the similarity of the (w,cneg) pairs from the negative examples.\n",
      "If we consider one word/context pair (w,cpos) with its k noise words cneg1...cnegk,\n",
      "page_content and meta data  from the positive examples\n",
      "‚Ä¢ Minimize the similarity of the (w,cneg) pairs from the negative examples.\n",
      "If we consider one word/context pair (w,cpos) with its k noise words cneg1...cnegk,\n",
      "we can express these two goals as the following loss function L to be minimized\n",
      "(hence the ‚àí); here the Ô¨Årst term expresses that we want the classiÔ¨Åer to assign the\n",
      "real context word cpos a high probability of being a neighbor, and the second term\n",
      "expresses that we want to assign each of the noise words cnegi a high probability of\n",
      "being a non-neighbor, all multiplied because we assume independence:\n",
      "L = ‚àílog\n",
      "\"\n",
      "P(+|w,cpos)\n",
      "kY\n",
      "i=1\n",
      "P(‚àí|w,cnegi)\n",
      "#\n",
      "= ‚àí\n",
      "\"\n",
      "logP(+|w,cpos)+\n",
      "k\n",
      "X\n",
      "i=1\n",
      "logP(‚àí|w,cnegi)\n",
      "#\n",
      "= ‚àí\n",
      "\"\n",
      "logP(+|w,cpos)+\n",
      "k\n",
      "X\n",
      "i=1\n",
      "log\n",
      "\u00001‚àíP(+|w,cnegi)\n",
      "\u0001\n",
      "#\n",
      "= ‚àí\n",
      "\"\n",
      "logœÉ(cpos ¬∑w)+\n",
      "k\n",
      "X\n",
      "i=1\n",
      "logœÉ(‚àícnegi ¬∑w)\n",
      "#\n",
      "(5.21)\n",
      "That is, we want to maximize the dot product of the word with the actual context\n",
      "words, and minimize the dot products of the word with the k negative sampled non-\n",
      "neighbor words.\n",
      "page_content and meta data  #\n",
      "(5.21)\n",
      "That is, we want to maximize the dot product of the word with the actual context\n",
      "words, and minimize the dot products of the word with the k negative sampled non-\n",
      "neighbor words.\n",
      "We minimize this loss function using stochastic gradient descent. Fig. 5.7 shows\n",
      "the intuition of one step of learning.\n",
      "To get the gradient, we need to take the derivative of Eq. 5.21 with respect to\n",
      "the different embeddings. It turns out the derivatives are the following (we leave the\n",
      "page_content and meta data  5.5\n",
      "‚Ä¢\n",
      "WORD2VEC\n",
      "15\n",
      "W\n",
      "C\n",
      "move apricot and jam closer,\n",
      "increasing cpos z w\n",
      "aardvark\n",
      "move apricot and matrix apart\n",
      "decreasing cneg1 z w\n",
      "‚Äú‚Ä¶apricot jam‚Ä¶‚Äù\n",
      "w\n",
      "zebra\n",
      "zebra\n",
      "aardvark\n",
      "jam\n",
      "apricot\n",
      "cpos\n",
      "matrix\n",
      "Tolstoy\n",
      "move apricot and Tolstoy apart\n",
      "decreasing cneg2 z w\n",
      "!\n",
      "cneg1\n",
      "cneg2\n",
      "k=2\n",
      "Figure 5.7\n",
      "Intuition of one step of gradient descent. The skip-gram model tries to shift em-\n",
      "beddings so the target embeddings (here for apricot) are closer to (have a higher dot product\n",
      "with) context embeddings for nearby words (here jam) and further from (lower dot product\n",
      "with) context embeddings for noise words that don‚Äôt occur nearby (here Tolstoy and matrix).\n",
      "proof as an exercise at the end of the chapter):\n",
      "‚àÇL\n",
      "‚àÇcpos\n",
      "= [œÉ(cpos ¬∑w)‚àí1]w\n",
      "(5.22)\n",
      "‚àÇL\n",
      "‚àÇcneg\n",
      "= [œÉ(cneg ¬∑w)]w\n",
      "(5.23)\n",
      "‚àÇL\n",
      "‚àÇw = [œÉ(cpos ¬∑w)‚àí1]cpos +\n",
      "k\n",
      "X\n",
      "i=1\n",
      "[œÉ(cnegi ¬∑w)]cnegi\n",
      "(5.24)\n",
      "The update equations going from time step t to t + 1 in stochastic gradient descent\n",
      "are thus:\n",
      "ct+1\n",
      "pos\n",
      "= ct\n",
      "pos ‚àíŒ∑[œÉ(ct\n",
      "pos ¬∑wt)‚àí1]wt\n",
      "(5.25)\n",
      "ct+1\n",
      "neg = ct\n",
      "neg ‚àíŒ∑[œÉ(ct\n",
      "neg ¬∑wt)]wt\n",
      "page_content and meta data  (5.24)\n",
      "The update equations going from time step t to t + 1 in stochastic gradient descent\n",
      "are thus:\n",
      "ct+1\n",
      "pos\n",
      "= ct\n",
      "pos ‚àíŒ∑[œÉ(ct\n",
      "pos ¬∑wt)‚àí1]wt\n",
      "(5.25)\n",
      "ct+1\n",
      "neg = ct\n",
      "neg ‚àíŒ∑[œÉ(ct\n",
      "neg ¬∑wt)]wt\n",
      "(5.26)\n",
      "wt+1 = wt ‚àíŒ∑\n",
      "\"\n",
      "[œÉ(ct\n",
      "pos ¬∑wt)‚àí1]ct\n",
      "pos +\n",
      "k\n",
      "X\n",
      "i=1\n",
      "[œÉ(ct\n",
      "negi ¬∑wt)]ct\n",
      "negi\n",
      "#\n",
      "(5.27)\n",
      "Just as in logistic regression, then, the learning algorithm starts with randomly ini-\n",
      "tialized W and C matrices, and then walks through the training corpus using gradient\n",
      "descent to move W and C so as to minimize the loss in Eq. 5.21 by making the up-\n",
      "dates in (Eq. 5.25)-(Eq. 5.27).\n",
      "Recall that the skip-gram model learns two separate embeddings for each word i:\n",
      "the target embedding wi and the context embedding ci, stored in two matrices, the\n",
      "target\n",
      "embedding\n",
      "context\n",
      "embedding\n",
      "target matrix W and the context matrix C. It‚Äôs common to just add them together,\n",
      "representing word i with the vector wi +ci. Alternatively we can throw away the C\n",
      "matrix and just represent each word i by the vector wi.\n",
      "page_content and meta data  representing word i with the vector wi +ci. Alternatively we can throw away the C\n",
      "matrix and just represent each word i by the vector wi.\n",
      "As with the simple count-based methods like tf-idf, the context window size L\n",
      "affects the performance of skip-gram embeddings, and experiments often tune the\n",
      "parameter L on a devset.\n",
      "page_content and meta data  16\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "5.5.3\n",
      "Other kinds of static embeddings\n",
      "There are many kinds of static embeddings. An extension of word2vec, fasttext\n",
      "fasttext\n",
      "(Bojanowski et al., 2017), addresses a problem with word2vec as we have presented\n",
      "it so far: it has no good way to deal with unknown words‚Äîwords that appear in\n",
      "a test corpus but were unseen in the training corpus. A related problem is word\n",
      "sparsity, such as in languages with rich morphology, where some of the many forms\n",
      "for each noun and verb may only occur rarely. Fasttext deals with these problems\n",
      "by using subword models, representing each word as itself plus a bag of constituent\n",
      "n-grams, with special boundary symbols < and > added to each word. For example,\n",
      "with n = 3 the word where would be represented by the sequence <where> plus the\n",
      "character n-grams:\n",
      "<wh, whe, her, ere, re>\n",
      "Then a skipgram embedding is learned for each constituent n-gram, and the word\n",
      "page_content and meta data  character n-grams:\n",
      "<wh, whe, her, ere, re>\n",
      "Then a skipgram embedding is learned for each constituent n-gram, and the word\n",
      "where is represented by the sum of all of the embeddings of its constituent n-grams.\n",
      "Unknown words can then be presented only by the sum of the constituent n-grams.\n",
      "A fasttext open-source library, including pretrained embeddings for 157 languages,\n",
      "is available at https://fasttext.cc.\n",
      "Another very widely used static embedding model is GloVe (Pennington et al.,\n",
      "2014), short for Global Vectors, because the model is based on capturing global\n",
      "corpus statistics. GloVe is based on ratios of probabilities from the word-word co-\n",
      "occurrence matrix.\n",
      "It turns out that dense embeddings like word2vec actually have an elegant math-\n",
      "ematical relationship with count-based embeddings, in which word2vec can be seen\n",
      "as implicitly optimizing a function of a count matrix with a particular (PPMI) weight-\n",
      "ing (Levy and Goldberg, 2014c).\n",
      "5.6\n",
      "Visualizing Embeddings\n",
      "page_content and meta data  as implicitly optimizing a function of a count matrix with a particular (PPMI) weight-\n",
      "ing (Levy and Goldberg, 2014c).\n",
      "5.6\n",
      "Visualizing Embeddings\n",
      "‚ÄúI see well in many dimensions as long as the dimensions are around two.‚Äù\n",
      "The late economist Martin Shubik\n",
      "Visualizing embeddings is an important goal in helping understand, apply, and\n",
      "improve these models of word meaning. But how can we visualize a (for example)\n",
      "100-dimensional vector?\n",
      "WRIST\n",
      "ANKLE\n",
      "SHOULDER\n",
      "ARM\n",
      "LEG\n",
      "HAND\n",
      "FOOT\n",
      "HEAD\n",
      "NOSE\n",
      "FINGER\n",
      "TOE\n",
      "FACE\n",
      "EAR\n",
      "EYE\n",
      "TOOTH\n",
      "DOG\n",
      "CAT\n",
      "PUPPY\n",
      "KITTEN\n",
      "COW\n",
      "MOUSE\n",
      "TURTLE\n",
      "OYSTER\n",
      "LION\n",
      "BULL\n",
      "CHICAGO\n",
      "ATLANTA\n",
      "MONTREAL\n",
      "NASHVILLE\n",
      "TOKYO\n",
      "CHINA\n",
      "RUSSIA\n",
      "AFRICA\n",
      "ASIA\n",
      "EUROPE\n",
      "AMERICA\n",
      "BRAZIL\n",
      "MOSCOW\n",
      "FRANCE\n",
      "HAWAII\n",
      "The simplest way to visualize the meaning of a word\n",
      "w embedded in a space is to list the most similar words to\n",
      "w by sorting the vectors for all words in the vocabulary by\n",
      "their cosine with the vector for w. For example the 7 closest\n",
      "words to frog using a particular embeddings computed with\n",
      "page_content and meta data  w by sorting the vectors for all words in the vocabulary by\n",
      "their cosine with the vector for w. For example the 7 closest\n",
      "words to frog using a particular embeddings computed with\n",
      "the GloVe algorithm are: frogs, toad, litoria, leptodactyli-\n",
      "dae, rana, lizard, and eleutherodactylus (Pennington et al.,\n",
      "2014).\n",
      "Yet another visualization method is to use a clustering\n",
      "algorithm to show a hierarchical representation of which\n",
      "words are similar to others in the embedding space. The\n",
      "uncaptioned Ô¨Ågure on the left uses hierarchical clustering\n",
      "of some embedding vectors for nouns as a visualization\n",
      "method (Rohde et al., 2006).\n",
      "page_content and meta data  5.7\n",
      "‚Ä¢\n",
      "SEMANTIC PROPERTIES OF EMBEDDINGS\n",
      "17\n",
      "Probably the most common visualization method, how-\n",
      "ever, is to project the 100 dimensions of a word down into 2\n",
      "dimensions. Fig. 5.1 showed one such visualization, as does\n",
      "Fig. 5.9, using a projection method called t-SNE (van der\n",
      "Maaten and Hinton, 2008).\n",
      "5.7\n",
      "Semantic properties of embeddings\n",
      "In this section we brieÔ¨Çy summarize some of the semantic properties of embeddings\n",
      "that have been studied.\n",
      "Different types of similarity or association:\n",
      "One parameter of vector semantic\n",
      "models that is relevant to both sparse PPMI vectors and dense word2vec vectors is\n",
      "the size of the context window used to collect counts. This is generally between 1\n",
      "and 10 words on each side of the target word (for a total context of 2-20 words).\n",
      "The choice depends on the goals of the representation. Shorter context windows\n",
      "tend to lead to representations that are a bit more syntactic, since the information is\n",
      "page_content and meta data  The choice depends on the goals of the representation. Shorter context windows\n",
      "tend to lead to representations that are a bit more syntactic, since the information is\n",
      "coming from immediately nearby words. When the vectors are computed from short\n",
      "context windows, the most similar words to a target word w tend to be semantically\n",
      "similar words with the same parts of speech. When vectors are computed from long\n",
      "context windows, the highest cosine words to a target word w tend to be words that\n",
      "are topically related but not similar.\n",
      "For example Levy and Goldberg (2014a) showed that using skip-gram with a\n",
      "window of ¬±2, the most similar words to the word Hogwarts (from the Harry Potter\n",
      "series) were names of other Ô¨Åctional schools: Sunnydale (from Buffy the Vampire\n",
      "Slayer) or Evernight (from a vampire series). With a window of ¬±5, the most similar\n",
      "words to Hogwarts were other words topically related to the Harry Potter series:\n",
      "Dumbledore, Malfoy, and half-blood.\n",
      "page_content and meta data  words to Hogwarts were other words topically related to the Harry Potter series:\n",
      "Dumbledore, Malfoy, and half-blood.\n",
      "It‚Äôs also often useful to distinguish two kinds of similarity or association between\n",
      "words (Sch¬®utze and Pedersen, 1993). Two words have Ô¨Årst-order co-occurrence\n",
      "Ô¨Årst-order\n",
      "co-occurrence\n",
      "(sometimes called syntagmatic association) if they are typically nearby each other.\n",
      "Thus wrote is a Ô¨Årst-order associate of book or poem. Two words have second-order\n",
      "co-occurrence (sometimes called paradigmatic association) if they have similar\n",
      "second-order\n",
      "co-occurrence\n",
      "neighbors. Thus wrote is a second-order associate of words like said or remarked.\n",
      "Analogy/Relational Similarity:\n",
      "Another semantic property of embeddings is their\n",
      "ability to capture relational meanings. In an important early vector space model of\n",
      "cognition, Rumelhart and Abrahamson (1973) proposed the parallelogram model\n",
      "parallelogram\n",
      "model\n",
      "page_content and meta data  ability to capture relational meanings. In an important early vector space model of\n",
      "cognition, Rumelhart and Abrahamson (1973) proposed the parallelogram model\n",
      "parallelogram\n",
      "model\n",
      "for solving simple analogy problems of the form a is to b as a* is to what?. In such\n",
      "problems, a system is given a problem like apple:tree::grape:?, i.e., apple is to tree\n",
      "as grape is to\n",
      ", and must Ô¨Åll in the word vine. In the parallelogram model, il-\n",
      "lustrated in Fig. 5.8, the vector from the word apple to the word tree (= #   ¬ª\n",
      "tree‚àí#       ¬ª\n",
      "apple)\n",
      "is added to the vector for grape (#        ¬ª\n",
      "grape); the nearest word to that point is returned.\n",
      "In early work with sparse embeddings, scholars showed that sparse vector mod-\n",
      "els of meaning could solve such analogy problems (Turney and Littman, 2005),\n",
      "but the parallelogram method received more modern attention because of its suc-\n",
      "cess with word2vec or GloVe vectors (Mikolov et al. 2013c, Levy and Goldberg\n",
      "page_content and meta data  but the parallelogram method received more modern attention because of its suc-\n",
      "cess with word2vec or GloVe vectors (Mikolov et al. 2013c, Levy and Goldberg\n",
      "2014b, Pennington et al. 2014). For example, the result of the expression #     ¬ª\n",
      "king ‚àí\n",
      "#     ¬ª\n",
      "man + #            ¬ª\n",
      "woman is a vector close to #         ¬ª\n",
      "queen. Similarly, #      ¬ª\n",
      "Paris ‚àí#           ¬ª\n",
      "France + #     ¬ª\n",
      "Italy results\n",
      "in a vector that is close to #         ¬ª\n",
      "Rome. The embedding model thus seems to be extract-\n",
      "page_content and meta data  18\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "tree\n",
      "apple\n",
      "grape\n",
      "vine\n",
      "Figure 5.8\n",
      "The parallelogram model for analogy problems (Rumelhart and Abrahamson,\n",
      "1973): the location of #     ¬ª\n",
      "vine can be found by subtracting #       ¬ª\n",
      "apple from #   ¬ª\n",
      "tree and adding #       ¬ª\n",
      "grape.\n",
      "ing representations of relations like MALE-FEMALE, or CAPITAL-CITY-OF, or even\n",
      "COMPARATIVE/SUPERLATIVE, as shown in Fig. 5.9 from GloVe.\n",
      "(a)\n",
      "(b)\n",
      "Figure 5.9\n",
      "Relational properties of the GloVe vector space, shown by projecting vectors onto two dimensions.\n",
      "(a) #     ¬ª\n",
      "king‚àí#     ¬ª\n",
      "man+ #            ¬ª\n",
      "woman is close to #        ¬ª\n",
      "queen. (b) offsets seem to capture comparative and superlative morphology\n",
      "(Pennington et al., 2014).\n",
      "For a a : b :: a‚àó: b‚àóproblem, meaning the algorithm is given vectors a, b, and\n",
      "a‚àóand must Ô¨Ånd b‚àó, the parallelogram method is thus:\n",
      "ÀÜb‚àó= argmin\n",
      "x\n",
      "distance(x,b‚àía+a‚àó)\n",
      "(5.28)\n",
      "with some distance function, such as Euclidean distance.\n",
      "There are some caveats. For example, the closest value returned by the paral-\n",
      "page_content and meta data  ÀÜb‚àó= argmin\n",
      "x\n",
      "distance(x,b‚àía+a‚àó)\n",
      "(5.28)\n",
      "with some distance function, such as Euclidean distance.\n",
      "There are some caveats. For example, the closest value returned by the paral-\n",
      "lelogram algorithm in word2vec or GloVe embedding spaces is usually not in fact\n",
      "b* but one of the 3 input words or their morphological variants (i.e., cherry:red ::\n",
      "potato:x returns potato or potatoes instead of brown), so these must be explicitly\n",
      "excluded. Furthermore while embedding spaces perform well if the task involves\n",
      "frequent words, small distances, and certain relations (like relating countries with\n",
      "their capitals or verbs/nouns with their inÔ¨Çected forms), the parallelogram method\n",
      "with embeddings doesn‚Äôt work as well for other relations (Linzen 2016, Gladkova\n",
      "et al. 2016, Schluter 2018, Ethayarajh et al. 2019a), and indeed Peterson et al. (2020)\n",
      "argue that the parallelogram method is in general too simple to model the human\n",
      "cognitive process of forming analogies of this kind.\n",
      "page_content and meta data  5.8\n",
      "‚Ä¢\n",
      "BIAS AND EMBEDDINGS\n",
      "19\n",
      "5.7.1\n",
      "Embeddings and Historical Semantics\n",
      "Embeddings can also be a useful tool for studying how meaning changes over time,\n",
      "by computing multiple embedding spaces, each from texts written in a particular\n",
      "time period. For example Fig. 5.10 shows a visualization of changes in meaning in\n",
      "English words over the last two centuries, computed by building separate embedding\n",
      "spaces for each decade from historical corpora like Google n-grams (Lin et al., 2012)\n",
      "and the Corpus of Historical American English (Davies, 2012).\n",
      "Figure 5.10\n",
      "A t-SNE visualization of the semantic change of 3 words in English using\n",
      "word2vec vectors. The modern sense of each word, and the grey context words, are com-\n",
      "puted from the most recent (modern) time-point embedding space. Earlier points are com-\n",
      "puted from earlier historical embedding spaces. The visualizations show the changes in the\n",
      "word gay from meanings related to ‚Äúcheerful‚Äù or ‚Äúfrolicsome‚Äù to referring to homosexuality,\n",
      "page_content and meta data  puted from earlier historical embedding spaces. The visualizations show the changes in the\n",
      "word gay from meanings related to ‚Äúcheerful‚Äù or ‚Äúfrolicsome‚Äù to referring to homosexuality,\n",
      "the development of the modern ‚Äútransmission‚Äù sense of broadcast from its original sense of\n",
      "sowing seeds, and the pejoration of the word awful as it shifted from meaning ‚Äúfull of awe‚Äù\n",
      "to meaning ‚Äúterrible or appalling‚Äù (Hamilton et al., 2016).\n",
      "5.8\n",
      "Bias and Embeddings\n",
      "In addition to their ability to learn word meaning from text, embeddings, alas,\n",
      "also reproduce the implicit biases and stereotypes that were latent in the text. As\n",
      "the prior section just showed, embeddings can roughly model relational similar-\n",
      "ity: ‚Äòqueen‚Äô as the closest word to ‚Äòking‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô implies the analogy\n",
      "man:woman::king:queen. But these same embedding analogies also exhibit gender\n",
      "stereotypes. For example Bolukbasi et al. (2016) Ô¨Ånd that the closest occupation\n",
      "page_content and meta data  man:woman::king:queen. But these same embedding analogies also exhibit gender\n",
      "stereotypes. For example Bolukbasi et al. (2016) Ô¨Ånd that the closest occupation\n",
      "to ‚Äòcomputer programmer‚Äô - ‚Äòman‚Äô + ‚Äòwoman‚Äô in word2vec embeddings trained on\n",
      "news text is ‚Äòhomemaker‚Äô, and that the embeddings similarly suggest the analogy\n",
      "‚Äòfather‚Äô is to ‚Äòdoctor‚Äô as ‚Äòmother‚Äô is to ‚Äònurse‚Äô. This could result in what Crawford\n",
      "(2017) and Blodgett et al. (2020) call an allocational harm, when a system allo-\n",
      "allocational\n",
      "harm\n",
      "cates resources (jobs or credit) unfairly to different groups. For example algorithms\n",
      "that use embeddings as part of a search for hiring potential programmers or doctors\n",
      "might thus incorrectly downweight documents with women‚Äôs names.\n",
      "It turns out that embeddings don‚Äôt just reÔ¨Çect the statistics of their input, but also\n",
      "amplify bias; gendered terms become more gendered in embedding space than they\n",
      "bias\n",
      "ampliÔ¨Åcation\n",
      "page_content and meta data  It turns out that embeddings don‚Äôt just reÔ¨Çect the statistics of their input, but also\n",
      "amplify bias; gendered terms become more gendered in embedding space than they\n",
      "bias\n",
      "ampliÔ¨Åcation\n",
      "were in the input text statistics (Zhao et al. 2017, Ethayarajh et al. 2019b, Jia et al.\n",
      "2020), and biases are more exaggerated than in actual labor employment statistics\n",
      "(Garg et al., 2018).\n",
      "Embeddings also encode the implicit associations that are a property of human\n",
      "reasoning. The Implicit Association Test (Greenwald et al., 1998) measures peo-\n",
      "page_content and meta data  20\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "ple‚Äôs associations between concepts (like ‚ÄòÔ¨Çowers‚Äô or ‚Äòinsects‚Äô) and attributes (like\n",
      "‚Äòpleasantness‚Äô and ‚Äòunpleasantness‚Äô) by measuring differences in the latency with\n",
      "which they label words in the various categories.3 Using such methods, people\n",
      "in the United States have been shown to associate African-American names with\n",
      "unpleasant words (more than European-American names), male names more with\n",
      "mathematics and female names with the arts, and old people‚Äôs names with unpleas-\n",
      "ant words (Greenwald et al. 1998, Nosek et al. 2002a, Nosek et al. 2002b). Caliskan\n",
      "et al. (2017) replicated all these Ô¨Åndings of implicit associations using GloVe vectors\n",
      "and cosine similarity instead of human latencies. For example African-American\n",
      "names like ‚ÄòLeroy‚Äô and ‚ÄòShaniqua‚Äô had a higher GloVe cosine with unpleasant words\n",
      "while European-American names (‚ÄòBrad‚Äô, ‚ÄòGreg‚Äô, ‚ÄòCourtney‚Äô) had a higher cosine\n",
      "with pleasant words. These problems with embeddings are an example of a repre-\n",
      "page_content and meta data  while European-American names (‚ÄòBrad‚Äô, ‚ÄòGreg‚Äô, ‚ÄòCourtney‚Äô) had a higher cosine\n",
      "with pleasant words. These problems with embeddings are an example of a repre-\n",
      "sentational harm (Crawford 2017, Blodgett et al. 2020), which is a harm caused by\n",
      "representational\n",
      "harm\n",
      "a system demeaning or even ignoring some social groups. Any embedding-aware al-\n",
      "gorithm that made use of word sentiment could thus exacerbate bias against African\n",
      "Americans.\n",
      "Recent research focuses on ways to try to remove these kinds of biases, for\n",
      "example by developing a transformation of the embedding space that removes gen-\n",
      "der stereotypes but preserves deÔ¨Ånitional gender (Bolukbasi et al. 2016, Zhao et al.\n",
      "2017) or changing the training procedure (Zhao et al., 2018). However, although\n",
      "these sorts of debiasing may reduce bias in embeddings, they do not eliminate it\n",
      "debiasing\n",
      "(Gonen and Goldberg, 2019), and this remains an open problem.\n",
      "Historical embeddings are also being used to measure biases in the past. Garg\n",
      "page_content and meta data  debiasing\n",
      "(Gonen and Goldberg, 2019), and this remains an open problem.\n",
      "Historical embeddings are also being used to measure biases in the past. Garg\n",
      "et al. (2018) used embeddings from historical texts to measure the association be-\n",
      "tween embeddings for occupations and embeddings for names of various ethnici-\n",
      "ties or genders (for example the relative cosine similarity of women‚Äôs names versus\n",
      "men‚Äôs to occupation words like ‚Äòlibrarian‚Äô or ‚Äòcarpenter‚Äô) across the 20th century.\n",
      "They found that the cosines correlate with the empirical historical percentages of\n",
      "women or ethnic groups in those occupations. Historical embeddings also repli-\n",
      "cated old surveys of ethnic stereotypes; the tendency of experimental participants in\n",
      "1933 to associate adjectives like ‚Äòindustrious‚Äô or ‚Äòsuperstitious‚Äô with, e.g., Chinese\n",
      "ethnicity, correlates with the cosine between Chinese last names and those adjectives\n",
      "using embeddings trained on 1930s text. They also were able to document historical\n",
      "page_content and meta data  ethnicity, correlates with the cosine between Chinese last names and those adjectives\n",
      "using embeddings trained on 1930s text. They also were able to document historical\n",
      "gender biases, such as the fact that embeddings for adjectives related to competence\n",
      "(‚Äòsmart‚Äô, ‚Äòwise‚Äô, ‚Äòthoughtful‚Äô, ‚Äòresourceful‚Äô) had a higher cosine with male than fe-\n",
      "male words, and showed that this bias has been slowly decreasing since 1960. We\n",
      "return in later chapters to this question about the role of bias in natural language\n",
      "processing.\n",
      "5.9\n",
      "Evaluating Vector Models\n",
      "The most important evaluation metric for vector models is extrinsic evaluation on\n",
      "tasks, i.e., using vectors in an NLP task and seeing whether this improves perfor-\n",
      "mance over some other model.\n",
      "3\n",
      "Roughly speaking, if humans associate ‚ÄòÔ¨Çowers‚Äô with ‚Äòpleasantness‚Äô and ‚Äòinsects‚Äô with ‚Äòunpleasant-\n",
      "ness‚Äô, when they are instructed to push a green button for ‚ÄòÔ¨Çowers‚Äô (daisy, iris, lilac) and ‚Äòpleasant words‚Äô\n",
      "page_content and meta data  ness‚Äô, when they are instructed to push a green button for ‚ÄòÔ¨Çowers‚Äô (daisy, iris, lilac) and ‚Äòpleasant words‚Äô\n",
      "(love, laughter, pleasure) and a red button for ‚Äòinsects‚Äô (Ô¨Çea, spider, mosquito) and ‚Äòunpleasant words‚Äô\n",
      "(abuse, hatred, ugly) they are faster than in an incongruous condition where they push a red button for\n",
      "‚ÄòÔ¨Çowers‚Äô and ‚Äòunpleasant words‚Äô and a green button for ‚Äòinsects‚Äô and ‚Äòpleasant words‚Äô.\n",
      "page_content and meta data  5.10\n",
      "‚Ä¢\n",
      "SUMMARY\n",
      "21\n",
      "Nonetheless it is useful to have intrinsic evaluations. The most common metric\n",
      "is to test their performance on similarity, computing the correlation between an\n",
      "algorithm‚Äôs word similarity scores and word similarity ratings assigned by humans.\n",
      "WordSim-353 (Finkelstein et al., 2002) is a commonly used set of ratings from 0\n",
      "to 10 for 353 noun pairs; for example (plane, car) had an average score of 5.77.\n",
      "SimLex-999 (Hill et al., 2015) is a more complex dataset that quantiÔ¨Åes similarity\n",
      "(cup, mug) rather than relatedness (cup, coffee), and includes concrete and abstract\n",
      "adjective, noun and verb pairs. The TOEFL dataset is a set of 80 questions, each\n",
      "consisting of a target word with 4 additional word choices; the task is to choose\n",
      "which is the correct synonym, as in the example: Levied is closest in meaning to:\n",
      "imposed, believed, requested, correlated (Landauer and Dumais, 1997). All of these\n",
      "datasets present words without context.\n",
      "page_content and meta data  imposed, believed, requested, correlated (Landauer and Dumais, 1997). All of these\n",
      "datasets present words without context.\n",
      "Slightly more realistic are intrinsic similarity tasks that include context. The\n",
      "Stanford Contextual Word Similarity (SCWS) dataset (Huang et al., 2012) and the\n",
      "Word-in-Context (WiC) dataset (Pilehvar and Camacho-Collados, 2019) offer richer\n",
      "evaluation scenarios. SCWS gives human judgments on 2,003 pairs of words in\n",
      "their sentential context, while WiC gives target words in two sentential contexts that\n",
      "are either in the same or different senses; see Appendix G. The semantic textual\n",
      "similarity task (Agirre et al. 2012, Agirre et al. 2015) evaluates the performance of\n",
      "sentence-level similarity algorithms, consisting of a set of pairs of sentences, each\n",
      "pair with human-labeled similarity scores.\n",
      "Another task used for evaluation is the analogy task, discussed on page 17, where\n",
      "the system has to solve problems of the form a is to b as a* is to b*, given a, b, and a*\n",
      "page_content and meta data  Another task used for evaluation is the analogy task, discussed on page 17, where\n",
      "the system has to solve problems of the form a is to b as a* is to b*, given a, b, and a*\n",
      "and having to Ô¨Ånd b* (Turney and Littman, 2005). A number of sets of tuples have\n",
      "been created for this task (Mikolov et al. 2013a, Mikolov et al. 2013c, Gladkova\n",
      "et al. 2016), covering morphology (city:cities::child:children), lexicographic rela-\n",
      "tions (leg:table::spout:teapot) and encyclopedia relations (Beijing:China::Dublin:Ireland),\n",
      "some drawing from the SemEval-2012 Task 2 dataset of 79 different relations (Jur-\n",
      "gens et al., 2012).\n",
      "All embedding algorithms suffer from inherent variability. For example because\n",
      "of randomness in the initialization and the random negative sampling, algorithms\n",
      "like word2vec may produce different results even from the same dataset, and in-\n",
      "dividual documents in a collection may strongly impact the resulting embeddings\n",
      "page_content and meta data  like word2vec may produce different results even from the same dataset, and in-\n",
      "dividual documents in a collection may strongly impact the resulting embeddings\n",
      "(Tian et al. 2016, Hellrich and Hahn 2016, Antoniak and Mimno 2018). When em-\n",
      "beddings are used to study word associations in particular corpora, therefore, it is\n",
      "best practice to train multiple embeddings with bootstrap sampling over documents\n",
      "and average the results (Antoniak and Mimno, 2018).\n",
      "5.10\n",
      "Summary\n",
      "‚Ä¢ In vector semantics, a word is modeled as a vector‚Äîa point in high-dimensional\n",
      "space, also called an embedding. In this chapter we focus on static embed-\n",
      "dings, where each word is mapped to a Ô¨Åxed embedding.\n",
      "‚Ä¢ Vector semantic models fall into two classes: sparse and dense. In sparse\n",
      "models each dimension corresponds to a word in the vocabulary V and cells\n",
      "are functions of co-occurrence counts. The word-context or term-term ma-\n",
      "trix has a row for each (target) word in the vocabulary and a column for each\n",
      "page_content and meta data  are functions of co-occurrence counts. The word-context or term-term ma-\n",
      "trix has a row for each (target) word in the vocabulary and a column for each\n",
      "context term in the vocabulary.\n",
      "page_content and meta data  22\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "‚Ä¢ Dense vector models typically have dimensionality 50‚Äì1000. Word2vec al-\n",
      "gorithms like skip-gram are a popular way to compute dense embeddings.\n",
      "Skip-gram trains a logistic regression classiÔ¨Åer to compute the probability that\n",
      "two words are ‚Äòlikely to occur nearby in text‚Äô. This probability is computed\n",
      "from the dot product between the embeddings for the two words.\n",
      "‚Ä¢ Skip-gram uses stochastic gradient descent to train the classiÔ¨Åer, by learning\n",
      "embeddings that have a high dot product with embeddings of words that occur\n",
      "nearby and a low dot product with noise words.\n",
      "‚Ä¢ Other important embedding algorithms include GloVe, a method based on\n",
      "ratios of word co-occurrence probabilities.\n",
      "‚Ä¢ Whether using sparse or dense vectors, word and document similarities are\n",
      "computed by some function of the dot product between vectors. The cosine\n",
      "of two vectors‚Äîa normalized dot product‚Äîis the most popular such metric.\n",
      "Historical Notes\n",
      "page_content and meta data  computed by some function of the dot product between vectors. The cosine\n",
      "of two vectors‚Äîa normalized dot product‚Äîis the most popular such metric.\n",
      "Historical Notes\n",
      "The idea of vector semantics arose out of research in the 1950s in three distinct\n",
      "Ô¨Åelds: linguistics, psychology, and computer science, each of which contributed a\n",
      "fundamental aspect of the model.\n",
      "The idea that meaning is related to the distribution of words in context was\n",
      "widespread in linguistic theory of the 1950s, among distributionalists like Zellig\n",
      "Harris, Martin Joos, and J. R. Firth, and semioticians like Thomas Sebeok. As Joos\n",
      "(1950) put it,\n",
      "the linguist‚Äôs ‚Äúmeaning‚Äù of a morpheme. . . is by deÔ¨Ånition the set of conditional\n",
      "probabilities of its occurrence in context with all other morphemes.\n",
      "The idea that the meaning of a word might be modeled as a point in a multi-\n",
      "dimensional semantic space came from psychologists like Charles E. Osgood, who\n",
      "page_content and meta data  The idea that the meaning of a word might be modeled as a point in a multi-\n",
      "dimensional semantic space came from psychologists like Charles E. Osgood, who\n",
      "had been studying how people responded to the meaning of words by assigning val-\n",
      "ues along scales like happy/sad or hard/soft. Osgood et al. (1957) proposed that the\n",
      "meaning of a word in general could be modeled as a point in a multidimensional\n",
      "Euclidean space, and that the similarity of meaning between two words could be\n",
      "modeled as the distance between these points in the space.\n",
      "A Ô¨Ånal intellectual source in the 1950s and early 1960s was the Ô¨Åeld then called\n",
      "mechanical indexing, now known as information retrieval. In what became known\n",
      "mechanical\n",
      "indexing\n",
      "as the vector space model for information retrieval (Salton 1971, Sparck Jones\n",
      "1986), researchers demonstrated new ways to deÔ¨Åne the meaning of words in terms\n",
      "of vectors (Switzer, 1965), and reÔ¨Åned methods for word similarity based on mea-\n",
      "page_content and meta data  1986), researchers demonstrated new ways to deÔ¨Åne the meaning of words in terms\n",
      "of vectors (Switzer, 1965), and reÔ¨Åned methods for word similarity based on mea-\n",
      "sures of statistical association between words like mutual information (Giuliano,\n",
      "1965) and idf (Sparck Jones, 1972), and showed that the meaning of documents\n",
      "could be represented in the same vector spaces used for words. Around the same\n",
      "time, (Cordier, 1965) showed that factor analysis of word association probabilities\n",
      "could be used to form dense vector representations of words.\n",
      "Some of the philosophical underpinning of the distributional way of thinking\n",
      "came from the late writings of the philosopher Wittgenstein, who was skeptical of\n",
      "the possibility of building a completely formal theory of meaning deÔ¨Ånitions for\n",
      "each word. Wittgenstein suggested instead that ‚Äúthe meaning of a word is its use in\n",
      "the language‚Äù (Wittgenstein, 1953, PI 43). That is, instead of using some logical lan-\n",
      "page_content and meta data  each word. Wittgenstein suggested instead that ‚Äúthe meaning of a word is its use in\n",
      "the language‚Äù (Wittgenstein, 1953, PI 43). That is, instead of using some logical lan-\n",
      "guage to deÔ¨Åne each word, or drawing on denotations or truth values, Wittgenstein‚Äôs\n",
      "page_content and meta data  HISTORICAL NOTES\n",
      "23\n",
      "idea is that we should deÔ¨Åne a word by how it is used by people in speaking and un-\n",
      "derstanding in their day-to-day interactions, thus preÔ¨Åguring the movement toward\n",
      "embodied and experiential models in linguistics and NLP (Glenberg and Robertson\n",
      "2000, Lake and Murphy 2021, Bisk et al. 2020, Bender and Koller 2020).\n",
      "More distantly related is the idea of deÔ¨Åning words by a vector of discrete fea-\n",
      "tures, which has roots at least as far back as Descartes and Leibniz (Wierzbicka 1992,\n",
      "Wierzbicka 1996). By the middle of the 20th century, beginning with the work of\n",
      "Hjelmslev (Hjelmslev, 1969) (originally 1943) and Ô¨Çeshed out in early models of\n",
      "generative grammar (Katz and Fodor, 1963), the idea arose of representing mean-\n",
      "ing with semantic features, symbols that represent some sort of primitive meaning.\n",
      "semantic\n",
      "feature\n",
      "For example words like hen, rooster, or chick, have something in common (they all\n",
      "page_content and meta data  ing with semantic features, symbols that represent some sort of primitive meaning.\n",
      "semantic\n",
      "feature\n",
      "For example words like hen, rooster, or chick, have something in common (they all\n",
      "describe chickens) and something different (their age and sex), representable as:\n",
      "hen\n",
      "+female, +chicken, +adult\n",
      "rooster -female, +chicken, +adult\n",
      "chick\n",
      "+chicken, -adult\n",
      "The dimensions used by vector models of meaning to deÔ¨Åne words, however, are\n",
      "only abstractly related to this idea of a small Ô¨Åxed number of hand-built dimensions.\n",
      "Nonetheless, there has been some attempt to show that certain dimensions of em-\n",
      "bedding models do contribute some speciÔ¨Åc compositional aspect of meaning like\n",
      "these early semantic features.\n",
      "The use of dense vectors to model word meaning, and indeed the term embed-\n",
      "ding, grew out of the latent semantic indexing (LSI) model (Deerwester et al.,\n",
      "1988) recast as LSA (latent semantic analysis) (Deerwester et al., 1990). In LSA\n",
      "page_content and meta data  ding, grew out of the latent semantic indexing (LSI) model (Deerwester et al.,\n",
      "1988) recast as LSA (latent semantic analysis) (Deerwester et al., 1990). In LSA\n",
      "singular value decomposition‚ÄîSVD‚Äî is applied to a term-document matrix (each\n",
      "SVD\n",
      "cell weighted by log frequency and normalized by entropy), and then the Ô¨Årst 300\n",
      "dimensions are used as the LSA embedding. Singular Value Decomposition (SVD)\n",
      "is a method for Ô¨Ånding the most important dimensions of a data set, those dimen-\n",
      "sions along which the data varies the most. LSA was then quickly widely applied:\n",
      "as a cognitive model (Landauer and Dumais, 1997), and for tasks like spell checking\n",
      "(Jones and Martin, 1997), language modeling (Bellegarda 1997, Coccaro and Ju-\n",
      "rafsky 1998, Bellegarda 2000), morphology induction (Schone and Jurafsky 2000,\n",
      "Schone and Jurafsky 2001b), multiword expressions (MWEs) (Schone and Jurafsky,\n",
      "2001a), and essay grading (Rehder et al., 1998). Related models were simultane-\n",
      "page_content and meta data  Schone and Jurafsky 2001b), multiword expressions (MWEs) (Schone and Jurafsky,\n",
      "2001a), and essay grading (Rehder et al., 1998). Related models were simultane-\n",
      "ously developed and applied to word sense disambiguation by Sch¬®utze (1992). LSA\n",
      "also led to the earliest use of embeddings to represent words in a probabilistic clas-\n",
      "siÔ¨Åer, in the logistic regression document router of Sch¬®utze et al. (1995). The idea of\n",
      "SVD on the term-term matrix (rather than the term-document matrix) as a model of\n",
      "meaning for NLP was proposed soon after LSA by Sch¬®utze (1992). Sch¬®utze applied\n",
      "the low-rank (97-dimensional) embeddings produced by SVD to the task of word\n",
      "sense disambiguation, analyzed the resulting semantic space, and also suggested\n",
      "possible techniques like dropping high-order dimensions. See Sch¬®utze (1997).\n",
      "A number of alternative matrix models followed on from the early SVD work,\n",
      "including Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 1999), Latent\n",
      "page_content and meta data  A number of alternative matrix models followed on from the early SVD work,\n",
      "including Probabilistic Latent Semantic Indexing (PLSI) (Hofmann, 1999), Latent\n",
      "Dirichlet Allocation (LDA) (Blei et al., 2003), and Non-negative Matrix Factoriza-\n",
      "tion (NMF) (Lee and Seung, 1999).\n",
      "The LSA community seems to have Ô¨Årst used the word ‚Äúembedding‚Äù in Landauer\n",
      "et al. (1997), in a variant of its mathematical meaning as a mapping from one space\n",
      "or mathematical structure to another. In LSA, the word embedding seems to have\n",
      "described the mapping from the space of sparse count vectors to the latent space of\n",
      "SVD dense vectors. Although the word thus originally meant the mapping from one\n",
      "page_content and meta data  24\n",
      "CHAPTER 5\n",
      "‚Ä¢\n",
      "EMBEDDINGS\n",
      "space to another, it has metonymically shifted to mean the resulting dense vector in\n",
      "the latent space, and it is in this sense that we currently use the word.\n",
      "By the next decade, Bengio et al. (2003) and Bengio et al. (2006) showed that\n",
      "neural language models could also be used to develop embeddings as part of the task\n",
      "of word prediction. Collobert and Weston (2007), Collobert and Weston (2008), and\n",
      "Collobert et al. (2011) then demonstrated that embeddings could be used to represent\n",
      "word meanings for a number of NLP tasks. Turian et al. (2010) compared the value\n",
      "of different kinds of embeddings for different NLP tasks. Mikolov et al. (2011)\n",
      "showed that recurrent neural nets could be used as language models. The idea of\n",
      "simplifying the hidden layer of these neural net language models to create the skip-\n",
      "gram (and also CBOW) algorithms was proposed by Mikolov et al. (2013a). The\n",
      "negative sampling training algorithm was proposed in Mikolov et al. (2013b). There\n",
      "page_content and meta data  gram (and also CBOW) algorithms was proposed by Mikolov et al. (2013a). The\n",
      "negative sampling training algorithm was proposed in Mikolov et al. (2013b). There\n",
      "are numerous surveys of static embeddings and their parameterizations (Bullinaria\n",
      "and Levy 2007, Bullinaria and Levy 2012, Lapesa and Evert 2014, Kiela and Clark\n",
      "2014, Levy et al. 2015).\n",
      "See Manning et al. (2008) and Chapter 11 for a deeper understanding of the role\n",
      "of vectors in information retrieval, including how to compare queries with docu-\n",
      "ments, more details on tf-idf, and issues of scaling to very large datasets. See Kim\n",
      "(2019) for a clear and comprehensive tutorial on word2vec. Cruse (2004) is a useful\n",
      "introductory linguistic text on lexical semantics.\n",
      "Exercises\n",
      "page_content and meta data  Exercises\n",
      "25\n",
      "Agirre, E., C. Banea, C. Cardie, D. Cer, M. Diab,\n",
      "A. Gonzalez-Agirre, W. Guo, I. Lopez-Gazpio, M. Mar-\n",
      "itxalar, R. Mihalcea, G. Rigau, L. Uria, and J. Wiebe.\n",
      "2015. SemEval-2015 task 2: Semantic textual similarity,\n",
      "English, Spanish and pilot on interpretability. SemEval-\n",
      "15.\n",
      "Agirre, E., M. Diab, D. Cer, and A. Gonzalez-Agirre. 2012.\n",
      "SemEval-2012 task 6: A pilot on semantic textual simi-\n",
      "larity. SemEval-12.\n",
      "Antoniak, M. and D. Mimno. 2018. Evaluating the stability\n",
      "of embedding-based word similarities. TACL, 6:107‚Äì119.\n",
      "Bellegarda, J. R. 1997. A latent semantic analysis framework\n",
      "for large-span language modeling. EUROSPEECH.\n",
      "Bellegarda, J. R. 2000. Exploiting latent semantic informa-\n",
      "tion in statistical language modeling. Proceedings of the\n",
      "IEEE, 89(8):1279‚Äì1296.\n",
      "Bender, E. M. and A. Koller. 2020. Climbing towards NLU:\n",
      "On meaning, form, and understanding in the age of data.\n",
      "ACL.\n",
      "Bengio, Y., A. Courville, and P. Vincent. 2013. Represen-\n",
      "page_content and meta data  IEEE, 89(8):1279‚Äì1296.\n",
      "Bender, E. M. and A. Koller. 2020. Climbing towards NLU:\n",
      "On meaning, form, and understanding in the age of data.\n",
      "ACL.\n",
      "Bengio, Y., A. Courville, and P. Vincent. 2013. Represen-\n",
      "tation learning: A review and new perspectives. IEEE\n",
      "Transactions on Pattern Analysis and Machine Intelli-\n",
      "gence, 35(8):1798‚Äì1828.\n",
      "Bengio, Y., R. Ducharme, P. Vincent, and C. Jauvin. 2003.\n",
      "A neural probabilistic language model. JMLR, 3:1137‚Äì\n",
      "1155.\n",
      "Bengio, Y., H. Schwenk, J.-S. Sen¬¥ecal, F. Morin, and J.-L.\n",
      "Gauvain. 2006. Neural probabilistic language models. In\n",
      "Innovations in Machine Learning, 137‚Äì186. Springer.\n",
      "Bisk, Y., A. Holtzman, J. Thomason, J. Andreas, Y. Bengio,\n",
      "J. Chai, M. Lapata, A. Lazaridou, J. May, A. Nisnevich,\n",
      "N. Pinto, and J. Turian. 2020. Experience grounds lan-\n",
      "guage. EMNLP.\n",
      "Blei, D. M., A. Y. Ng, and M. I. Jordan. 2003. Latent Dirich-\n",
      "let allocation. JMLR, 3(5):993‚Äì1022.\n",
      "Blodgett, S. L., S. Barocas, H. Daum¬¥e III, and H. Wallach.\n",
      "page_content and meta data  guage. EMNLP.\n",
      "Blei, D. M., A. Y. Ng, and M. I. Jordan. 2003. Latent Dirich-\n",
      "let allocation. JMLR, 3(5):993‚Äì1022.\n",
      "Blodgett, S. L., S. Barocas, H. Daum¬¥e III, and H. Wallach.\n",
      "2020. Language (technology) is power: A critical survey\n",
      "of ‚Äúbias‚Äù in NLP. ACL.\n",
      "Bojanowski, P., E. Grave, A. Joulin, and T. Mikolov. 2017.\n",
      "Enriching word vectors with subword information. TACL,\n",
      "5:135‚Äì146.\n",
      "Bolukbasi, T., K.-W. Chang, J. Zou, V. Saligrama, and A. T.\n",
      "Kalai. 2016. Man is to computer programmer as woman\n",
      "is to homemaker? Debiasing word embeddings. NeurIPS.\n",
      "Br¬¥eal, M. 1897. Essai de S¬¥emantique: Science des signiÔ¨Åca-\n",
      "tions. Hachette.\n",
      "Budanitsky, A. and G. Hirst. 2006.\n",
      "Evaluating WordNet-\n",
      "based measures of lexical semantic relatedness. Compu-\n",
      "tational Linguistics, 32(1):13‚Äì47.\n",
      "Bullinaria, J. A. and J. P. Levy. 2007. Extracting seman-\n",
      "tic representations from word co-occurrence statistics:\n",
      "A computational study.\n",
      "Behavior research methods,\n",
      "39(3):510‚Äì526.\n",
      "page_content and meta data  Bullinaria, J. A. and J. P. Levy. 2007. Extracting seman-\n",
      "tic representations from word co-occurrence statistics:\n",
      "A computational study.\n",
      "Behavior research methods,\n",
      "39(3):510‚Äì526.\n",
      "Bullinaria, J. A. and J. P. Levy. 2012. Extracting semantic\n",
      "representations from word co-occurrence statistics: stop-\n",
      "lists, stemming, and SVD. Behavior research methods,\n",
      "44(3):890‚Äì907.\n",
      "Caliskan, A., J. J. Bryson, and A. Narayanan. 2017. Seman-\n",
      "tics derived automatically from language corpora contain\n",
      "human-like biases. Science, 356(6334):183‚Äì186.\n",
      "Carlson, G. N. 1977. Reference to kinds in English. Ph.D.\n",
      "thesis, University of Massachusetts, Amherst. Forward.\n",
      "Clark, E. 1987. The principle of contrast: A constraint on\n",
      "language acquisition. In B. MacWhinney, ed., Mecha-\n",
      "nisms of language acquisition, 1‚Äì33. LEA.\n",
      "Coccaro, N. and D. Jurafsky. 1998. Towards better integra-\n",
      "tion of semantic predictors in statistical language model-\n",
      "ing. ICSLP.\n",
      "Collobert, R. and J. Weston. 2007. Fast semantic extraction\n",
      "page_content and meta data  Coccaro, N. and D. Jurafsky. 1998. Towards better integra-\n",
      "tion of semantic predictors in statistical language model-\n",
      "ing. ICSLP.\n",
      "Collobert, R. and J. Weston. 2007. Fast semantic extraction\n",
      "using a novel neural network architecture. ACL.\n",
      "Collobert, R. and J. Weston. 2008. A uniÔ¨Åed architecture for\n",
      "natural language processing: Deep neural networks with\n",
      "multitask learning. ICML.\n",
      "Collobert,\n",
      "R.,\n",
      "J.\n",
      "Weston,\n",
      "L.\n",
      "Bottou,\n",
      "M.\n",
      "Karlen,\n",
      "K. Kavukcuoglu, and P. Kuksa. 2011. Natural language\n",
      "processing (almost) from scratch. JMLR, 12:2493‚Äì2537.\n",
      "Cordier, B. 1965. Factor-analysis of correspondences. COL-\n",
      "ING 1965.\n",
      "Crawford, K. 2017.\n",
      "The trouble with bias.\n",
      "Keynote at\n",
      "NeurIPS.\n",
      "Cruse, D. A. 2004. Meaning in Language: an Introduction\n",
      "to Semantics and Pragmatics. Oxford University Press.\n",
      "Second edition.\n",
      "Davies, M. 2012.\n",
      "Expanding horizons in historical lin-\n",
      "guistics with the 400-million word Corpus of Historical\n",
      "American English. Corpora, 7(2):121‚Äì157.\n",
      "page_content and meta data  Second edition.\n",
      "Davies, M. 2012.\n",
      "Expanding horizons in historical lin-\n",
      "guistics with the 400-million word Corpus of Historical\n",
      "American English. Corpora, 7(2):121‚Äì157.\n",
      "Davies, M. 2015. The Wikipedia Corpus: 4.6 million arti-\n",
      "cles, 1.9 billion words. Adapted from Wikipedia. https:\n",
      "//www.english-corpora.org/wiki/.\n",
      "Deerwester, S. C., S. T. Dumais, G. W. Furnas, R. A. Harsh-\n",
      "man, T. K. Landauer, K. E. Lochbaum, and L. Streeter.\n",
      "1988. Computer information retrieval using latent seman-\n",
      "tic structure: US Patent 4,839,853.\n",
      "Deerwester, S. C., S. T. Dumais, T. K. Landauer, G. W. Fur-\n",
      "nas, and R. A. Harshman. 1990. Indexing by latent se-\n",
      "mantics analysis. JASIS, 41(6):391‚Äì407.\n",
      "Ethayarajh, K., D. Duvenaud, and G. Hirst. 2019a. Towards\n",
      "understanding linear word analogies. ACL.\n",
      "Ethayarajh, K., D. Duvenaud, and G. Hirst. 2019b. Under-\n",
      "standing undesirable word embedding associations. ACL.\n",
      "Finkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin,\n",
      "Z. Solan, G. Wolfman, and E. Ruppin. 2002.\n",
      "Placing\n",
      "page_content and meta data  standing undesirable word embedding associations. ACL.\n",
      "Finkelstein, L., E. Gabrilovich, Y. Matias, E. Rivlin,\n",
      "Z. Solan, G. Wolfman, and E. Ruppin. 2002.\n",
      "Placing\n",
      "search in context: The concept revisited. ACM Trans-\n",
      "actions on Information Systems, 20(1):116‚Äî-131.\n",
      "Firth, J. R. 1957.\n",
      "A synopsis of linguistic theory 1930‚Äì\n",
      "1955. In Studies in Linguistic Analysis. Philological So-\n",
      "ciety. Reprinted in Palmer, F. (ed.) 1968. Selected Papers\n",
      "of J. R. Firth. Longman, Harlow.\n",
      "Garg, N., L. Schiebinger, D. Jurafsky, and J. Zou. 2018.\n",
      "Word embeddings quantify 100 years of gender and eth-\n",
      "nic stereotypes. Proceedings of the National Academy of\n",
      "Sciences, 115(16):E3635‚ÄìE3644.\n",
      "Girard, G. 1718. La justesse de la langue franc¬∏oise: ou les\n",
      "diff¬¥erentes signiÔ¨Åcations des mots qui passent pour syn-\n",
      "onimes. Laurent d‚ÄôHoury, Paris.\n",
      "page_content and meta data  26\n",
      "Chapter 5\n",
      "‚Ä¢\n",
      "Embeddings\n",
      "Giuliano,\n",
      "V. E. 1965.\n",
      "The interpretation of word\n",
      "associations.\n",
      "Statistical Association Methods For\n",
      "Mechanized\n",
      "Documentation.\n",
      "Symposium\n",
      "Proceed-\n",
      "ings.\n",
      "Washington,\n",
      "D.C.,\n",
      "USA,\n",
      "March\n",
      "17,\n",
      "1964.\n",
      "https://nvlpubs.nist.gov/nistpubs/Legacy/\n",
      "MP/nbsmiscellaneouspub269.pdf.\n",
      "Gladkova, A., A. Drozd, and S. Matsuoka. 2016. Analogy-\n",
      "based detection of morphological and semantic relations\n",
      "with word embeddings: what works and what doesn‚Äôt.\n",
      "NAACL Student Research Workshop.\n",
      "Glenberg, A. M. and D. A. Robertson. 2000. Symbol ground-\n",
      "ing and meaning: A comparison of high-dimensional and\n",
      "embodied theories of meaning. Journal of memory and\n",
      "language, 43(3):379‚Äì401.\n",
      "Gonen, H. and Y. Goldberg. 2019. Lipstick on a pig: Debi-\n",
      "asing methods cover up systematic gender biases in word\n",
      "embeddings but do not remove them. NAACL HLT.\n",
      "Gould, S. J. 1980. The Panda‚Äôs Thumb. Penguin Group.\n",
      "Greenwald, A. G., D. E. McGhee, and J. L. K. Schwartz.\n",
      "1998. Measuring individual differences in implicit cogni-\n",
      "page_content and meta data  Gould, S. J. 1980. The Panda‚Äôs Thumb. Penguin Group.\n",
      "Greenwald, A. G., D. E. McGhee, and J. L. K. Schwartz.\n",
      "1998. Measuring individual differences in implicit cogni-\n",
      "tion: the implicit association test. Journal of personality\n",
      "and social psychology, 74(6):1464‚Äì1480.\n",
      "Hamilton, W. L., J. Leskovec, and D. Jurafsky. 2016. Di-\n",
      "achronic word embeddings reveal statistical laws of se-\n",
      "mantic change. ACL.\n",
      "Harris, Z. S. 1954. Distributional structure. Word, 10:146‚Äì\n",
      "162.\n",
      "Hellrich,\n",
      "J. and U. Hahn. 2016.\n",
      "Bad company‚Äî\n",
      "Neighborhoods in neural embedding spaces considered\n",
      "harmful. COLING.\n",
      "Hill, F., R. Reichart, and A. Korhonen. 2015. Simlex-999:\n",
      "Evaluating semantic models with (genuine) similarity es-\n",
      "timation. Computational Linguistics, 41(4):665‚Äì695.\n",
      "Hjelmslev, L. 1969. Prologomena to a Theory of Language.\n",
      "University of Wisconsin Press. Translated by Francis J.\n",
      "WhitÔ¨Åeld; original Danish edition 1943.\n",
      "Hofmann, T. 1999. Probabilistic latent semantic indexing.\n",
      "SIGIR-99.\n",
      "page_content and meta data  University of Wisconsin Press. Translated by Francis J.\n",
      "WhitÔ¨Åeld; original Danish edition 1943.\n",
      "Hofmann, T. 1999. Probabilistic latent semantic indexing.\n",
      "SIGIR-99.\n",
      "Huang, E. H., R. Socher, C. D. Manning, and A. Y. Ng. 2012.\n",
      "Improving word representations via global context and\n",
      "multiple word prototypes. ACL.\n",
      "Jia, S., T. Meng, J. Zhao, and K.-W. Chang. 2020. Mitigat-\n",
      "ing gender bias ampliÔ¨Åcation in distribution by posterior\n",
      "regularization. ACL.\n",
      "Jones, M. P. and J. H. Martin. 1997. Contextual spelling cor-\n",
      "rection using latent semantic analysis. ANLP.\n",
      "Joos, M. 1950.\n",
      "Description of language design.\n",
      "JASA,\n",
      "22:701‚Äì708.\n",
      "Jurgens, D., S. M. Mohammad, P. Turney, and K. Holyoak.\n",
      "2012. SemEval-2012 task 2: Measuring degrees of rela-\n",
      "tional similarity. *SEM 2012.\n",
      "Katz, J. J. and J. A. Fodor. 1963. The structure of a semantic\n",
      "theory. Language, 39:170‚Äì210.\n",
      "Kiela, D. and S. Clark. 2014. A systematic study of semantic\n",
      "vector space model parameters. EACL 2nd Workshop on\n",
      "page_content and meta data  theory. Language, 39:170‚Äì210.\n",
      "Kiela, D. and S. Clark. 2014. A systematic study of semantic\n",
      "vector space model parameters. EACL 2nd Workshop on\n",
      "Continuous Vector Space Models and their Composition-\n",
      "ality (CVSC).\n",
      "Kim,\n",
      "E.\n",
      "2019.\n",
      "Optimize\n",
      "computational\n",
      "efÔ¨Åciency\n",
      "of skip-gram with negative sampling.\n",
      "https://\n",
      "aegis4048.github.io/optimize_computational_\n",
      "efficiency_of_skip-gram_with_negative_\n",
      "sampling.\n",
      "Lake, B. M. and G. L. Murphy. 2021.\n",
      "Word meaning in\n",
      "minds and machines. Psychological Review. In press.\n",
      "Landauer, T. K. and S. T. Dumais. 1997. A solution to Plato‚Äôs\n",
      "problem: The Latent Semantic Analysis theory of acqui-\n",
      "sition, induction, and representation of knowledge. Psy-\n",
      "chological Review, 104:211‚Äì240.\n",
      "Landauer, T. K., D. Laham, B. Rehder, and M. E. Schreiner.\n",
      "1997. How well can passage meaning be derived with-\n",
      "out using word order? A comparison of Latent Semantic\n",
      "Analysis and humans. COGSCI.\n",
      "Lapesa, G. and S. Evert. 2014. A large scale evaluation of\n",
      "page_content and meta data  1997. How well can passage meaning be derived with-\n",
      "out using word order? A comparison of Latent Semantic\n",
      "Analysis and humans. COGSCI.\n",
      "Lapesa, G. and S. Evert. 2014. A large scale evaluation of\n",
      "distributional semantic models: Parameters, interactions\n",
      "and model selection. TACL, 2:531‚Äì545.\n",
      "Lee, D. D. and H. S. Seung. 1999. Learning the parts of\n",
      "objects by non-negative matrix factorization.\n",
      "Nature,\n",
      "401(6755):788‚Äì791.\n",
      "Levy, O. and Y. Goldberg. 2014a. Dependency-based word\n",
      "embeddings. ACL.\n",
      "Levy, O. and Y. Goldberg. 2014b. Linguistic regularities in\n",
      "sparse and explicit word representations. CoNLL.\n",
      "Levy, O. and Y. Goldberg. 2014c. Neural word embedding\n",
      "as implicit matrix factorization. NeurIPS.\n",
      "Levy, O., Y. Goldberg, and I. Dagan. 2015. Improving dis-\n",
      "tributional similarity with lessons learned from word em-\n",
      "beddings. TACL, 3:211‚Äì225.\n",
      "Lin, Y., J.-B. Michel, E. Lieberman Aiden, J. Orwant,\n",
      "W. Brockman, and S. Petrov. 2012. Syntactic annotations\n",
      "for the Google Books NGram corpus. ACL.\n",
      "page_content and meta data  beddings. TACL, 3:211‚Äì225.\n",
      "Lin, Y., J.-B. Michel, E. Lieberman Aiden, J. Orwant,\n",
      "W. Brockman, and S. Petrov. 2012. Syntactic annotations\n",
      "for the Google Books NGram corpus. ACL.\n",
      "Linzen, T. 2016. Issues in evaluating semantic spaces us-\n",
      "ing word analogies. 1st Workshop on Evaluating Vector-\n",
      "Space Representations for NLP.\n",
      "Manning, C. D., P. Raghavan, and H. Sch¬®utze. 2008. Intro-\n",
      "duction to Information Retrieval. Cambridge.\n",
      "Mikolov, T., K. Chen, G. S. Corrado, and J. Dean. 2013a. Ef-\n",
      "Ô¨Åcient estimation of word representations in vector space.\n",
      "ICLR 2013.\n",
      "Mikolov, T., S. Kombrink, L. Burget, J. H. ÀáCernock`y, and\n",
      "S. Khudanpur. 2011. Extensions of recurrent neural net-\n",
      "work language model. ICASSP.\n",
      "Mikolov, T., I. Sutskever, K. Chen, G. S. Corrado, and\n",
      "J. Dean. 2013b. Distributed representations of words and\n",
      "phrases and their compositionality. NeurIPS.\n",
      "Mikolov, T., W.-t. Yih, and G. Zweig. 2013c.\n",
      "Linguis-\n",
      "tic regularities in continuous space word representations.\n",
      "NAACL HLT.\n",
      "page_content and meta data  phrases and their compositionality. NeurIPS.\n",
      "Mikolov, T., W.-t. Yih, and G. Zweig. 2013c.\n",
      "Linguis-\n",
      "tic regularities in continuous space word representations.\n",
      "NAACL HLT.\n",
      "Nosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002a.\n",
      "Harvesting implicit group attitudes and beliefs from a\n",
      "demonstration web site. Group Dynamics: Theory, Re-\n",
      "search, and Practice, 6(1):101.\n",
      "Nosek, B. A., M. R. Banaji, and A. G. Greenwald. 2002b.\n",
      "Math=male, me=female, therefore mathÃ∏= me. Journal of\n",
      "personality and social psychology, 83(1):44.\n",
      "Osgood, C. E., G. J. Suci, and P. H. Tannenbaum. 1957. The\n",
      "Measurement of Meaning. University of Illinois Press.\n",
      "page_content and meta data  Exercises\n",
      "27\n",
      "Pennington, J., R. Socher, and C. D. Manning. 2014. GloVe:\n",
      "Global vectors for word representation. EMNLP.\n",
      "Peterson, J. C., D. Chen, and T. L. GrifÔ¨Åths. 2020. Parallelo-\n",
      "grams revisited: Exploring the limitations of vector space\n",
      "models for simple analogies. Cognition, 205.\n",
      "Pilehvar, M. T. and J. Camacho-Collados. 2019. WiC: the\n",
      "word-in-context dataset for evaluating context-sensitive\n",
      "meaning representations. NAACL HLT.\n",
      "Rehder, B., M. E. Schreiner, M. B. W. Wolfe, D. Laham,\n",
      "T. K. Landauer, and W. Kintsch. 1998.\n",
      "Using Latent\n",
      "Semantic Analysis to assess knowledge: Some technical\n",
      "considerations. Discourse Processes, 25(2-3):337‚Äì354.\n",
      "Rohde, D. L. T., L. M. Gonnerman, and D. C. Plaut. 2006.\n",
      "An improved model of semantic similarity based on lexi-\n",
      "cal co-occurrence. CACM, 8:627‚Äì633.\n",
      "Rumelhart, D. E. and A. A. Abrahamson. 1973. A model for\n",
      "analogical reasoning. Cognitive Psychology, 5(1):1‚Äì28.\n",
      "Salton, G. 1971. The SMART Retrieval System: Experiments\n",
      "page_content and meta data  Rumelhart, D. E. and A. A. Abrahamson. 1973. A model for\n",
      "analogical reasoning. Cognitive Psychology, 5(1):1‚Äì28.\n",
      "Salton, G. 1971. The SMART Retrieval System: Experiments\n",
      "in Automatic Document Processing. Prentice Hall.\n",
      "Schluter, N. 2018. The word analogy testing caveat. NAACL\n",
      "HLT.\n",
      "Schone, P. and D. Jurafsky. 2000. Knowlege-free induction\n",
      "of morphology using latent semantic analysis. CoNLL.\n",
      "Schone, P. and D. Jurafsky. 2001a. Is knowledge-free in-\n",
      "duction of multiword unit dictionary headwords a solved\n",
      "problem? EMNLP.\n",
      "Schone, P. and D. Jurafsky. 2001b. Knowledge-free induc-\n",
      "tion of inÔ¨Çectional morphologies. NAACL.\n",
      "Sch¬®utze, H. 1992. Dimensions of meaning. Proceedings of\n",
      "Supercomputing ‚Äô92. IEEE Press.\n",
      "Sch¬®utze, H. 1997. Ambiguity Resolution in Language Learn-\n",
      "ing ‚Äì Computational and Cognitive Models. CSLI, Stan-\n",
      "ford, CA.\n",
      "Sch¬®utze, H., D. A. Hull, and J. Pedersen. 1995. A compar-\n",
      "ison of classiÔ¨Åers and document representations for the\n",
      "routing problem. SIGIR-95.\n",
      "page_content and meta data  ford, CA.\n",
      "Sch¬®utze, H., D. A. Hull, and J. Pedersen. 1995. A compar-\n",
      "ison of classiÔ¨Åers and document representations for the\n",
      "routing problem. SIGIR-95.\n",
      "Sch¬®utze, H. and J. Pedersen. 1993. A vector model for syn-\n",
      "tagmatic and paradigmatic relatedness. 9th Annual Con-\n",
      "ference of the UW Centre for the New OED and Text Re-\n",
      "search.\n",
      "Sparck Jones, K. 1972. A statistical interpretation of term\n",
      "speciÔ¨Åcity and its application in retrieval. Journal of Doc-\n",
      "umentation, 28(1):11‚Äì21.\n",
      "Sparck Jones, K. 1986. Synonymy and Semantic ClassiÔ¨Åca-\n",
      "tion. Edinburgh University Press, Edinburgh. Republica-\n",
      "tion of 1964 PhD Thesis.\n",
      "Switzer, P. 1965.\n",
      "Vector images in document retrieval.\n",
      "Statistical Association Methods For Mechanized Docu-\n",
      "mentation. Symposium Proceedings. Washington, D.C.,\n",
      "USA, March 17, 1964. https://nvlpubs.nist.gov/\n",
      "nistpubs/Legacy/MP/nbsmiscellaneouspub269.\n",
      "pdf.\n",
      "Tian, Y., V. Kulkarni, B. Perozzi, and S. Skiena. 2016. On\n",
      "the convergent properties of word embedding methods.\n",
      "page_content and meta data  nistpubs/Legacy/MP/nbsmiscellaneouspub269.\n",
      "pdf.\n",
      "Tian, Y., V. Kulkarni, B. Perozzi, and S. Skiena. 2016. On\n",
      "the convergent properties of word embedding methods.\n",
      "ArXiv preprint arXiv:1605.03956.\n",
      "Turian, J., L. Ratinov, and Y. Bengio. 2010. Word represen-\n",
      "tations: a simple and general method for semi-supervised\n",
      "learning. ACL.\n",
      "Turney, P. D. and M. L. Littman. 2005. Corpus-based learn-\n",
      "ing of analogies and semantic relations. Machine Learn-\n",
      "ing, 60(1-3):251‚Äì278.\n",
      "van der Maaten, L. and G. E. Hinton. 2008. Visualizing high-\n",
      "dimensional data using t-SNE. JMLR, 9:2579‚Äì2605.\n",
      "Wierzbicka, A. 1992. Semantics, Culture, and Cognition:\n",
      "University Human Concepts in Culture-SpeciÔ¨Åc ConÔ¨Ågu-\n",
      "rations. Oxford University Press.\n",
      "Wierzbicka, A. 1996. Semantics: Primes and Universals.\n",
      "Oxford University Press.\n",
      "Wittgenstein, L. 1953. Philosophical Investigations. (Trans-\n",
      "lated by Anscombe, G.E.M.). Blackwell.\n",
      "Zhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-\n",
      "W. Chang. 2017.\n",
      "Men also like shopping: Reducing\n",
      "page_content and meta data  Wittgenstein, L. 1953. Philosophical Investigations. (Trans-\n",
      "lated by Anscombe, G.E.M.). Blackwell.\n",
      "Zhao, J., T. Wang, M. Yatskar, V. Ordonez, and K.-\n",
      "W. Chang. 2017.\n",
      "Men also like shopping: Reducing\n",
      "gender bias ampliÔ¨Åcation using corpus-level constraints.\n",
      "EMNLP.\n",
      "Zhao, J., Y. Zhou, Z. Li, W. Wang, and K.-W. Chang. 2018.\n",
      "Learning gender-neutral word embeddings. EMNLP.\n",
      "------thhe length of chunks  116\n"
     ]
    }
   ],
   "source": [
    "chunks = split_documents(pdf)\n",
    "all_text = []\n",
    "for chunk in chunks:\n",
    "    print(\"page_content and meta data \"  , chunk.page_content )\n",
    "    all_text.append(chunk.page_content)\n",
    "print(\"------thhe length of chunks \",len(all_text))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a069ae",
   "metadata": {},
   "source": [
    "## Embeddings And VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "37ec7d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import numpy as np\n",
    "from typing import List\n",
    "\n",
    "class Embeddingmanager:\n",
    "    def __init__(self , model_name : str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "\n",
    "    def _load_model(self):\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\" model{self.model_name} loaded successfully\")\n",
    "\n",
    "    def generated_embeddings(self , texts: List[str]) -> np.ndarray:\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not Looaded\")\n",
    "        embeddings = self.model.encode(texts , show_progress_bar=False)\n",
    "        print(f\" eembeddings size :{embeddings.shape}\")\n",
    "        return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ead195c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " modelall-MiniLM-L6-v2 loaded successfully\n",
      " eembeddings size :(116, 384)\n",
      "[[-1.3537210e-01 -6.3055538e-02  3.4148529e-02 ...  2.0333301e-02\n",
      "  -3.4821808e-02  5.6623355e-03]\n",
      " [-1.0171697e-01 -3.5498220e-02  4.2096920e-02 ...  2.1835525e-02\n",
      "  -1.5402910e-02  3.0679405e-03]\n",
      " [-6.2994093e-02 -2.0093251e-02  3.7470080e-02 ...  2.4549354e-02\n",
      "  -8.1064871e-05  3.1577493e-03]\n",
      " ...\n",
      " [-9.9427355e-03  5.0785695e-03 -3.9594166e-02 ...  2.1511057e-02\n",
      "  -3.7029561e-02  4.5129624e-03]\n",
      " [ 4.3912038e-02 -6.2552482e-02  1.0157664e-03 ...  6.0877934e-02\n",
      "  -3.3232991e-02 -3.3315273e-03]\n",
      " [-1.1903145e-04 -1.6633263e-02  3.5781883e-02 ... -2.7365180e-02\n",
      "   1.1771239e-02 -5.1329885e-02]]\n"
     ]
    }
   ],
   "source": [
    "embeddings = Embeddingmanager()\n",
    "embeddings = embeddings.generated_embeddings(all_text)\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7455ad0a",
   "metadata": {},
   "source": [
    "VectorDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "03e9983a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " chromadb client intialized successfullly\n",
      "collection Collection(name=pdf_documents) ready to use\n",
      " added 116 documnets to the vector store \n",
      "vector store setup complete\n"
     ]
    }
   ],
   "source": [
    "import uuid\n",
    "import numpy as np\n",
    "from typing import List\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "class vectorstoreManager():\n",
    "        def __init__(self ,documents: List, \n",
    "                     embeddings: np.ndarray, \n",
    "                     persistent_directory:str = \"./data/chromadb\"):\n",
    "            self.persistent_directory = persistent_directory\n",
    "            self.client = None\n",
    "            self.collection = None\n",
    "            self.documents = documents\n",
    "            self.embeddings = embeddings\n",
    "            self._initialize_client() \n",
    "            self._get_or_create_collection()\n",
    "            self._add_documents(self.documents, self.embeddings)\n",
    "\n",
    "        def _initialize_client(self):\n",
    "            self.client = chromadb.PersistentClient(path = self.persistent_directory)\n",
    "            print(\" chromadb client intialized successfullly\")\n",
    "\n",
    "        def _get_or_create_collection(self):\n",
    "            self.collection = self.client.get_or_create_collection(name = \"pdf_documents\" , metadata = {\"source\" : \"pdf documenst for RAG\"})\n",
    "            print(f\"collection {self.collection} ready to use\")\n",
    "\n",
    "        def _add_documents(self , documents , embeddings : np.ndarray):\n",
    "            ids = []\n",
    "            texts = []\n",
    "            metadatas = []\n",
    "            embeddings_list = []\n",
    "\n",
    "            for i , (doc , emb) in enumerate(zip(documents , embeddings)):\n",
    "                doc_id = f\"doc_{uuid.uuid4().hex[:8]}\"\n",
    "                ids.append(doc_id)\n",
    "                texts.append(doc.page_content)\n",
    "                metadatas.append(doc.metadata)\n",
    "                embeddings_list.append(emb.tolist())\n",
    "\n",
    "            try:\n",
    "                self.collection.add(\n",
    "                    ids = ids , \n",
    "                    documents = texts,\n",
    "                    metadatas = metadatas,\n",
    "                    embeddings = embeddings_list\n",
    "                )\n",
    "                print(f\" added {len(documents)} documnets to the vector store \")\n",
    "            except Exception as e:\n",
    "                print(f\" error adding documents to vector store : {e}\")\n",
    "vectorstore = vectorstoreManager(documents = chunks , embeddings = embeddings)\n",
    "\n",
    "print(\"vector store setup complete\")\n",
    "\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9371713",
   "metadata": {},
   "source": [
    "RAG Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f102d289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RAG system initialized successfully\n"
     ]
    }
   ],
   "source": [
    "class RAGsystem:\n",
    "    def __init__(self , vectorestore : vectorstoreManager ,  embedding_manager: Embeddingmanager):\n",
    "        self.vectorestore = vectorestore\n",
    "        self.embeddings = embedding_manager\n",
    "    def reterive(self , query:str , top_k:int =5)-> List[Document]:\n",
    "\n",
    "        query_embeddings = self.embeddings.generated_embeddings( [query])\n",
    "        quer_retrive = self.vectorestore.collection.query( query_embeddings= query_embeddings.tolist(),\n",
    "                                                            n_results = top_k)\n",
    "        \n",
    "        docs = quer_retrive[\"documents\"][0]\n",
    "        metas = quer_retrive[\"metadatas\"][0]\n",
    "         \n",
    "        retrieved_docs = [] \n",
    "        for doc, meta in zip(docs, metas):\n",
    "            retrieved_docs.append(Document(page_content=doc, metadata=meta))\n",
    "            \n",
    "        return retrieved_docs\n",
    "    \n",
    "    \n",
    "    print(\" RAG system initialized successfully\")\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " modelall-MiniLM-L6-v2 loaded successfully\n",
      "RAG system setup complete\n",
      " eembeddings size :(1, 384)\n",
      "<class 'list'>\n",
      "[Document(metadata={'modDate': 'D:20251223172733Z', 'keywords': '', 'producer': 'www.ilovepdf.com', 'author': '', 'total_pages': 3, 'creationDate': \"D:20251223172733+00'00'\", 'creationdate': '2025-12-23T17:27:33+00:00', 'format': 'PDF 1.5', 'creator': 'Microsoft¬Æ Word 2016', 'title': '', 'moddate': '2025-12-23T17:27:33+00:00', 'subject': '', 'trapped': '', 'file_path': 'data\\\\Darshan_resume.pdf', 'source': 'Darshan_resume.pdf', 'page': 0}, page_content='Darshan Hiremath \\n8904691801 | darshanah2002@gmail.com \\n \\nProfile \\nAI & Machine Learning enthusiast with hands-on experience in Statistical Models, Transformer \\nModels, and Large Language Models (LLMs). Passionate about model explainability, fine-tuning \\ntechniques, and AI-powered applications. Skilled in integrating LIME, SHAP, and LLMs (GPT-\\n4, Gemini AI) to enhance interpretability. Experienced in efficient fine-tuning (LoRA, PEFT) and \\noptimizing large models for real-world use. \\n \\nTechnical Skills \\nProgramming: Python \\n‚Ä¢ \\nExplainable AI: SHAP, LIME, Grad-CAM, Integrated Gradients \\n‚Ä¢ \\nLLM : Llama 3.1  \\n‚Ä¢ \\nDeep Learning: CNNs, Transformers, LLMs   \\n‚Ä¢ \\nNLP Models: GPT-2, DistilBERT   \\n‚Ä¢ \\nLLM Fine-Tuning: LoRA, PEFT, Quantization (4-bit, 8-bit)   \\n‚Ä¢ \\nFrameworks: PyTorch, TensorFlow , Hugging Face   \\n‚Ä¢ \\nTools: Gemini AI, GPT-4   \\n‚Ä¢ \\nDomains: XAI, NLP, Deep Learning , Model Interpretability \\n \\nWork Experience \\nAI & Machine Learning Engineer'), Document(metadata={'keywords': '', 'moddate': '2025-12-23T17:27:33+00:00', 'creationdate': '2025-12-23T17:27:33+00:00', 'total_pages': 3, 'title': '', 'producer': 'www.ilovepdf.com', 'creationDate': \"D:20251223172733+00'00'\", 'subject': '', 'trapped': '', 'modDate': 'D:20251223172733Z', 'creator': 'Microsoft¬Æ Word 2016', 'file_path': 'data\\\\Darshan_resume.pdf', 'format': 'PDF 1.5', 'author': '', 'page': 0, 'source': 'Darshan_resume.pdf'}, page_content='Darshan Hiremath \\n8904691801 | darshanah2002@gmail.com \\n \\nProfile \\nAI & Machine Learning enthusiast with hands-on experience in Statistical Models, Transformer \\nModels, and Large Language Models (LLMs). Passionate about model explainability, fine-tuning \\ntechniques, and AI-powered applications. Skilled in integrating LIME, SHAP, and LLMs (GPT-\\n4, Gemini AI) to enhance interpretability. Experienced in efficient fine-tuning (LoRA, PEFT) and \\noptimizing large models for real-world use. \\n \\nTechnical Skills \\nProgramming: Python \\n‚Ä¢ \\nExplainable AI: SHAP, LIME, Grad-CAM, Integrated Gradients \\n‚Ä¢ \\nLLM : Llama 3.1  \\n‚Ä¢ \\nDeep Learning: CNNs, Transformers, LLMs   \\n‚Ä¢ \\nNLP Models: GPT-2, DistilBERT   \\n‚Ä¢ \\nLLM Fine-Tuning: LoRA, PEFT, Quantization (4-bit, 8-bit)   \\n‚Ä¢ \\nFrameworks: PyTorch, TensorFlow , Hugging Face   \\n‚Ä¢ \\nTools: Gemini AI, GPT-4   \\n‚Ä¢ \\nDomains: XAI, NLP, Deep Learning , Model Interpretability \\n \\nWork Experience \\nAI & Machine Learning Engineer'), Document(metadata={'keywords': '', 'creationdate': '2025-12-23T17:27:33+00:00', 'total_pages': 3, 'subject': '', 'file_path': 'data\\\\Darshan_resume.pdf', 'creationDate': \"D:20251223172733+00'00'\", 'producer': 'www.ilovepdf.com', 'modDate': 'D:20251223172733Z', 'title': '', 'author': '', 'page': 0, 'format': 'PDF 1.5', 'creator': 'Microsoft¬Æ Word 2016', 'source': 'Darshan_resume.pdf', 'trapped': '', 'moddate': '2025-12-23T17:27:33+00:00'}, page_content='Darshan Hiremath \\n8904691801 | darshanah2002@gmail.com \\n \\nProfile \\nAI & Machine Learning enthusiast with hands-on experience in Statistical Models, Transformer \\nModels, and Large Language Models (LLMs). Passionate about model explainability, fine-tuning \\ntechniques, and AI-powered applications. Skilled in integrating LIME, SHAP, and LLMs (GPT-\\n4, Gemini AI) to enhance interpretability. Experienced in efficient fine-tuning (LoRA, PEFT) and \\noptimizing large models for real-world use. \\n \\nTechnical Skills \\nProgramming: Python \\n‚Ä¢ \\nExplainable AI: SHAP, LIME, Grad-CAM, Integrated Gradients \\n‚Ä¢ \\nLLM : Llama 3.1  \\n‚Ä¢ \\nDeep Learning: CNNs, Transformers, LLMs   \\n‚Ä¢ \\nNLP Models: GPT-2, DistilBERT   \\n‚Ä¢ \\nLLM Fine-Tuning: LoRA, PEFT, Quantization (4-bit, 8-bit)   \\n‚Ä¢ \\nFrameworks: PyTorch, TensorFlow , Hugging Face   \\n‚Ä¢ \\nTools: Gemini AI, GPT-4   \\n‚Ä¢ \\nDomains: XAI, NLP, Deep Learning , Model Interpretability \\n \\nWork Experience \\nAI & Machine Learning Engineer')]\n"
     ]
    }
   ],
   "source": [
    "embedding_manager = Embeddingmanager()\n",
    "\n",
    "print(\"RAG system setup complete\")\n",
    "rag_system = RAGsystem(vectorestore=vectorstore , embedding_manager=embedding_manager)\n",
    "query = \" who is darshan \"\n",
    "retrieved_documents = rag_system.reterive(query=query , top_k=3)\n",
    "print(type(retrieved_documents))\n",
    "print(retrieved_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fe6bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Darshan is an AI & Machine Learning enthusiast and engineer with hands-on experience in Statistical Models, Transformer Models, and Large Language Models (LLMs). He is passionate about model explainability, fine-tuning techniques, and AI-powered applications.\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "context = \"\\n\\n\".join([doc.page_content for doc in retrieved_documents])\n",
    "\n",
    "import os\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "\n",
    "llm = ChatGroq( temperature=0.7 ,  model = \"llama-3.3-70b-versatile\" ,  max_tokens = 1024)\n",
    "\n",
    "prompt =  f\"\"\"\n",
    "    Use the following context to answer the question.\\n\\n and if the answer is \n",
    "    not present tell \" i don't know the  answwer\" .\n",
    "    context : {context}\n",
    "    question : {query}\n",
    "    answer :\n",
    "    \"\"\"\n",
    "\n",
    "response = llm.invoke(prompt)\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langrag1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
